{"posts":[{"title":"","text":"SVM-based Adaptive Markov Chain for Tennis Match Prediction: Updatable Probabilities and Momentum AnalysisZhihao Li, Changrong You, Zhihan LiuCOMAP’s Mathematical Contest in Modeling (MCM) and Interdisciplinary Contest in Modeling (ICM), 2024[paper][award][code] Research on Replenishment and Pricing Strategies Based on Time Series Linkage AnalysisZhihao Li, Pai Lin, Kaida HuangChina Undergraduate Mathematical Contest in Modeling (CUMCM), 2023[paper][award][code]","link":"/publications/"},{"title":"Top prize of Shaanxi Province Advanced Mathematical Competition for College Students","text":"","link":"/AMC2023/"},{"title":"National Second Prize of China Collegiate Mathematical Modeling Contest","text":"","link":"/CUMCM2023/"},{"title":"Excellent Student Model Award of Xidian University","text":"","link":"/ExcellentStudent2023/"},{"title":"National First Prize in the China College Student Service Outsourcing Innovation and Entrepreneurship Competition","text":"","link":"/FWWB2023/"},{"title":"Huameng Scholarship of Xidian University","text":"","link":"/HuamengScholarship2023/"},{"title":"Huawei &quot;Intelligent Base&quot; Industry-Education Integration Collaboration Education Base Scholarship of Xidian University","text":"","link":"/HuaweiIntelligentBaseScholarship2023/"},{"title":"International First Prize of American Collegiate Mathematical Modeling Contest","text":"","link":"/MCMICM2024/"},{"title":"关于 ARM 指令体系中立即数范围的扩散机制","text":"ARM 指令体系特点ARM作为一款嵌入式微处理器或者一种嵌入式微处理架构，具有非常规整的指令体系，其精简指令集中共计 $30$ 条指令，并且每条指令均为 $32$ 位宽。 ARM 立即数的表示ARM 中一条指令有 $32$ 比特，但是立即数不能占用 $32$ 位指令编码空间的全部比特位，留给立即数的编码空间只有 $12$ 位。此外，因为 ARM 指令为单周期指令，当遇到操作数非常大的情形时，也不可能再取指一次。因此，不得不对指令中立即数表示进行特殊的设计。 扩散数据表示范围ARM 处理器指令系统将 $12$ 比特位分成 $8$ 比特位的常数和 $4$ 比特位的循环右移偶数位两部分。我们知道，$8$ 位比特位能够表示的数据范围为 (无符号数) Immed_$8=0\\sim255$，而 $4$ 位循环移位能够表示范围为 Rotate_Imm$=0\\sim15$, 因此设计立即数表示为: Immed = Immed_$8$ >> ($2\\times$Rotate_Imm) 循环右移偶数位数 $2\\times(0\\sim15)=${$0,2,4,\\cdots,30$} 因此，一个 $8$ 比特的数据，有 $16$ 种不同的循环右移方式，那么可以表示的数据范围为： $$2^8\\times16=256\\times16=4096B=4KB=2^{12}$$ 上式表明，循环右移偶数位并没有使得数据表示个数有任何改变; I.有效数据位在进一步阐述数据表示的扩散机制前，先要明确有效数据位的含义。在循环移位中，有效数据位指的是最长非零二进制串，即 $000101000100$ 中有效数据位为 $1010001$, 长度为 $7$。 II.扩散机制循环右移偶数位使得立即数在数据表示上有效数据位范围从原来的 $0\\sim12$ 位变为了 $0\\sim8$ 位，并且可以表示在第 $12\\sim32$ 比特位上。注：最高移位是 $8$ 位常数位，循环右移 $30$ 位，最长可以表示为 $38$ 位的长度，为什么不尽最大长度扩散数据范围呢？可以考虑指令的执行过程，ARM 指令中的立即数会被送往 ALU 中，而 ARM 的 ALU 最高处理 $32$ 位数据，因此只扩散到 $32$ 位编码空间。【扩散效应】——数据本源并没有发生变化，而是将数据扩展散开分布。 概括来讲，循环右移偶数位不能改变原有数据表示个数，只是将数据离散分布到 $32$ 位编码空间，因此称为扩散数据表示。但是这种方式，就要保证立即数是合法的，即满足有效位数小于等于 $8$ 位，能够通过循环右移偶数位后表示该数据。","link":"/blog/ARMImmediateNumber/"},{"title":"Install Anaconda On the Linux Server","text":"Download the Anaconda PackageFirstly, we need to get the anaconda3 package and there is some mirrors website providing the faster speed of downloading. There, we chosen the tsinghua mirror and the version of 2023.09 with x86 architecture. 1wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.09-0-MacOSX-x86_64.sh After running, we can get this package at the home directory. Install the PackageIn the linux server, we can install the anaconda package by the following command. 1bash Anaconda3-2023.09-0-Linux-x86_64.sh Running the above command we can see this welcoming page, Next, we need to accept the license agreement to continue following steps. Then, we need to choose the installation path, and we can choose the default path by inputting ENTER. Automatically initializing conda will be convenient for us. So in this step, it is recommended to input the yes for automatically activating base environment. After implementing the above steps, we can successfully install the anaconda on a linux server. There is two ways to check whether the anaconda is installed successfully. The first one is to check the version of anaconda. The second one is to check the environment variable of anaconda. Create the New EnvironmentIn this section, a new conda virtual environment will be create: 1conda create -n LabelNoise python=3.11.5 We can also specify the installation path of the new environment. For example, we can create a new environment in the path of /home/zhli/anaconda3/envs/Pytorch by the following command: 1conda create --prefix=/home/zhli/anaconda3/envs/Pytorch python=3.11.5 Activate the New EnvironmentIf we want use the new environment, we need to activate it first. 1conda activate LabelNoise Remove the New EnvironmentIf we donn’t need the new environment any more, we can remove it by the following command: 1conda remove --n Pytorch --all","link":"/blog/AnacondaOnLinuxServer/"},{"title":"Blog Configuration on Icarus Theme","text":"Blog Configuration On Github1. Setup initialize Hexo project in the target &lt;folder&gt; 12$ hexo init &lt;folder&gt;$ cd &lt;folder&gt; 2. Install Icarus Theme To install Icarus as a node package via NPM, run the following command from the root of your Hexo site: 1npm install -S hexo-theme-icarus hexo-renderer-inferno Use the hexo command to change the theme to Icarus: 1hexo config theme icarus 3. Theme Configuration Icarus’ default theme configuration file is _config.icarus.yml. 3.1 Overall style configurationVersionThis version of the theme configuration file is not advised to change by yourself, determining whether to upgrade the theme configuration. 1version: 5.1.0 Theme Variantdefault and cyberpunk determine the skin of Icarus theme. default has always been suggested if you want to make a acadmic style blog. 1variant: default LogoThe logo of your site will display on the navigation bar and the footer. The value of the logo can either be the path or URL to your logo image: 1logo: https://ms-blogimage.oss-cn-chengdu.aliyuncs.com/picture/img/EBlog202306222351609.png FaviconSet a icon for your blog website in the form of URL or path to the website’s icon. 12head: favicon: https://ms-blogimage.oss-cn-chengdu.aliyuncs.com/picture/img/EBlog202306222351609.png Navigation BarThe navbar section defines the menu items and links in the navigation bar. You may put any menu item in the navigation bar by adding : to the menu setting. To put links on the right side of the navigation bar, add : to the links setting. 12345678910111213navbar: # Navigation menu items menu: Zhihao Li's Blog: / Archives: /archives Categories: /categories Tags: /tags About: /about # Links to be shown on the right of the navigation bar links: GitHub: icon: fab fa-github url: https://github.com/LZHMS/LZHMS.github.io FooterThe footer section defines the links on the right side of the page footer. The link format is exactly the same as links in the navbar section. 1234567891011121314footer: # Copyright text copyright: © 2023 Zhihao Li # Links to be shown on the right of the footer section links: Creative Commons: icon: fab fa-creative-commons url: https://creativecommons.org/ Attribution 4.0 International: icon: fab fa-creative-commons-by url: https://creativecommons.org/licenses/by/4.0/ GitHub: icon: fab fa-github url: https://github.com/LZHMS/LZHMS.github.io 3.2 Article configurtionCode Highlight You can choose a theme from all themes listed under highlight.js/src/styles to customize the code blocks. Copy the file name (without the .css extension) to the theme setting. To hide the “copy” button of every code block, set clipboard to false. If you wish to fold or unfold all code blocks, set the fold setting to folded or unfolded. 12345678highlight: # Code highlight themes # https://github.com/highlightjs/highlight.js/tree/master/src/styles theme: atom-one-light # Show copy code button clipboard: true # Default folding status of the code blocks. Can be &quot;&quot;, &quot;folded&quot;, &quot;unfolded&quot; fold: unfolded Read TimeYou can show a word counter and the estimated reading time of your article above the article title by setting readtime to true in the article section. 12article: readtime: true Update Timeset update_time to true in the article section of your theme configuration file to show every article updated time. 12article: update_time: true Article LicensingYou can show a section at the end of your posts/pages describing the licensing of your work. Both text and icons are accepted as license links. 123456789101112article: # Article licensing block licenses: Creative Commons: icon: fab fa-creative-commons url: https://creativecommons.org/ Attribution: icon: fab fa-creative-commons-by url: https://creativecommons.org/licenses/by/4.0/ Noncommercial: icon: fab fa-creative-commons-nc url: https://creativecommons.org/licenses/by-nc/4.0/ SidebarTo make a sidebar fixed when you scroll the page, set the sticky setting of that sidebar to true in the sidebar section. 123456789sidebar: # Left sidebar configurations left: # Whether the sidebar sticks to the top when page scrolls sticky: false # Right sidebar configurations right: # Whether the sidebar sticks to the top when page scrolls sticky: true 3.3 Widgets ConfigurationProfile Widget Set multiple author_title and display by rows and set font-family in hexo-theme-icarus\\layout\\widget\\profile.jsx 123{author ? &lt;p class=&quot;title is-size-4 is-block&quot; style=&quot;line-height: 'inherit'; font-family: Times New Roman&quot;&gt;{author}&lt;/p&gt; : null}{authorTitle ? &lt;p style=&quot;white-space: pre-line; font-style: italic; font-family: Times New Roman; margin-bottom: 0.50rem; font-size: 1.0em&quot;&gt;{authorTitle}&lt;/p&gt; : null}{location ? &lt;p class=&quot;is-size-5 is-flex justify-content-center&quot; style=&quot;font-family: Times New Roman&quot;&gt;} 1234# Author titleauthor_title: | Computer Science Machine Learning Set social_links using Font Awesome Icons 12345678910111213141516social_links: Github: icon: fab fa-github url: https://github.com/LZHMS Facebook: icon: fab fa-facebook url: https://www.facebook.com/profile.php?id=100094074308733 Twitter: icon: fab fa-twitter url: https://twitter.com/ZhihaoLi1376106 Email: icon: fa-solid fa-envelope url: mailto:LZH1314521ligao@163.com QQ: icon: fab fa-qq url: https://w.4rxb.com/s/yq3hxp 4. Configure Home Page on the SiteIn the normal case, the default home page includes some abstacts of blogs. However, in some case we want to to display our information or introduction about the website. That’s the time when we need to individually configure the home page. Create a index.md anticle under the source directoryThis is an anticle used for our individual content to be display on the home page. Modify index_generator in the file of _config.ymlWe need to modify the index_generator:path to an invalid value for example default-index in order to shield the default home page. Add the home page to the websiteIn the configuration file of theme, we can add an item of home under menu item. And then set the home value like / || fa fa-home if we need an icon for the home page. 5. Open the GalleryIf we want to display multiple pictures in the gallery, we can use the following code to open the gallery. 12&lt;div class=&quot;justified-gallery&quot;&gt;&lt;/div&gt; 主题魔改自定义 ICON 图标Hexo + Icarus 采用 FontAwesome 图标，但很多图标实际上并未包含，包括国内的 、 以及 以及国外的 ，尤其是我们想自定义地引入一些 icon 的话也不能够实现，所以我们需要让 hexo 添加对这些网站图标的支持，使博客正常显示他们图标。 Step 1: 下载图标最开始的准备是收集所需的图标，最常用的网站库还是阿里的矢量库 Iconfont，搜索选择所需的图标，不断添加到购物车。选购完毕后，再选择 Add to Project，让选择的图标添加到你的一个项目中。 在项目中，选择 Font class，然后下载至本地即可，将其保存至主题目录themes\\icarus\\source\\css 文件夹中，解压并重新命名为 icons。如果想对下载的图标的颜色、大小等进行修改，则打开所下载的文件，找到对应项进行修改。 Step 2: 配置图标我们需要在主题中引入所下载的图标库，在主题目录下 themes\\icarus\\layout\\common\\head.jsxw 文件中，在 &lt;link rel=&quot;stylesheet&quot; href={iconcdn()} /&gt; 下方添加 &lt;link rel=&quot;stylesheet&quot; href=&quot;/css/icons/iconfont.css&quot;&gt;&lt;/link&gt;，添加后如下所示: 12&lt;link rel=&quot;stylesheet&quot; href={iconcdn()} /&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/css/icons/iconfont.css&quot;&gt;&lt;/link&gt; // add the iconfont 然后需要具体添加图标，主要在于图标 icon 的大小位置配置需要与 icarus 主题原生的 icon 相容，所以首先需要统一配置引入的 icon 的大小，具体在 themes\\icarus\\source\\css\\icons\\iconfont.css 中配置大小为 24px，如下所示: 1234567.iconfont { font-family: &quot;iconfont&quot; !important; font-size: 24px; font-style: normal; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale;} 统一配置的大小全局有效，但是具体图标下面配置后，全局配置就会被覆盖，所以对于导航栏的图标，需要额外配置的参数如下， 1234567.icon-github:before { content: &quot;\\ea0b&quot;; font-size: 14px; display: flex; align-items: center; margin: 0;} 对于 Profile 的图标也需要进一步地调节大小，配置的参数可以参考如下： 1234.icon-QQ1:before { content: &quot;\\e667&quot;; font-size: 20px;} 仍然存在的问题是，对于白天和黑夜两种主题模式，引入的 icon 图标无法自动切换黑夜模式，只保持一种样式。 Step 3: 使用图标 使用图标主要是在配置文件和博客文章两个地方，在博客配置中，直接配置相应的icon即可，iconfont icon-xxx; 在博客文章中，需要引入 &lt;i class=&quot;iconfont icon-bilibili&quot;&gt;&lt;/i&gt; 即可； 如果需要在引用时配置图标大小，可以这样指定：&lt;i class=&quot;iconfont icon-github7&quot; style=&quot;font-size: 20px;&quot;&gt;&lt;/i&gt;。 引入霞鹜文楷中文字体Icarus 主题默认使用谷歌的 cdn，因此字体样式只能从其中选择，引入霞鹜文楷中文字体首先需要制作一个字体的 cdn 用于引用，这个可以直接利用项目 lxgw-wenkai-screen-webfont 中的 cdn，在博客配置文件中引入即可。 Step 1: 引入字体 CDN在主题目录 themes\\icarus\\layout\\common\\head.jsx 文件中，找到 const fontCssUrl ，然后将其修改为： 12345const fontCssUrl = { default: 'https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.7.0/style.css', // default: fontcdn('Ubuntu:wght@400;600&amp;family=Source+Code+Pro', 'css2'), //cyberpunk: fontcdn('Oxanium:wght@300;400;600&amp;family=Roboto+Mono', 'css2')}; 霞鹜文楷中文字体的 CDN 有许多版本，可以选择最新的配置。 Step 2: 配置字体在主题目录 themes\\icarus\\include\\style\\base.styl 文件中，找到 $family-sans-serif，然后将其修改为： 12$family-sans-serif ?= Times New Roman, LXGW WenKai Screen /* serif Georgia */$family-code ?= LXGW WenKai Screen, Cambria, 'Source Code Pro', monospace, 'Microsoft YaHei' 其中 Times New Roman 首先匹配英文字体，无法匹配中文字体，然后会找到第二个字体样式 LXGW WenKai Screen 匹配中文，这样就可以在 icarus 主题中引入霞鹜文楷字体了。","link":"/blog/BlogConfiguration/"},{"title":"Common Screen Commands","text":"IntroductionIn project development, when executing programs on the Linux terminal, if the terminal is closed, the program execution will also terminate. This poses significant inconvenience for long-running programs. Screen facilitates the management of multiple command-line workflows without concern for their interference. Programs are automatically backgrounded and continue execution until completion. Start a New screen Session1234# Start a new screen session named &quot;my_session&quot;screen -S my_session# Automatically name the new screen sessionscreen View Existing screen Sessions12# List all screen sessionsscreen -ls Attach to an Existing screen Session12# Attach to the screen session named &quot;my_session&quot;screen -r my_session Detach from an Existing screen Session12345678# Way 1# Detach from the screen session named &quot;my_session&quot;screen -d my_session# Way 2# Enter the following keys in turn and the program# will also continue to execute in the backgroundCtrl+aa Delete an Existing screen Session12# Delete the screen session named &quot;my_session&quot;screen -X -S my_session quit","link":"/blog/CommonScreenCommands/"},{"title":"Courses Analysis Tutorial Using MicroSoft Power BI","text":"准备工作数据准备针对自己本科阶段所有学习科目，应当导出或制作对应每个科目的属性以及成绩，将其汇总程 Excel 表格。具体的属性可以见以下打印的 PDF 文件，Excel 表格无法直接展示，附在随后。 MyCourses.xlsx 西电校友对于各位西电计科学子，博文也提供了可以直接导出个人所有必修以及限选科目成绩的jupyter notebook（因包含个人信息，完成科目成绩可以私下联系我），详见下文具体步骤。主要计算每门课程的平均分、最高分、最低分以及排名，可以将其替换为自己的ID，以及置换自己对应的专业限选课，然后计算即可。对于其他排名，诸如学年排名、推免综合排名等部分，这个因人而异，需要自行添加。 Jupyter Notebook Codes Load Datasets 123456789101112import pandas as pdimport numpy as npBaseCourses = pd.read_excel(&quot;Courses.xlsx&quot;, sheet_name=&quot;6Semester&quot;)print(BaseCourses.head())MyCourses = pd.read_excel(&quot;Courses.xlsx&quot;, sheet_name=&quot;Courses&quot;)MyCourses.set_index(MyCourses.columns[0], inplace=True)print(MyCourses.head())EmbeddedCourses = pd.read_excel(&quot;Courses.xlsx&quot;, sheet_name=&quot;Embedded&quot;)print(EmbeddedCourses.head()) Calculate Scores 1234567891011121314151617181920212223# calculate the average, min, max scoreMyCourses['单科排名'] = MyCourses['单科排名'].astype(str)for col in BaseCourses.columns[3:]: MyCourses.loc[col, '平均分'] = round(BaseCourses[col].mean(), 2) MyCourses.loc[col, '最低分'] = BaseCourses[col].min() MyCourses.loc[col, '最高分'] = BaseCourses[col].max() ranking = BaseCourses[col].rank(method='min', ascending=False).astype(int) rank_rate_percentage = (ranking.iloc[0] / len(BaseCourses)) MyCourses.loc[col, '单科排名'] = f&quot;{ranking[0]}/{len(BaseCourses)}={rank_rate_percentage* 100:.2f}%&quot; MyCourses.loc[col, '百分比'] = round(1 - rank_rate_percentage, 2)# 专业限选课EmbeddedColumns = ['嵌入式程序设计', '嵌入式应用综合设计', 'SOC微体系结构设计', '数字信号处理', '自主可控嵌入式系统']for col in EmbeddedColumns: MyCourses.loc[col, '平均分'] = round(EmbeddedCourses[col].mean(), 2) MyCourses.loc[col, '最低分'] = EmbeddedCourses[col].min() MyCourses.loc[col, '最高分'] = EmbeddedCourses[col].max() ranking = EmbeddedCourses[col].rank(method='min', ascending=False).astype(int) rank_rate_percentage = (ranking.iloc[0] / len(EmbeddedCourses)) MyCourses.loc[col, '单科排名'] = f&quot;{ranking[0]}/{len(EmbeddedCourses)}={rank_rate_percentage * 100:.2f}%&quot; MyCourses.loc[col, '百分比'] = round(1 - rank_rate_percentage, 2) Save to Excel 12345678MyCourses.reset_index(drop=False, inplace=True)print(MyCourses.head())try: with pd.ExcelWriter(&quot;MyCourses.xlsx&quot;, mode='a') as writer: MyCourses.to_excel(writer, sheet_name=&quot;MyCourses&quot;, index=False)except Exception as e: MyCourses.to_excel(&quot;MyCourses.xlsx&quot;, sheet_name=&quot;MyCourses&quot;, index=False) Power BI Desktop 安装Microsoft Power BI 官网提供了多种安装方式，但是比较推荐的安装方式还是 Power BI Desktop，详情可见下载页面。 数据导入 可视化图块 Power BI 可以对数据做汇总分析，然后重构成新的统计量，对应每一个可视化图块，都可以对选中的数据自动绘制图表。最终的报表可以由多个可视化图块组成，共同展示相应的统计信息。而且基于同一份数据，不同图块能够相互关联，交互地展示同一份子数据。 具体的模块配置比较简单，对照着示例基本很快可以完成一份报表的绘制，因此具体用法就不在此阐述了。 发布到博客网站重点想要分享的还是怎样把我们做好的报表整个地发布到博客网站上，可以展示给其他人阅览。 注册 Power BI 服务账号企业账号以及部分地区可以免费享有 Power BI 服务，尤其是公布到微软服务器上。但是在国内的话，不会提供相应的服务，具体需要购买相应的方案。比较简单高效的方法是，获取一个国外或企业账号，进行注册。这里可以通过淘宝渠道购买一个，基本8元左右。另外有的采用 Azure 账户的方式，但似乎已经失效，具体可以参考知乎文章最新版-PowerBI账户注册（无需企业邮箱！！！）。 发布到 Power BI 服务 本机上制作好的报表需要先发布到 Power BI，如上图所示。然后需要在 Power BI 服务上对应保存本机报表的工作区中，将报表生成网页嵌入代码，具体操作如下： 最后将生成的HTML代码放置在博客网页中就可以了。 效果展示放置一个做好的报表的网页链接，具体效果可以见下文。 资源汇总 MyCourses.xlsx CoursesAnalysis.pbix Reference Chenlai Qian, bachelor in Xidian University and master in Southeast University. https://levitate-qian.github.io/about/","link":"/blog/CoursesAnalysis/"},{"title":"Deep Into Denoising Diffusion Probabilistic Models (DDPM)","text":"Notion Blog 生成式模型 Normalizing Flows GANs VAEs . . . 他们的核心思想都是将来自简单分布的噪声转换为数据样本，DDPM 也正是如此，它从纯噪声开始学习并逐渐对数据进行去噪； DDPMDDPM 主要包含两个处理过程， 一个固定/预先定义的前向扩散过程 $q$ ，选择的方法是逐渐向图像中添加高斯噪声直到最终变为纯噪声； 一个可学习的逆去噪扩散过程 $p_{\\theta}$ , 方法是训练一个神经网络逐渐对来自纯噪声的图像去噪，指导最终获得一个真实图像； 从数据分布（某个数据集）采样一张真实图像，前向过程在每一时间步都对上一时间步的图像添加采样自高斯分布的噪声，以获得当前加噪图像。经过充分大时间步且具有较好的添加噪声的模式，最终会在有限步内（例如 $T=1000$）获得各向同性高斯分布。 数学形式前向扩散过程真实数据分布记为 $q(x_0)$，采样的图像表示为 $x_0\\sim q(x_0)$，已知的方差模式为 $0&lt; \\beta_1 &lt; \\beta_2 &lt; \\cdots &lt; \\beta_T &lt;1$，则前向过程定义为 $$q(x_t|x_{t-1}) = N(x_t; \\sqrt{1-\\beta_t}x_{t-1},\\beta_tI)$$ 时间步 $t$ 处的包含更大噪声的图像是从上一时间步 $t-1$ 加噪而来，构造的数据分布为条件高斯分布，即从该条件高斯分布中采样得到。条件高斯分布的参数为，$\\mu_t = \\sqrt{1-\\beta_t}x_{t-1}, \\sigma_t^2 = \\beta_t$。 条件性：$x_t$ 的获取需要以 $x_{t-1}$ 为条件，或者说缩放 $x_{t-1}$ 均值变换得到； $\\beta_t$：可以理解为缩放系数，对每一时间步而言，因此对应下标为 $t$，并且其是变化的，所谓的 “variance schedule” 表示其可以是线性、二次、余弦形式。 我们知道对一个非标准正态分布 $x\\sim N(\\mu, \\sigma^2)$，其标准化对应的公式为 $z=\\frac{x-\\mu}{\\sigma}\\sim N(0, 1)$ 可以将其转变为标准正态分布。因此我们易得，$x$ 对应的变换公式为 $x = \\mu + \\sigma z$ 因此，我们可以在每一时间步通过采样 $\\epsilon\\sim N(0, I)$ 然后表示 $$x_t = \\sqrt{1-\\beta_t}{x_{t-1}} + \\sqrt{\\beta_t}\\epsilon$$ 逆扩散过程相对于前向扩散过程，如果我们知道 $p(x_{t-1}|x_t)$ ，则可以对 $x_T$ 随机采样出高斯噪声，然后逐渐去噪直到它变化为来自于真实数据分布的一个样本 $x_0$； $p(x_{t-1}|x_t)$ 的不可知性 当然，如果我们知道了这个条件概率分布，那么就很容易从纯噪声生成想要的数据样本，但是这需要知道所有可能图像的分布去计算这样的条件概率。 $q(x_{t}|x_{t-1})$ 的可知性 之所以在这里分析前向扩散就是为了与逆向扩散进行对比，$q(x_{t}|x_{t-1})$ 是我们通过前面分析的高斯分布建立模型的，并且高斯模型的均值、协方差矩阵都是与设定的超参数相关，是固定/预先设置的过程，用于将采样的真实数据逐步变化纯噪声。因此，它是可知的，有确定性模型（参数确定）的。 $p(x_{t-1}|x_t)$ 的参数估计 我们无法对 $p(x_{t-1}|x_t)$ 直接建立确定性的模型，但是可以利用神经网络去估计这个条件概率分布，记为 $p_{\\theta}(x_{t-1}|x_t)$，这个过程中参数 $\\theta$ 是可学习的，通过随机梯度下降法进行优化。 类比前向扩散过程，很容易想到逆扩散过程可能也会是一个高斯模型，含有待估计的均值、协方差参数，即 $$p_{\\theta}(x_{t-1}|x_t) = N(x_{t-1};\\mu_{\\theta}(x_t,t),\\Sigma_{\\theta}(x_t,t))$$ 其中，对应的均值 $\\mu_{\\theta}$、协方差 $\\Sigma_{\\theta}$ 均与上一步图像样本 $x_t$ 以及当前噪声水平 $t$ 相关。 参数学习 正常来讲，神经网络应当学习均值 $\\mu_{\\theta}$ 和协方差 $\\Sigma_{\\theta}$ 才能实现最好的结果，事实也是如此 Improved diffusion models。但是DDPM 只学习了条件概率分布的均值而保持方差固定，即设定 $\\sigma_t^2 = \\beta_t$. 目标函数$q$ 和 $p_{\\theta}$ 可以被看作一个变分自动编码器（VAE），其中 variational lower bound 被用来最小化负对数似然值相对于 ground truth. 因此在每一时间步，损失函数是各时间步的损失项之和，即 $$L = L_0 + L_1 + \\cdots + L_T$$ 除了 $L_0$ 损失函数的每一项均是两个高斯分布的 KL 散度，用于度量前向扩散过程和逆向扩散过程中每一时间步对应的高斯分布的差异，实际上就是在让逆向扩散过程学习前向扩散过程。DDPM（逆扩散过程中协方差固定）中可以明确地表示为相对于均值的 L2 损失。 Nice Property前向扩散过程的构造一个最好的特性是可以直接根据 $x_0$ 计算任意噪声水平下的样本 $x_t$， $$q(x_t|x_0)=N(x_t;\\sqrt{\\overline{\\alpha_t}}x_0,(1-\\overline{\\alpha_t})I)$$ 其中，$\\alpha_t:=1-\\beta_t$ 且 $\\overline{\\alpha_t}:=\\prod_{s=1}^t\\alpha_s$ 不妨表示 $x_t$, $x_{t-1}$ 如下， $$\\begin{align*}x_{t} &amp;= \\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}\\epsilon_t\\newlinex_{t-1} &amp;= \\sqrt{\\alpha_{t-1}}x_{t-2}+\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}\\end{align*}$$ 故 $$\\begin{align*}x_{t} &amp;= \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2}+\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1})+\\sqrt{1-\\alpha_t}\\epsilon_t\\newline&amp;=\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2}+\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}+\\sqrt{1-\\alpha_t}\\epsilon_t\\end{align*}$$ 对于 $\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}$ 可以将其看作一个高斯分布，其满足 $$\\begin{align*}z_1&amp;=0+\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}\\newline&amp;\\sim N(0,\\alpha_t(1-\\alpha_{t-1})I)\\end{align*}$$ 同理，对于 $\\sqrt{1-\\alpha_t}\\epsilon_t$ 可以表示为 $$\\begin{align*}z_2&amp;=0+\\sqrt{1-\\alpha_{t}}\\epsilon_{t}\\newline&amp;\\sim N(0,(1-\\alpha_{t})I)\\end{align*}$$ 对于两个相互独立的正态随机变量 $z_1\\sim N(\\mu_1,\\sigma^2_1)$ 以及 $z_2\\sim N(\\mu_2,\\sigma^2_2)$有 $DZ = DZ_1 + DZ_2 + 2Cov(Z_1, Z_2)=\\sigma_1^2 + \\sigma_2^2$ 因此，$z=z_1+z_2\\sim N(0,(1-\\alpha_t\\alpha_{t-1})I)$ 则可推得 $$\\begin{aligned}x_{t} &amp;=\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2}+\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}+\\sqrt{1-\\alpha_t}\\epsilon_t\\newline&amp;=\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2}+\\sqrt{1-\\alpha_t\\alpha_{t-1}}\\epsilon_t\\newline&amp;=\\cdots\\newline&amp;=\\sqrt{\\alpha_t\\alpha_{t-1}\\cdots\\alpha_1}x_0+\\sqrt{1-\\alpha_t\\alpha_{t-1}\\cdots\\alpha_1}\\epsilon_t\\newline&amp;=\\sqrt{\\overline{\\alpha_t}}x_0+\\sqrt{1-\\overline{\\alpha_t}}\\epsilon_t\\end{aligned}$$ 其中，记 $\\alpha_t:=1-\\beta_t$ 且 $\\overline{\\alpha_t}:=\\prod_{s=1}^t\\alpha_s$ . 所以，根据以上推导，可以得到直接由初始真实数据样本在噪声水平 $t$ 下的条件概率分布为 $$q(x_t|x_0)=N(x_t;\\sqrt{\\overline{\\alpha_t}}x_0,(1-\\overline{\\alpha_t})I)$$ 由以下公式可以直接看出 $$\\begin{align*}x_{t} &amp;=\\sqrt{\\overline{\\alpha_t}}x_0+\\sqrt{1-\\overline{\\alpha_t}}\\epsilon_t\\end{align*}$$ 这种特性可以解释为，从高斯噪声中采样 $\\epsilon_t$，将它添加到真实样本 $x_0$ 中并通过适当缩放 $\\overline{\\alpha_t}$ 可以直接得到 $x_t$。由于 $\\overline{\\alpha_t}$ 可以预先计算，这启示我们，在训练过程中，可以优化损失函数 $L$ 的随机项 $L_t (t=1\\cdots T)$，整个优化过程变为采样时间步 $t$，采样高斯噪声 $\\epsilon_t$，优化 $L_t$. Noise Predictor由于前面推到的优美的特性，可以使得参数化均值后的神经网络去学习添加的噪声（$\\epsilon_\\theta(x_t, t)$） 而不是学习均值，因为从 $x_0$ 直接推导到 $x_t$ 对应的均值并不是在时间步 $t$ 由上一时间步 $t-1$ 推导的均值，而为了避免重复计算 $q$ 过程来获得 $x_t$，显然利用上述特性是最好的方式。 而损失函数的计算就转化为衡量添加噪声与预测噪声之间的差异。均值可以通过以下公式计算得到 $$\\mu_{\\theta}(x_t,t)=\\frac{1}{\\sqrt{\\alpha_t}}(x_t-\\frac{\\beta_t}{\\sqrt{1-\\overline{\\alpha_t}}}\\epsilon_{\\theta}(x_t,t))$$ Loss Function最终的目标函数 $L_t$ 表示为 $$||\\epsilon-\\epsilon_\\theta(x_t,t)||^2 = ||\\epsilon-\\epsilon_\\theta(\\sqrt{\\overline{\\alpha_t}}x_0+\\sqrt{(1-\\overline{\\alpha_t})}\\epsilon,t)||^2$$ 其中，$\\epsilon\\sim N(0, I)$ 表示在时间步 $t$ 采样的纯噪声，$\\epsilon_\\theta(x_t,t)$ 表示构建的神经网络，噪声预测采用 MSE 计算损失。 训练流程 从真实数据分布 $q(x_0)$ 中随机采样 $x_0$； 从 $1\\sim T$ 中均匀随机采样噪声水平/时间步 $t$； 从高斯分布中随机采样噪声 $\\epsilon$ , 并将其直接应用于 $x_0$ 获得 $x_t$； 神经网络基于给定的当前时间步样本 $x_t$ 预测添加的噪声； 计算采样噪声 $\\epsilon$ 与预测的噪声 $\\epsilon_\\theta$ 之间的损失，更新模型参数； Reference The Annotated Diffusion Model","link":"/blog/DeepIntoDDPM/"},{"title":"一个深入研究的实验分析示例——启示与探索","text":"引言通过从事前三个月的研究工作，我逐渐发现，在研究的过程中，最最重要的是，需要非常清楚每一个步骤/环节中结果如何、表现怎样，有没有按照我们的预期进行。这是我们回溯实验结果、分析数据特点、模型特性以及方法有效性的衡量标准，最终得出一条我个人目前的研究路线：发现存在的问题、分析内在的特征然后提出有效的解决方案才是高效的研究路线。 实验探究一——探究同一类别样本的互相似度分布差异实验设置 计算单一样本相似度向量的平均值、最值、方差等分布参数； 观察 TP 样本与 FP 样本，TP 样本与 TN 样本之间差异情况； 实验现象样本分布特性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465Testing the similarities distribution of CLS_SIMindex: 0 nlabel: 0 tlabel: 0 min_sim: 0.4758 mean_sim: 0.7277 std_sim: 0.1334 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0074.jpg[1. 0.81201172 0.75390625 0.8671875 0.75244141 0.87597656 0.56884766 0.70263672 0.75244141 0.4831543 0.47583008 0.68701172 0.66796875 0.70703125 0.73535156 0.80126953]index: 1 nlabel: 0 tlabel: 0 min_sim: 0.5483 mean_sim: 0.7607 std_sim: 0.1154 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0078.jpg[0.81201172 1. 0.70654297 0.87353516 0.75195312 0.83007812 0.61865234 0.70410156 0.75732422 0.55224609 0.54833984 0.80908203 0.80322266 0.73583984 0.78271484 0.88476562]index: 2 nlabel: 0 tlabel: 0 min_sim: 0.5356 mean_sim: 0.7162 std_sim: 0.1057 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0138.jpg[0.75390625 0.70654297 1. 0.72607422 0.59667969 0.71728516 0.58007812 0.79736328 0.80371094 0.53564453 0.65869141 0.68457031 0.6484375 0.75097656 0.79785156 0.70117188]index: 3 nlabel: 0 tlabel: 0 min_sim: 0.5234 mean_sim: 0.7680 std_sim: 0.1165 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0059.jpg[0.8671875 0.87353516 0.72607422 1. 0.80126953 0.90673828 0.64306641 0.72070312 0.74365234 0.60400391 0.5234375 0.72851562 0.72900391 0.77539062 0.76806641 0.87695312]index: 4 nlabel: 0 tlabel: 0 min_sim: 0.4858 mean_sim: 0.6780 std_sim: 0.1206 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0041.jpg[0.75244141 0.75195312 0.59667969 0.80126953 1. 0.73876953 0.54443359 0.64111328 0.671875 0.50927734 0.48583984 0.64453125 0.63574219 0.64941406 0.68261719 0.7421875 ]index: 5 nlabel: 0 tlabel: 0 min_sim: 0.4875 mean_sim: 0.7469 std_sim: 0.1298 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0055.jpg[0.87597656 0.83007812 0.71728516 0.90673828 0.73876953 1. 0.57470703 0.77099609 0.74658203 0.53076172 0.48754883 0.72998047 0.70361328 0.75097656 0.74560547 0.84130859]index: 6 nlabel: 0 tlabel: 39 min_sim: 0.4878 mean_sim: 0.6113 std_sim: 0.1139 ip: /home/zhli/projects/PTNL/data/dtd/images/striped/striped_0122.jpg[0.56884766 0.61865234 0.58007812 0.64306641 0.54443359 0.57470703 1. 0.55371094 0.61279297 0.63964844 0.48779297 0.52099609 0.50976562 0.67724609 0.671875 0.57763672]index: 7 nlabel: 0 tlabel: 0 min_sim: 0.5537 mean_sim: 0.7301 std_sim: 0.1030 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0113.jpg[0.70263672 0.70410156 0.79736328 0.72070312 0.64111328 0.77099609 0.55371094 1. 0.78710938 0.58007812 0.64208984 0.73779297 0.68359375 0.83789062 0.78076172 0.7421875 ]index: 8 nlabel: 0 tlabel: 0 min_sim: 0.5571 mean_sim: 0.7348 std_sim: 0.1003 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0141.jpg[0.75244141 0.75732422 0.80371094 0.74365234 0.671875 0.74658203 0.61279297 0.78710938 1. 0.55712891 0.65283203 0.67626953 0.64257812 0.75732422 0.84619141 0.74902344]index: 9 nlabel: 0 tlabel: 7 min_sim: 0.4702 mean_sim: 0.5970 std_sim: 0.1245 ip: /home/zhli/projects/PTNL/data/dtd/images/cracked/cracked_0102.jpg[0.4831543 0.55224609 0.53564453 0.60400391 0.50927734 0.53076172 0.63964844 0.58007812 0.55712891 1. 0.57177734 0.52539062 0.47021484 0.73925781 0.68701172 0.56689453]index: 10 nlabel: 0 tlabel: 0 min_sim: 0.4758 mean_sim: 0.5924 std_sim: 0.1239 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0117.jpg[0.47583008 0.54833984 0.65869141 0.5234375 0.48583984 0.48754883 0.48779297 0.64208984 0.65283203 0.57177734 1. 0.54980469 0.56298828 0.65332031 0.65429688 0.5234375 ]index: 11 nlabel: 0 tlabel: 0 min_sim: 0.5210 mean_sim: 0.7170 std_sim: 0.1238 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0081.jpg[0.68701172 0.80908203 0.68457031 0.72851562 0.64453125 0.72998047 0.52099609 0.73779297 0.67626953 0.52539062 0.54980469 1. 0.88818359 0.73046875 0.72167969 0.83740234]index: 12 nlabel: 0 tlabel: 0 min_sim: 0.4702 mean_sim: 0.7017 std_sim: 0.1324 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0036.jpg[0.66796875 0.80322266 0.6484375 0.72900391 0.63574219 0.70361328 0.50976562 0.68359375 0.64257812 0.47021484 0.56298828 0.88818359 1. 0.72460938 0.70263672 0.85400391]index: 13 nlabel: 0 tlabel: 0 min_sim: 0.6494 mean_sim: 0.7557 std_sim: 0.0811 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0123.jpg[0.70703125 0.73583984 0.75097656 0.77539062 0.64941406 0.75097656 0.67724609 0.83789062 0.75732422 0.73925781 0.65332031 0.73046875 0.72460938 1. 0.82958984 0.77197266]index: 14 nlabel: 0 tlabel: 0 min_sim: 0.6543 mean_sim: 0.7605 std_sim: 0.0822 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0133.jpg[0.73535156 0.78271484 0.79785156 0.76806641 0.68261719 0.74560547 0.671875 0.78076172 0.84619141 0.68701172 0.65429688 0.72167969 0.70263672 0.82958984 1. 0.76171875]index: 15 nlabel: 0 tlabel: 0 min_sim: 0.5234 mean_sim: 0.7645 std_sim: 0.1226 ip: /home/zhli/projects/PTNL/data/dtd/images/banded/banded_0077.jpg[0.80126953 0.88476562 0.70117188 0.87695312 0.7421875 0.84130859 0.57763672 0.7421875 0.74902344 0.56689453 0.5234375 0.83740234 0.85400391 0.77197266 0.76171875 1. ] 这是我对混杂噪声的 banded 少样本数据集的特点分析，目的是寻找一种更加高效的方法筛选出该类别中干净的样本和噪声的样本，于是我对提出的方法其作用的有效性进行探究，挖掘了该类别的互相似度特征分布，得出以下的分析： 干净样本与噪声样本对比：从各个样本的相似度分布可以看出，干净样本大都具有较高的平均相似度值，噪声样本 index=6, 9 的平均相似度较低； FP 样本：其中 index=10 的干净样本与 index=9 的噪声样本具有相近的平均相似度，这将导致 FP 样本的出现； 相似度向量：干净样本的各相似度向量均普遍较高，但仍存在较低的相似度值；噪声样本的各相似度值均普遍较低； 样本对比 TP Sample of banded Class: index 5 FP Sample of banded Class: index 10 TN Sample of striped Class: index 6 TN Sample of Cracked Class: index 8 当我们的模型推理特别奇怪的时候，一定需要深入的观察到底推理的有多奇怪。 对比 TP 样本和 FP 样本，我发现确实大部分 TP 样本和该 FP 样本，是有一部分差异的：直观地观察，TP 样本更加平整，没有类似这种衣服的折皱以及其他的边角，这可能是由于 Visual Encoder 结构提出特征的能力特别强大，细微的特征也进一步地被反映了出来； 对比 TP 样本和 TN 样本，只有 index=6 的样本有些相似，因此具有较高的相似度值，另外的 TN 样本倒是区别挺大，也是合理的。因此进一步分析观察，我们的模型其实推理也并无特别奇怪，似乎也都在合理之中。 实验结论这一步骤特别重要，我们深入地探究推理的细节、数据特征分布，就是为了明细每一步地性能，以及该如何在哪个环节或哪些结果上做改进，从而进一步提升模型性能。从上面的实验结果分析，其实也是基于计算出的样本数据特征： 仅仅依靠样本平均相似度是不足以支撑筛选噪声标签的（因为我们之前的方法是依据平均平均相似度的）； 可以选定 Top-K 个较优相似度进一步增强噪声样本与干净样本的特征距离，这是因为我们发现干净样本的高相似度值居多，相反，噪声样本的低相似度值居多； 总结当然，这只是一个简单的分析，目的是想跟大家分享一个心得，从发现问题到分析问题这一步骤，该从哪里着手研究。我的最大的感触是一定要深入研究过程，发现问题所在，分析推理结果，才能针对问题提出更有效的 Idea。","link":"/blog/ExperimentalAnalysis/"},{"title":"Genetic Algorithm","text":"算法简介遗传算法（Genetic Algorithm，GA）是一种基于自然选择和遗传操作的随机全局搜索优化算法。它通过模拟自然选择和遗传中发生的复制、交叉(crossover)和变异(mutation)等现象，从任一初始种群（父代）开始，通过随机选择、交叉和变异操作，产生更具有生存优势的子代，使群体不断向搜索空间最优的方向进化，最后收敛到一群最适应环境的个体，从而求得问题的最佳解。 达尔文进化论保留了种群的个体性状，而遗传算法则保留了针对给定问题的候选解集合(即individuals)。这些候选解经过迭代评估 (evaluate)，生成子代解。更优的解有更大的机会被选择，并将其特征传递给下一代候选解集合。 相关概念染色体(Chromosome)/位串(Bit String)个体的表示形式, 对应于遗传学中的染色体. 一条染色体表示为一个二进制串，其中每个位代表一个基因，表征染色体上是否存在该基因。 基因(Gene)基因是染色体中的元素，用于表示个体的特征，用 0 和 1 表示其是否存在于一条染色体上。 特征值(Eigenvalue)在用串表示整数时，基因的特征值与二进制数的权一致，即二进制串的位权一致。 基因型(Genotype) 进化理论：通过基因型表征繁殖和突变，基因型是组成染色体的一组基因的集合。 遗传算法：每个个体都由代表基因集合的染色体构成, 对应于位串(个体均为单染色体型) 表现型(Phenotype)生物体的基因型在特定环境下的表现特征, 对应于GA中的位串解码后的参数. 适应度(Fitness)各个个体对环境的适应程度叫做适应度(fitness)。在算法的每次迭代中，会使用适应度函数/目标函数对个体进行度量评估，得到其适应度值。 种群 (Population)遗传算法保持大量的个体 (individuals) —— 针对当前问题的候选解集合。由于每个个体都由染色体表示，因此这些种族的个体 (individuals) 可以看作是染色体集合： 遗传算子(Genetic Operators) 选择(Selection): 选择操作从种群中概率选择适应度值最高的个体作为父代，生成子代 交叉(Crossover): 交叉操作将父代的两条染色体进行交叉，生成子代随机地将选择的双亲样本的部分染色体互换(交叉)，以生成后代的两个新染色体，也称为基因重组 变异(Mutation): 变异操作将父代的一条染色体进行变异，生成子代。突变操作的目的是定期随机更新种群，将新模式引入染色体以便探索求解空间的未知区域，避免陷入局部最优。 算法原理染色体编码 编码：原问题的解到基因型的映射，即将问题的可行解从其解空间转换到遗传算法的搜索空间 二进制数编码方案：染色体上的基因序列是由二进制表示的 若参数 $U\\in [U_1, U_2]$, 表示为长度 $k$ 的位串, 产生 $2^k$ 个不同基因型 $000\\cdots 000=0\\rightarrow U_1$ $000\\cdots 001=1\\rightarrow U_1+\\delta$ $000\\cdots 010=2\\rightarrow U_1+2\\delta$ $\\vdots$ $111\\cdots 111=2^k-1\\rightarrow U_2$ 其中，$\\delta = \\frac{U_2-U_1}{2^k-1}$ 解码：将染色体上的基因序列转换为原问题的可行解$$U = U_1 + (\\sum^k_{i=1}b_i\\cdot2^{i-1})\\cdot\\frac{U_2-U_1}{2^k-1}$$其中，$(\\sum^k_{i=1}b_i\\cdot2^{i-1})$表示将基因位串按权展开，进一步将其转换为原可行解 初始种群在遗传算法中, 需要随机初始化一个待进化种群 $P_0$, 并配置参数: 最大进化代数$T$，群体大小 $M$, 交叉概率 $P_c$, 变异概率 $P_m$. 适应度尺度变换在算法迭代过程中，利用适应度函数计算出每个个体的适应度值，但是由于其相对于原问题的目标函数可能存在群体间适应度相当而造成的竞争减弱，导致种群收敛于局部最优解。 因此，需要对适应度值进行尺度变换，以增强种群间的竞争能力，常用的经典方法有: 线性尺度变换、乘幂尺度变换以及指数尺度变换 线性尺度变换$$F’ = aF+b$$其中，$a$为缩放系数，$b$为平移系数，$F$为变换前适应度值，$F’$为变换后适应度值。 乘幂尺度变换$$F’ = F^k$$其中, $k$ 为幂次，$F$为变换前适应度值，$F’$为变换后适应度值。 指数尺度变换$$F’ = e^{-\\beta F}$$其中，$\\beta$ 的大小决定了适应度尺度变换的强弱. 选择操作选择操作从旧群体中以一定概率选择优良个体组成新的种群，以繁殖得到下一代个体。个体被选中的概率跟适应度值有关，个体适应度值越高，被选中的概率越大。$$P_i = \\frac{F_i}{\\sum^M_{j=1}F_j}$$ 交叉操作交叉操作是指从种群中随机选择两个个体，依概率对两个染色体进行交换组合，把父串基因序列遗传给子串，从而产生新的个体。 单点交叉算子: 该算子在配对的染色体中随机的选择一个交叉位置，然后在该交叉位置对配对的染色体进行基因位变换 变异操作为了防止遗传算法在优化过程中陷入局部最优解，在搜索过程中需要对个体进行变异，以探索新的解空间。 单点变异算子：对基因序列中某一个位进行变异，随机变异为进制中其他一位 终止条件 算法已迭代到最大代数，主要用于限制运行时间和计算资源 种群个体没有明显的改进，当代种群最佳适应度值与父代种群最佳适应度值相比，其差异小于某个阈值，则算法可以停止 应用实践Configure Running Environment12# prepare corresponding environmentimport numpy as np Parameters for Genetic Algorithm Setting the crossover probability to 1 ensures adequate evolution of the population In general, variation is less likely to occur, so a variation rate of 0.005 is set 12345678910# Set parameters for Genetic AlgorithmGENE_SIZE = 48 # Gene lengthPOP_SIZE = 200 # Population sizeCROSSOVER_RATE = 1 # Crossover rateMUTATION_RATE = 0.005 # Mutation rateN_GENERATIONS = 50 # Maximum generations# Set parameters for optimization problemsX_BOUND = [-3, 3]Y_BOUND = [-3, 3] Objective Function$$F(x, y) = 3\\times (1-x)^2\\times e^{-[x^2+(y+1)^2]}-10\\times (\\frac{x}{5}-x^3-y^5)\\times e^{-x^2-y^2}-\\frac{1}{3^{e^{-(x+1)^2-y^2}}}$$ 123# define object functiondef F(x, y): return 3*(1-x)**2*np.exp(-(x**2)-(y+1)**2)- 10*(x/5 - x**3 - y**5)*np.exp(-x**2-y**2)- 1/3**np.exp(-(x+1)**2 - y**2) Coding Strategy Parameters Demonstrate pop represents the population matrix: A row represents a binary code represents DNA The number of rows of the matrix is the number of populations Odd columns represent X Even columns represent Y 123456789def TranslateDNA(pop): x_pop = pop[:,1::2] y_pop = pop[:,::2] Gene_Size = GENE_SIZE / 2 # pop:(POP_SIZE, GENE_SIZE)*(GENE_SIZE,1) --&gt; (POP_SIZE,1) x = x_pop.dot(2**np.arange(Gene_Size)[::-1])/float(2**Gene_Size-1)*(X_BOUND[1]-X_BOUND[0])+X_BOUND[0] y = y_pop.dot(2**np.arange(Gene_Size)[::-1])/float(2**Gene_Size-1)*(Y_BOUND[1]-Y_BOUND[0])+Y_BOUND[0] return x, y Crossover and Mutation1234567891011121314151617181920212223242526272829def Mutation(child, Mutation_Rate=0.003): # Mutation with Mutation_Rate probability if np.random.rand() &lt; Mutation_Rate: # Randomly generate an mutation location mutate_point = np.random.randint(0, GENE_SIZE) # Inverts the binary bit of the mutation point child[mutate_point] = child[mutate_point] ^ 1def CrossoverMutation(pop, Crossover_Rate=0.8): new_pop = [] # Traverse each individual in the population, taking that individual as the father for father in pop: child = father # The child first gets all the genes of the father # Crossover occurs with a certain probability when producing offspring if np.random.rand() &lt; Crossover_Rate: # Another individual is selected in the population and that individual is taken as the mother mother = pop[np.random.randint(POP_SIZE)] # Randomly generate an intersection cross_points = np.random.randint(low=0, high=GENE_SIZE) # The child gets the mother's genes located behind the intersection child[cross_points:] = mother[cross_points:] # Each child has a certain chance of mutating Mutation(child, MUTATION_RATE) new_pop.append(child) return new_pop Calculate Fitness of New Population Subtracting the minimum fitness is to prevent negative fitness In this way, wa can gurantee the range of fitness is [0, np.max(pred) - np.min(pred)] Add a small number to prevent the appearance of fitness to 0 1234def GetFitness(pop): x, y = TranslateDNA(pop) pred = F(x, y) # Calculate objective value return (pred - np.min(pred)) + 1e-3 Select New Population12345# nature selection according to pop's fitnessdef SelectPop(pop, fitness): idx = np.random.choice(np.arange(POP_SIZE), size=POP_SIZE, replace=True, p=(fitness) / (fitness.sum()) ) return pop[idx] Print Results12345678def Print_Info(pop): fitness = GetFitness(pop) max_fitness_index = np.argmax(fitness) print(&quot;Max_Fitness:&quot;, fitness[max_fitness_index]) x, y = TranslateDNA(pop) print(&quot;Optimal gene:&quot;, pop[max_fitness_index]) print(&quot;(x, y):&quot;, (x[max_fitness_index], y[max_fitness_index])) print(&quot;Optimal value:&quot;, F(x[max_fitness_index], y[max_fitness_index])) Run GA12345678910111213def GeneticAlgorithm(): # initial population pop = np.random.randint(2, size=(POP_SIZE, GENE_SIZE)) for _ in range(N_GENERATIONS): pop = np.array(CrossoverMutation(pop, CROSSOVER_RATE)) fitness = GetFitness(pop) pop = SelectPop(pop, fitness) Print_Info(pop)if __name__ == '__main__': GeneticAlgorithm() Running Results12345Max_Fitness: 0.08738358838357263Optimal gene: [1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0](x, y): (-0.028632940568503074, 1.499641925075169)Optimal value: 7.052501227315164 References 遗传算法(Genetic Algorithm, GA)详解与实现","link":"/blog/GeneticAlgorithm/"},{"title":"A Graph Plot Tool that Integrates Data Processing And Visualization","text":"Project Introduction Project Repo: GraphPlotting This is an accumulated project that will record every plotted figure in the past projects. The sense of accumulation and archiving is worth encouraging! Each time when we want to fast plot a fantastic figure to show the results of our experiments, we need to spend a lot of time to process the data and adjust the parameters of the figure. This project is to solve this problem. We can use this project to quickly plot the figure we want, and then adjust the parameters of the figure according to our needs. And every you create a new figure, you can save it in the project folder, so that you can use it later. This is what the archiving means. In the following, I list some good examples about using this tool. Robust Prompt Learning A whole analysis about results A continuous progress to analysis Project Environments123456789101112131415161718&quot;&quot;&quot;@author: Zhihao Li@date: 2024-11-16@homepage: https://zhihaoli.top/&quot;&quot;&quot;import osimport numpy as npimport pandas as pdfrom sklearn.preprocessing import Normalizerimport seaborn as snsimport matplotlib.pyplot as pltfrom matplotlib.font_manager import FontPropertiesimport warningswarnings.filterwarnings('ignore') Data Processor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class DataProcessor: # Initialize the configuration of Data Preprocessing def __init__(self): self.data = None def LoadData(self, data_path, sheet_name=0, sep=',', header=0, index_col=None): &quot;&quot;&quot;LoadData Function Input: data_path: the path of data file sheet_name: the table of Excel file sep: the separate sign of csv file header: the row of column names index_col: the index column of data file Output: self.data: the data read from given data file Function: From given source to reach the needed data. &quot;&quot;&quot; if data_path.split('.')[-1] in ('xlsx', 'xls'): self.data = pd.read_excel(data_path, sheet_name=sheet_name, header=header, index_col=index_col) elif data_path.split('.')[-1] == 'csv': self.data = pd.read_csv(data_path, sep=sep, header=header, index_col=index_col) else: raise Exception('Unknown data file type!') self.PrintData() def DataProcessing(self, date_name=None, fill_name=None, fill_method=&quot;Nearest&quot;, standard_name=None, standard_method=&quot;Zscore&quot;): &quot;&quot;&quot;DataProcessing Function Input: date_name: the column need to be converted to date style fill_name: the columns need to fill the missing values fill_method: the methods used to fill the missing values, alternatives like &quot;Nearest&quot;(default), &quot;Linear&quot;, &quot;Polynomial&quot;, &quot;Spline&quot;, &quot;Mean&quot;, &quot;Ffill&quot;, &quot;Bfill&quot;, other specific value. standard_name: the columns need to standardized standard_method: the methods used to standardize the columns, alternatives like &quot;Zscore&quot;(default), &quot;Minmax&quot;. Output: self.data: the data has been transformed Function: Process the data got from dat file by filling the missing values and standardize some columns. &quot;&quot;&quot; if date_name is not None: # Assuming the date_name column has be converted to the format like &quot;2024-1-31&quot; self.data[date_name] = pd.to_datetime(self.data[date_name]) if fill_name is not None: if fill_method == &quot;Nearest&quot;: self.data[fill_name] = self.data[fill_name].interpolate(method=&quot;nearest&quot;) elif fill_method == &quot;Linear&quot;: self.data[fill_name] = self.data[fill_name].interpolate(method=&quot;linear&quot;) elif fill_method == &quot;Polynomial&quot;: self.data[fill_name] = self.data[fill_name].interpolate(method=&quot;polynomial&quot;, order=2) elif fill_method == &quot;Spline&quot;: self.data[fill_name] = self.data[fill_name].interpolate(method=&quot;spline&quot;, order=2) elif fill_method == &quot;Mean&quot;: self.data[fill_name] = self.data[fill_name].fillna(self.data[fill_name].mean()) elif fill_method == &quot;Ffill&quot;: self.data[fill_name] = self.data[fill_name].fillna(method=&quot;ffill&quot;) elif fill_method == &quot;Bfill&quot;: self.data[fill_name] = self.data[fill_name].fillna(method=&quot;bfill&quot;) else: self.data[fill_name] = self.data[fill_name].fillna(int(fill_method)) if standard_name is not None: stdata = self.data[standard_name] if standard_method == &quot;Zscore&quot;: self.data[standard_name] = (stdata - stdata.mean()) / stdata.std() elif standard_method == &quot;Minmax&quot;: self.data[standard_name] = (stdata - stdata.min()) / (stdata.max() - stdata.min()) self.PrintData() def PrintData(self): &quot;&quot;&quot;A function to print out the loaded dataframe. Output the length of data, the first 5 elements and last 5 elements of data. &quot;&quot;&quot; print(&quot;&gt;&gt;&gt; Data Length: %d&quot; % (len(self.data))) print(f&quot;&gt;&gt;&gt; Data Head:\\n{self.data.head()}&quot;) print(f&quot;&gt;&gt;&gt; Data Tail:\\n{self.data.tail()}&quot;) Data Visualization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899class GraphPlotTool(DataProcessor): # Initialize the configuration of GraphPlot Tool def __init__(self, fname1=&quot;times.ttf&quot;, fname2=&quot;ARLRDBD.TTF&quot;): super().__init__() # Set up Seaborn style sns.set(style=&quot;whitegrid&quot;) # Fonts style self.title_fontsize = 12 self.label_fontsize = 10 self.fname1 = &quot;../fonts/&quot; + fname1 self.fname2 = &quot;../fonts/&quot; + fname2 self.digit_fontprop = FontProperties(fname=self.fname1) self.title_fontprop = FontProperties(fname=self.fname2) self.legend_fontprop = FontProperties(fname=self.fname2) # Set colors self.colors_name = ['yellow', 'blue', 'green', 'magenta', 'red', 'cyan', 'purple', 'orange', 'gray', 'pink'] self.colors_rgb = ['#f94144', '#f3722c', '#f8961e', '#f9844a', '#f9c74f', '#90be6d', '#43aa8b', '#4d908e', '#577590', '#277da1'] self.figsize = (12, 4) self.dpi = 500 def HistKdePlot(self, image_name, data_name, data_clean, data_noisy, output_dir): &quot;&quot;&quot; Plot a Histgram compared to a Kde according by row. params: image_name: the name of image file. data_names: a string list has the shape of (rows, cols). data_clean: a sub-dataset in a sub-graph. data_noisy: another sub-dataset in a sub-graph. output_dir: the directory to save the images. &quot;&quot;&quot; fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=self.dpi) # histplot for sub-figure1 sns.histplot(data_clean, color=&quot;blue&quot;, label=&quot;Clean&quot;, kde=False, stat=&quot;probability&quot;, bins=20, alpha=0.6, ax=axes[0]) sns.histplot(data_noisy, color=&quot;red&quot;, label=&quot;Noisy&quot;, kde=False, stat=&quot;probability&quot;, bins=20, alpha=0.6, ax=axes[0]) axes[0].set_title(f'{data_name} Density (Histogram)', fontproperties=self.title_fontprop, fontsize=self.title_fontsize+2) axes[0].set_xlabel(r'$L_{Divide}$', fontproperties=self.title_fontprop, fontsize=self.label_fontsize+2) axes[0].set_ylabel('Probability Density', fontproperties=self.title_fontprop, fontsize=self.label_fontsize+2) axes[0].legend(prop=self.legend_fontprop) # kdeplot for sub-figure2 sns.kdeplot(data_clean, color=&quot;blue&quot;, label=&quot;Clean&quot;, fill=True, ax=axes[1], alpha=0.3) sns.kdeplot(data_noisy, color=&quot;red&quot;, label=&quot;Noisy&quot;, fill=True, ax=axes[1], alpha=0.3) axes[1].set_title(f'{data_name} Density (KDE)', fontproperties=self.title_fontprop, fontsize=self.title_fontsize+2) axes[1].set_xlabel(r'$L_{Divide}$', fontproperties=self.title_fontprop, fontsize=self.label_fontsize+2) axes[1].set_ylabel('Probability Density', fontproperties=self.title_fontprop, fontsize=self.label_fontsize+2) axes[1].legend(prop=self.legend_fontprop) plt.tight_layout() folder_path = os.path.join(output_dir) if not os.path.exists(folder_path): os.makedirs(folder_path) plt.savefig(os.path.join(folder_path, f&quot;{image_name}.png&quot;), format=&quot;png&quot;) plt.show() def HistComparePlot(self, image_name, data_names, data_clean, data_noisy, output_dir): &quot;&quot;&quot; Plot multiple Histgrams to compare by row. params: image_name: the name of image file. data_names: a string list has the shape of (rows, cols). data_clean: a sub-dataset in a sub-graph. data_noisy: another sub-dataset in a sub-graph. output_dir: the directory to save the images. &quot;&quot;&quot; rows, cols = len(data_names), len(data_names[0]) legend_fontprop = FontProperties(fname=self.fname2, size=8) fig, axes = plt.subplots(rows, cols, figsize=(12, 4), dpi=self.dpi) for row in range(rows): for col in range(cols): sub_clean, sub_noisy = data_clean[row][col], data_noisy[row][col] # histplot for sub-figure sns.histplot(sub_clean, color=&quot;blue&quot;, label=&quot;Clean&quot;, kde=False, stat=&quot;probability&quot;, bins=20, alpha=0.6, ax=axes[row, col]) sns.histplot(sub_noisy, color=&quot;red&quot;, label=&quot;Noisy&quot;, kde=False, stat=&quot;probability&quot;, bins=20, alpha=0.6, ax=axes[row, col]) axes[row, col].set_title(f'{data_names[row][col]}', fontproperties=self.title_fontprop, fontsize=self.title_fontsize) axes[row, col].set_xlabel('') axes[row, col].set_ylabel('') axes[row, col].legend(prop=legend_fontprop) for col in range(cols): axes[1, col].set_xlabel(r'$Score_{BLIP}$', fontproperties=self.title_fontprop, fontsize=self.label_fontsize) for row in range(rows): axes[row, 0].set_ylabel('Probability Density', fontproperties=self.title_fontprop, fontsize=self.label_fontsize) plt.tight_layout() # save the image folder_path = os.path.join(output_dir) if not os.path.exists(folder_path): os.makedirs(folder_path) plt.savefig(os.path.join(folder_path, f&quot;{image_name}.png&quot;), format=&quot;png&quot;) plt.show() Contributors Zhihao Li","link":"/blog/GraphPlotTool/"},{"title":"Solution to OpenSSL Connection Problems With Github","text":"Problems Uploading Files with GitSometimes we can use git tool to successfully upload projects to Github, but in other time especially after a period of configuration, we often meet the following error:OpenSSL SSL_read: Connection was reset, error 10054So this post is written to demonstrate this bug and give some solutions. What’s the OpenSSLFirstly, in the course of Computer Network, we had learned the HTTPS(Hypertext Transfer Protocol Secure) which works as authentication between client and server for data transmission. And the service of HTTPS works on SSL/TLS protocol.SSL/TLS is a protocol for establishing a secure connection between a client and a server. It is used for authentication, encryption, and integrity check. Therefore, OpenSSL is a software library for implementing the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols. The Relationship Between OpenSSL and IP AddressMany web servers and services use OpenSSL to secure communication over IP addresses. When you access a website via its IP address (e.g., an HTTPS website), OpenSSL may be used to encrypt and secure the data exchange.SSL/TLS certificates, managed and validated by OpenSSL, are tied to specific domain names and IP addresses. When a client connects to a server using an IP address, the server’s SSL/TLS certificate must match that IP address. What’s Wrong with the GithubAt the same time, Github uses OpenSSL to secure communication over IP addresses. But what the most import thing is that GitHub, like many other online services, may periodically change its IP addresses for various reasons, including security, network optimization, and load balancing.In this case, if you use the previous IP address to access GitHub, you may encounter the above error. How to Solve the ProblemI. Check your Ip address of Github domain name in hosts file 123140.82.112.4 github.com199.232.69.194 github.global.ssl.fastly.net140.82.114.9 codeload.Github.com We can utilize this website https://www.ipaddress.com/ip-lookup to check whether the IP address corresponds with its domain name. II. Refresh DNS using PowerShell tools on your computer 1ipconfig /flushdns III. Deactivate SSL authenticationIf the above steps don’ work, we have to deactivate SSL authentication which is not advised sometimes. 1git config --global http.sslVerify &quot;false&quot;","link":"/blog/OpenSSLConnectionWithGithub/"},{"title":"Connect the Linux Server By Private Key in WinSCP Software","text":"Introduction of WinSCPWinSCP (Windows Secure Copy) is a free and open-source graphical SFTP (SSH File Transfer Protocol), SCP (Secure Copy Protocol), FTP (File Transfer Protocol), and WebDAV (Web Distributed Authoring and Versioning) client for the Windows operating system. It allows users to securely transfer files between a local computer and a remote computer. User Account GenerateSometimes, the linux server only uses public key to generate user account instead of IP address and password so we need to generate the private key first. Generate the Private KeyOpen the git terminal and run the following command: 1ssh-keygen -t rsa After running, we can get the id_rsa file in the .ssh directory and the id_rsa.pub file in the same directory. Add the Public Key to the ServerOnce got the public key, we can just use it to create a new user account on the server. The following command is used to add the public key to the server. 1ssh-copy-id -i ~/.ssh/id_rsa.pub zhli@cwfang.tpddns.cn WinSCP Configuration Firstly, we need to open the WinSCP and click the ‘Tools’ button to Run PuTTYgen: Then, click Load button to find previously generated private key file(id_rsa): There when we choose the key file, it’s necessary to switch target file type to All Files(*.*) for matching. After that, just wait for processing and finally we can Save private key in the format of .ppk: .ppk format is a need for WinSCP to obtain the local computer’s authorization to the linux server. Config the private key in WinSCP globallyIn Advanced module we can find the Authentication interface used for SSH connection. In this module, Private key fileis used to select the private key file ending with .ppk format. The generated .ppk file is just our private key file and it is used to match the public key file in the linux server. In this way, we can just use WinSCP to upload the file to the linux server. WinSCP ConnectionFinishing above steps, it’s just time to use WinSCP to connect to the linux server. In WinSCP, we can find the Session interface to set up the connection. In Session interface, we can set up the connection information, including the server domain(Host name), username, password, port.","link":"/blog/SSHPrivateKey/"},{"title":"A Lightweight Designed Beamer Template of Weekly Survey","text":"IntroductionNowadays, I’m working on a weekly report for my research group. Finding a concise and academic slides template is a need for us to represent our finds and ideas. Based on the PKU_beamer_lightweight_designed, I adjust some details according to my preference and share the tutorial in this post. Adjusted DetailsThis a lightweight designed beamer template of weekly survey with the version of Xidian University, which is useful for reporting your research work academically and concisely. Theme ColorI use the official red color of Xidian University as the theme color. The hex code of the color is #B0252A. Main FontI prefer the fontstyle of Times New Roman so I need to additionally include fontspec package.12\\usepackage{fontspec}\\setsansfont{Times New Roman} Remove Specific Frame From the HealineIn beamer, the default frames will be counted in the headline which is sometimes not suitable. Such as the title page, overline page and so on are usually independent pages. To remove them from the headline, I use the following code. configuration123456789101112\\makeatletter\\let\\beamer@writeslidentry@miniframeson=\\beamer@writeslidentry%\\def\\beamer@writeslidentry@miniframesoff{% \\expandafter\\beamer@ifempty\\expandafter{\\beamer@framestartpage}{}% does not happen normally {%else % removed \\addtocontents commands \\clearpage\\beamer@notesactions% }}\\newcommand*{\\miniframeson}{\\let\\beamer@writeslidentry=\\beamer@writeslidentry@miniframeson}\\newcommand*{\\miniframesoff}{\\let\\beamer@writeslidentry=\\beamer@writeslidentry@miniframesoff}\\makeatother Before those frames, we just turn off the frames style but if we next to count frame we also need to open this by the command of \\miniframeson. And the section*{} ensures the frame removes the number in some section. usage1234567\\miniframesoff\\begin{frame} \\section*{} \\begin{center} {\\Huge \\textit{Thanks for you3fr listening!}} \\end{center}\\end{frame} XidianU.sty CodesXidianU.sty123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133\\mode&lt;presentation&gt;\\newif\\ifbeamer@secheader\\beamer@secheaderfalse\\ProcessOptionsBeamer\\useoutertheme[subsection=false]{smoothbars}\\makeatletter\\newcommand{\\frameofframes}{/}\\newcommand{\\setframeofframes}[1]{\\renewcommand{\\frameofframes}{#1}}\\setbeamertemplate{footline} {% \\begin{beamercolorbox}[colsep=1.5pt]{upper separation line foot} \\end{beamercolorbox} \\begin{beamercolorbox}[ht=2.5ex,dp=1ex,% leftskip=.3cm,rightskip=.3cm plus1fil]{author in head/foot}% {\\usebeamerfont{author in head/foot}\\insertshortauthor}% \\hfill% {\\usebeamerfont{title in head/foot}\\insertshorttitle}% \\hfill% {\\usebeamerfont{frame number}\\usebeamercolor[fg]{frame number}\\insertframenumber~\\frameofframes~\\inserttotalframenumber} \\end{beamercolorbox}% \\begin{beamercolorbox}[colsep=1.5pt]{lower separation line foot} \\end{beamercolorbox} }\\makeatother\\useinnertheme{circles}%\\useinnertheme{rectangles}%\\useoutertheme{default}%\\useinnertheme[shadow=true]{rounded}\\definecolor{xidian}{HTML}{B0252A}% \\xdefinecolor{xidian}{cmyk}{0,1,1,0.45}%{rgb}{0.543,0.0,0.0703} %{cmyk}{0,100,100,45}%{rgb}{0.5,0.0,0.0} %RGB#820010\\xdefinecolor{xidian_gold}{cmyk}{0,0.35,0.75,0.05}\\xdefinecolor{xidian_blue}{cmyk}{0.6,0.35,0.0,0.4}\\xdefinecolor{xidian_darkblue}{cmyk}{1.0,0.6,0.0,0.5}\\xdefinecolor{xidian_gray}{cmyk}{0.0,0.0,0.08,0.55}\\xdefinecolor{xidian_dirt}{cmyk}{0.0,0.2,0.35,0.3}\\xdefinecolor{xidian_orange}{cmyk}{0.0,0.7,1.0,0.0}\\xdefinecolor{xidian_green}{cmyk}{0.2,0.0,1.0,0.15}\\xdefinecolor{xidian_darkgreen}{cmyk}{0.6,0.5,1.0,0.45}\\xdefinecolor{pantone_gold}{RGB}{135,103,79}\\xdefinecolor{pantone_silver}{RGB}{138,141,143}\\xdefinecolor{WM_Gold}{cmyk}{0.09,0.29,0.66,0.24}\\setbeamercolor{footline}{bg=xidian}%\\setbeamercolor{frametitle}{bg=white!70!pantone_gold,fg=xidian}\\setbeamercolor{frametitle}{bg=white,fg=xidian}\\setbeamercolor{title}{bg=xidian}%\\setbeamerfont{frametitle}{size=\\large}\\setbeamerfont{frametitle}{series=\\bfseries,size=\\large}%,parent=structure}\\setbeamerfont{footline}{series=\\bfseries}\\setbeamertemplate{navigation symbols}{}\\setbeamertemplate{bibliography item}[text]\\setbeamertemplate{caption}[numbered]\\beamertemplateshadingbackground{white!5}{white}\\setbeamercolor{palette primary}{use=structure,fg=white,bg=structure.fg}\\setbeamercolor{palette secondary}{use=structure,fg=white,bg=structure.fg!95!black}%{use=structure,fg=white,bg=structure.fg!90!black}\\setbeamercolor{palette tertiary}{use=structure,fg=white,bg=structure.fg!90!black}\\setbeamercolor{palette quaternary}{fg=white,bg=structure.fg!85!black}%\\setbeamercolor*{sidebar}{use=structure,bg=structure.fg}\\setbeamercolor{titlelike}{parent=palette primary}%% try\\setbeamercolor{block title}{bg=xidian_blue,fg=white}\\setbeamercolor{block body}{bg=xidian_blue!10}\\BeforeBeginEnvironment{definition}{% \\setbeamercolor{block title}{bg=xidian_blue,fg=white} \\setbeamercolor{block body}{bg=xidian_blue!10}}\\AfterEndEnvironment{definition}{ \\setbeamercolor{block title}{bg=xidian_blue,fg=white} \\setbeamercolor{block body}{bg=xidian_blue!10}}\\BeforeBeginEnvironment{theorem}{% \\setbeamercolor{block title}{bg=xidian_orange,fg=white} \\setbeamercolor{block body}{bg=xidian_orange!10}}\\AfterEndEnvironment{theorem}{ \\setbeamercolor{block title}{bg=xidian_blue,fg=white} \\setbeamercolor{block body}{bg=xidian_blue!10}}\\BeforeBeginEnvironment{proposition}{% \\setbeamercolor{block title}{bg=xidian_orange,fg=white} \\setbeamercolor{block body}{bg=xidian_orange!10}}\\AfterEndEnvironment{proposition}{ \\setbeamercolor{block title}{bg=xidian_blue,fg=white} \\setbeamercolor{block body}{bg=xidian_blue!10}}\\setbeamercolor*{block title example}{use={normal text,example text},bg=white!70!pantone_gold,fg=xidian}\\setbeamercolor{fine separation line}{}\\setbeamercolor{item projected}{fg=white}\\setbeamercolor{palette sidebar primary}{use=normal text,fg=normal text.fg}\\setbeamercolor{palette sidebar quaternary}{use=structure,fg=structure.fg}\\setbeamercolor{palette sidebar secondary}{use=structure,fg=structure.fg}\\setbeamercolor{palette sidebar tertiary}{use=normal text,fg=normal text.fg}%\\setbeamercolor{palette sidebar quaternary}{fg=white}\\setbeamercolor{section in sidebar}{fg=brown}\\setbeamercolor{section in sidebar shaded}{fg=grey}\\setbeamercolor{separation line}{}\\setbeamercolor{sidebar}{bg=xidian}\\setbeamercolor{sidebar}{parent=palette primary}\\setbeamercolor{structure}{fg=xidian}\\setbeamercolor{subsection in sidebar}{fg=brown}\\setbeamercolor{subsection in sidebar shaded}{fg=grey}\\AtBeginSection[]{ \\begin{frame} \\tableofcontents[sectionstyle=show/shaded,subsectionstyle=hide,subsubsectionstyle=hide] \\end{frame}} \\setbeamercolor{postgreen}{fg=black,bg=example text.fg!75!black!10!bg}\\setbeamercolor{postred}{fg=black,bg=white!70!pantone_gold}\\setbeamercolor{postblue}{fg=black,bg=xidian_blue!10}%\\AtBeginSubsection[]{% \\begin{frame}% \\tableofcontents[sectionstyle=show/shaded,subsectionstyle=hide,subsubsectionstyle=hide]% \\end{frame}%}\\mode&lt;all&gt; main.texmain.tex123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190\\documentclass[10pt,hyperref={colorlinks,citecolor=blue,urlcolor=xidian_blue,linkcolor=}]{beamer}\\usepackage{XidianU}\\usepackage{fontspec}\\setsansfont{Times New Roman}\\usepackage{lipsum}%\\usepackage[scheme = plain]{ctex}\\usepackage{charter} % Nicer fonts% other packages\\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}\\usepackage{amssymb}\\usepackage{graphicx}\\usepackage{subcaption}\\usepackage{bm}\\usepackage{natbib}\\usepackage{wrapfig}\\usepackage{amsfonts} \\usepackage{ragged2e}\\usepackage{parskip}\\apptocmd{\\frame}{}{\\justifying}{} % Allow optional arguments after frame.\\newcommand{\\theHalgorithm}{\\arabic{algorithm}}\\theoremstyle{plain}\\newtheorem{axiom}{Axiom}\\newtheorem{claim}[axiom]{Claim}\\newtheorem{assumption}{Assumption}\\newtheorem{remark}{Remark}\\newtheorem{proposition}{Proposition}\\setbeamertemplate{theorems}[numbered]% change for your title page information\\author[Zhihao Li]{Zhihao Li}\\title{Research Survey 1}\\subtitle{Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?}\\institute{School of Computer Science and Technology\\\\Xidian University}\\date{February 1, 2024}% official colors match with the Xidian color\\def\\cmd#1{\\texttt{\\color{red}\\footnotesize $\\backslash$#1}}\\def\\env#1{\\texttt{\\color{blue}\\footnotesize #1}}\\definecolor{deepblue}{rgb}{0,0,0.5}\\definecolor{deepred}{rgb}{0.6,0,0}\\definecolor{deepgreen}{rgb}{0,0.5,0}\\definecolor{halfgray}{gray}{0.55}\\show\\hss\\makeatletter\\let\\beamer@writeslidentry@miniframeson=\\beamer@writeslidentry%\\def\\beamer@writeslidentry@miniframesoff{% \\expandafter\\beamer@ifempty\\expandafter{\\beamer@framestartpage}{}% does not happen normally {%else % removed \\addtocontents commands \\clearpage\\beamer@notesactions% }}\\newcommand*{\\miniframeson}{\\let\\beamer@writeslidentry=\\beamer@writeslidentry@miniframeson}\\newcommand*{\\miniframesoff}{\\let\\beamer@writeslidentry=\\beamer@writeslidentry@miniframesoff}\\makeatother\\begin{document}{\\begin{frame} \\titlepage \\begin{figure}[htpb] \\begin{center} \\includegraphics[width=0.2\\linewidth]{Figures/XDUlogo.jpg} \\end{center} \\end{figure}\\end{frame}}\\section{Summary}\\begin{frame}{Weekly Work}\\begin{enumerate} \\item Read the paper of \\textit{Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?}; \\item Learn about some concepts;\\end{enumerate}\\end{frame}\\begin{frame}{A prompt tuning process is highlyrobust to label noises.}\\begin{enumerate} \\item \\textbf{Interest}: Studying the key reasons contributing to the robustness of the prompt tuning.paradigm. \\item \\textbf{Findings}: \\begin{enumerate} \\item the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; \\item the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. \\end{enumerate}\\end{enumerate}\\end{frame}\\begin{frame}{Author's Contributions} \\begin{itemize} \\item We demonstrate that \\textbf{prompt tuning for pre-trained vision-language models (e.g., CLIP) is more robust to noisy labels} than traditional transfer learning approaches, such as model fine-tuning and linear probes. \\item We further demonstrate that \\textbf{prompt tuning robustness can be further enhanced through the use of a robust training objective.} \\item We conduct an extensive analysis on why prompt tuning is robust to noisy labels to \\textbf{discover which components contribute the most to its robustness.} \\item We \\textbf{propose a simple yet effective method for unsupervised prompt tuning}, showing that randomly selected noisy pseudo labels can be effectively used to enhance CLIP zero-shot performance. The proposed robust prompt tuning outperformed prior work on a variety of datasets, even though noisier pseudo-labels are used for self-training. \\end{itemize}\\end{frame}\\section{Motivations}\\begin{frame}{Mathematical Models} \\begin{itemize} \\item CLIP\\\\ In the case of image classification, a normalized image embedding $\\boldsymbol{f}^{\\:v}$ is obtained by passing an image through CLIP's visual encoder, and a set of normalized class embeddings $[\\boldsymbol{f_i^{\\:t}}]_{i=1}^K$ by feeding template prompts of the form &quot;A photo of a&quot; into CLIP's text encoder. \\begin{equation} Pr(y=i|\\boldsymbol{x})=\\frac{\\exp(sim(\\boldsymbol{f}^{\\:v},\\boldsymbol{f}^{\\:t}_i))/\\tau}{\\sum_{j=1}^K\\exp(sim(\\boldsymbol{f}^{\\:v},\\boldsymbol{f}^{\\:t}_j))/\\tau} \\end{equation} \\item Prompt Tuning\\\\ The name of a class c is first converted into a classname embedding $\\boldsymbol{w}\\in R^d$ and prepended with a sequence of $M$ learnable tokens $\\boldsymbol{p_m}\\in R^d$ shared across all classes. \\begin{equation} P_c=[\\boldsymbol{p_1}, \\boldsymbol{p_2}, \\cdots, \\boldsymbol{p_M}, \\boldsymbol{w_c}]\\rightarrow \\boldsymbol{f}^{\\:t}_c \\end{equation} CoOp optimizes the shared learnable tokens $\\boldsymbol{p_1}, \\boldsymbol{p_1}, \\cdots, \\boldsymbol{p_M}$ on a small labeled dataset $D = [(\\boldsymbol{x_i}, c_i)^N_{i=1}]$ to minimize the cross-entropy loss: \\begin{equation} L_{CE}=-E_{(\\boldsymbol{x},c)\\in D}[\\log Pr(y=c|\\boldsymbol{x})] \\end{equation} \\end{itemize}\\end{frame}\\begin{frame}{Mathematical Models} \\begin{itemize} \\item Robust Prompt Tuning\\\\ Further enhance this robustness by optimizing the learnable prompts using the generalized cross-entropy (GCE) loss: \\begin{equation} L_{GCE}=E_{(\\boldsymbol{x},c)\\in D}[\\frac{1-Pr(y=c|\\boldsymbol{x})^q}{q}] \\end{equation} \\item Author's Conclusion: $q = 0.7$ leads to overall good performance across several experimental settings. \\end{itemize}\\end{frame}\\section{Robustness Analysis}\\begin{frame}{Pre-trained CLIP Generates Effective Class Embeddings} \\vspace{-1em} \\begin{figure} \\includegraphics[width=0.9\\textwidth]{Figures/Survey1/models.png} \\label{fig: Models} \\end{figure}\\vspace{-0.7em} \\begin{itemize} \\item Classifier-R v.s. Classifier-C: CLIP class embeddings provide a strong initialization for few-shot learning.\\vspace{-0.5em} \\item TEnc-FT v.s. Classifier-C: The highly expressive CLIP text encoder can easily overfit to the noisy labels.\\vspace{-0.5em} \\item Prompt Tuning v.s. Classifiers: The text encoder is essential for providing a strong but informative regularization of the text embeddings to combat noisy inputs.\\vspace{-0.5em} \\item Prompt Tuning v.s. TEnc-FT: The text encoder should be fixed to prevent overfitting. \\end{itemize}\\end{frame}\\begin{frame}{Other Aspects of Robustness}\\begin{itemize} \\item \\textbf{Effectiveness of Prompt} \\item \\textbf{Prompt Tuning Suppresses Noisy Gradients} \\item \\textbf{Generalization Across Model Architectures} \\item \\textbf{Robustness to Correlated Label Noise}\\end{itemize}\\end{frame}\\section{Robust UPL}\\begin{frame}{Improve UPL in Unsupervised Prompt Tuning} \\vspace{-1em} \\begin{figure} \\includegraphics[width=\\textwidth]{Figures/Survey1/UPL.png} \\label{fig: UPL} \\end{figure}\\vspace{-0.8em}\\begin{itemize} \\item Baseline UPL\\begin{itemize} \\item Phase 1: Leverage pre-trained CLIP to generate pseudo labels for unlabeled images. \\item Phase 2: Select \\textbf{the $K$ most confident samples per class} to optimize the learnable tokens through the typical prompt-tuning optimization process (described in CoOp). \\end{itemize} \\item Robust UPL\\\\ Based on UPL, \\textbf{randomly sample $K$ training samples} and optimize the prompt with the \\textbf{robust GCE loss}.\\end{itemize}\\end{frame}\\section{Next Stage}\\begin{frame}{New Plans for Next Week}\\begin{enumerate} \\item Reproduce the most of results about this paper. \\item Survey other relavent methods in this domain.\\end{enumerate} \\end{frame}\\miniframesoff\\begin{frame} \\section*{} \\begin{center} {\\Huge \\textit{Thanks for you3fr listening!}} \\end{center}\\end{frame}\\end{document} Template Overview Contributors Zhihao Li References PKU_beamer_lightweight_designed","link":"/blog/WeeklyReport/"},{"title":"Install the Operating System of Windows and Linux on the Laptop","text":"Environments Windows 11 Ubuntu 24.04 LTS Laptop: Yoga Pro 14S ARH7 Allocated Disk For Ubuntu: 146.5GB Step I: Download Ubuntu Package Download the Ubuntu ISO file from the official website: https://ubuntu.com/download/desktop Just select the version of Ubuntu 24.04 LTS and download the ISO file. Step II: Make a Bootable USB StickPreparation Prepare a USB stick with a capacity of at least 8GBThe USB stick will be formatted so you need to back up any important data on it. Install the software UltraISOWe use the software UltralSO to write the ISO file to the USB stick. UltraISO requires a paid registration, but we only need to use it for a short period, so we can click ‘Trial’ without purchasing a registration code. Steps Open the UltraISO and select the downloaded ISO file from the local directory Double-click the ISO file: ubuntu-24.04-desktop-and64.iso Select “Boot” in the menu bar above UltraISO, then click on “Write Disk Image” Check the configuration Format the USB stick by clicking the button of ‘format’ Write the ISO file to the USB stick by clicking the button of ‘Write’ This process will take a long time period and after writing the stage have just been finished. Step III: Allocate the Disk Space for Ubuntu Open the disk management tool in WindowsYou can search the Computer Management in the search bar and open it. And in the left menu, select Disk Management under the Memory section. Right-click on the disk, preferably D Disk, that you want to allocate space for Ubuntu and select Shrink Volume Enter the amount of space you want to allocate for Ubuntu, and then click “Shrink”It will be recommended to allocate around 100GB of space for Ubuntu. This will make sure that you have enough space for the operating system and other applications. Step IV: Install Ubuntu Insert the USB stick into the computer Method I: BIOS modePress the key of F12 or F2 to enter the BIOS setting and select the USB stick as the boot device Method II: Advanced RestartSometimes entering the BIOS setting is not easy, but there have another way to boot the system from the USB stick. Search the Restore in the windows search bar and open it. Click on the Restart Immediately button to restart the computer. After the computer restarts, it will enter the Advanced Boot Options menu. Select the Using Device option. About EFI mode we just choose the EFI USB Device to boot the operating system. Entering this page, we just choose to install Ubuntu When it boots the Ubuntu system, it will prepare the environment. Configure the Ubuntu system and just wait for several minutes. When all installation have been finished Step V: Restart the SystemAfter the installation, we need to restart the system to make sure that the system is working properly. Boot UbuntuWe just click the Ubuntu button to boot the Ubuntu system. Boot WindowsWe just click the Windows Boot Manager button to boot the Windows system. ConfigurationWe can see that the system is installed successfully, but we still need to configure it. For personalized usage needs, we can configure specific applications. Firstly, just have a look for my configuration. System Fonts Install the packages 1sudo apt install gnome-tweaks Run the command 1gnome-tweaks It will open the configuration interface, and we just click Fonts. It has three fonts to configure the displayed fonts style under different positions. And importantly, it has the Scaling Factor below the interface to configure the interface size. Chinese Input Install the packagesThere has several Chinese input methods, but I recommend ibus-libpinyin because it is simple and easy to use. 1sudo apt-get install ibus-libpinyin Run the commandAfter installation, we need to log out to fresh the package. And logging in again, we just run the following command to add the Pinyin method under the Chinese section. 1ibus-setup Configure the input method in the system settingsJust see the following picture. We need to add the input source of Chinese(Pinyin) under the Keyboard section. Clash Verge Download the package from website: https://github.com/clash-verge-rev/clash-verge-rev/releases Follow the instructions to install the package: https://clash-verge-rev.github.io/faq/linux.html A Fantastic Application Blue MailIt’s also a fantastic application on linux system. It is a mail client and it has a very beautiful interface. Wemeet Download the package from website: https://meeting.tencent.com/download/ Install the package and run it. Solve the problem: wayland 123sudo vim /etc/gdm3/custom.conf#WaylandEnable=false ==&gt; WaylandEnable=falsesudo service gdm3 restart Installation Command.deb file12sudo dpkg -i package_file.debsudo apt install ./package_file.deb .AppImage file12chmod +x package_file.AppImage./package_file.AppImage .rpm file1sudo rpm -i package_file.rpm","link":"/blog/WindowsLinuxSystem/"},{"title":"My Knowledge about Paper Writing","text":"Seven Simple, Actionable Suggestions For Making Papers BetterDon’t Wait to WriteWriting papers model: Your Idea $\\rightarrow$ Do Research $\\rightarrow$ Write Paper[Not Recommended] Your Idea $\\rightarrow$ Write Paper $\\rightarrow$ Do Research [Recommended] Recommend Reasons: Forces us to be clear, focused Crystallites what we don’t understand Opens the way to dialogue with others: reality check, critique, and collaboration Identify Your Key IdeaUseful Re-usable Idea You want to infect the mind of your reader with your idea, like a virus. Papers are far more durable than programs(think Mozert) Do Not be Intimidated Fallacy: You need to have a fantastic idea before you can write a paper. Idea: Your paper should have just one “ping”: one clear, sharp idea. You may not know exactly what the ping is when you start writing; but you must know when you finish. If you have lots of ideas, write lots of papers. Make certain that the reader is in no doubt what the idea is.(Be 100% explicit) “The main idea of this paper is…” “In this section we present the main contributions of the paper.” Tell A StoryYour Narrative FlowImagine you are explaining ar a whiteboard: Here is a problem It’s an interesting problem It’s an unsolved problem Here is my idea My idea works(details, data) Here’s how my idea compares to other people’s approaches Structure(Conference Paper) Title(1000 readers) Abstract(4 sentences, 100 readers) Introduction(1 page, 100 readers) The problem(1 page, 10 readers) My idea(2 page, 10 readers) The details(5 pages, 3 readers) Related work(1-2 pages, 10 readers) Conclusions and further work(0.5 pages) Nail Your Contributions to the MastDescribe the Problem Use an example to introduce the problem State Your Contributions Write the list of contributions first: Bulleted list of contributions The list of contributions drives the entire paper: the paper substantiates the claims you have made. Readers thinks “gosh, if they can really deliver this, that’s be exciting; I’d better read on” Evidence Your introduction makes claims The body of the paper provides evidence to support each claim Check each claim in the introduction, identify the evidence, and forward-reference it from the claim “Evidence” can be: analysis and comparison, theorems, measurements, case studies Related Work: LaterFallacy: To make my work look good, I have to make other people’s work look bad.Giving credit to others does not diminish the credit you get from your paper: Warmly acknowledge people who have helped you Be generous to the competition. “In his inspiring paper [Foo98] Foogle shows… We develop his foundation in the following ways…” Acknowledge weaknesses in your approach Failing to give credit to others can kill your paper Put Your Readers FirstPresenting the Idea Explain it as if you were speaking to someone using a whiteboard Conveying the intuition is primary, not secondary Once your reader has the intuition, she can follow the details (but not vice versa) Even if she skips the details, she still takes away something valuable Conveying the IntuitionIntroduce the problem, and your idea, using examples and only then present the general case. Do not recapitulate your personal journey of discovery. This route may be soaked with your blood, but that is not interesting to the reader. Instead, choose the most direct route to the idea. Listen to Your ReadersGetting Help Get your paper read by as many friendly guinea pigs as possible Each reader can only read your paper for the first time once! So use them carefully! Explain carefully what you want (“I got lost here” is much more important than “Jarva is mis-spelt”.) Getting Expert Help A good plan: when you think you are done, send the draft to the competition saying “could you help me ensure that I describe your work fairly?”. Often they will respond with helpful critique (they are interested in the area) They are likely to be your referees anyway, so getting their comments or criticism up front is Jolly Good Listening to Your ReviewersTreat every review like gold dust Be (truly) grateful for criticism as well as praise. Read every criticism as a positive suggestion for something you could explain more clearly DO NOT respond “you stupid person, I meant X”. Fix the paper so that X is apparent even to the stupidest reader. Thank them warmly. They have given up their time for you. References How to write a great research paper Seven simple suggestions","link":"/blog/WritingSkills/"},{"title":"人工智能导论","text":"课程实验、复习、期末试题资源详见阿里云盘链接 复习思维导图 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 杨利英. 2024年春, 人工智能导论, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/240785494.html","link":"/collaboration/AIIntroduction/"},{"title":"计算机通信与网络","text":"前言 课程复习、期末试题资源详见阿里云盘链接 数据通信与网络课件第一章 概述1.1 第一讲 绪论1.2 第二讲 网络模型第二章 物理层和介质2.1 第三讲 物理层2.2 第四讲 数字传输2.3 第五讲 模拟传输2.4 第六讲 带宽利用2.5 第七讲 传输介质2.6 第八讲 交换2.7 第九讲 使用电话网和有线电视网进行数据传输第三章 数据链路层3.1 第十讲 检错与纠错3.2 第十一讲 数据链路控制3.3 第十二讲 多路访问3.4 第十三讲 有线局域网：以太网3.5 第十四讲 无线局域网3.6 第十五讲 连接局域网、主干网和虚拟局域网3.7 第十七讲 广域网3.8 第十八讲 虚电路网络：帧中断和ATM第四章 网络层4.1 第十九讲 逻辑寻址4.2 第二十讲 IP协议4.3 第二十一讲 地址映射、差错报告和多播4.4 第二十二讲 传递、转发和路由选择第五章 传输层5.1 第二十三讲 UDP、TCP和SCTP5.2 第二十四讲 拥塞控制和服务质量计算机通信与网络课程总复习知识点第一部分 概述第1章 绪论1、数据通信基本概念及模型数据通信是在两台设备之间通过诸如线缆的某种形式的传输介质进行的数据交换。【数据通信系统模型】——五个组成部分 报文：进行通信的信息（数据）发送方：发送数据报文的设备接收方：接受报文的设备传输介质：报文从发送方到接收方之间所经过的物理通路协议：管理数据通信的一组规则，表示通信设备之间的一组约定 2、数据流：单工、半双工、全双工 单工模式（Simplex Mode)：通信是单方向的，两台设备只有一台能够发送，另一台则只能接受半双工模式（Half-duplex Mode)：每台主机均能发送和接受，但不能同时进行全双工模式（Full-duplex Mode)：双方主机都能同时发送和接受 3、连接类型和拓扑结构 点到点连接：提供两台设备之间专用的链路，链路全部的能力均为两台设备之间的传输所共用多点连接：两台以上设备共享单一链路的情形，通道的能力在空间和时间上共享拓扑结构：网状、星型、总线、环状 4、网络分类：局域网、城域网、广域网 网络 规模 介质 拓扑结构 局域网LAN 小于2英里 一种类型的传输介质 总线结构、环状结构和星型结构 城域网MAN 十几英里 广域网WAN 世界范围 5、协议和标准【协议三要素】 语法：指数据的结构或格式，即它们是以何种顺序表示的语义：指每一位片段的含义：如何解释一个特别的位模式时序：报文发送的时间和发送的顺序 【TCP/IP】 传输控制协议（TCP）负责高层功能，比如分段、重组和差错控制网际协议（TP）负责处理数据包路由 第2章 网络模型1、层次结构、层间接口和封装的概念【层次结构】：把相关的网络功能组合在一层中，每层都使用其直接下层提供的服务，保持网络灵活且易修改【层间接口】：数据和网络信息从高层向低层传递和从低层向高层传递都通过相邻两层的接口进行，每一层接口都定义了该层必须向上层提供信息和服务【封装】：第N-1层的分组中的数据部分是第N层的完整分组（数据、头部、也可能有尾部）2、OSI参考模型【开放系统互联（Open System Interconnection)模型】 对等协议：传输层、会话层、表示层、应用层中间节点只涉及下三层：物理层、数据链路层、网络层 物理层：负责位从一个节点到另一个节点的传递 位的表示：要进行位流的传输必须将位编码成信号——电信号或光信号（物理层定义编码的类型）数据速率：定义传输速率（每秒发送的位数）位同步：发送方与接收方不仅使用相同的比特率还必须位同步保证时钟同步线路配置：点到点连接或多点共享连接物理拓扑结构：定义设备连接成网络的连接方式（网状、星型、总线、环状）传输方式：定义两台设备之间的传输方式（单工、半双工和全双工） 数据链路层：负责帧从一跳到下一跳的传递 成帧：数据链路层将接收到的来自网络层的位流分成称为帧的易处理数据单元物理寻址：1、不同系统 数据链路层在帧的头部添加发送方的物理地址和接收方的物理地址 2、不同网络 数据链路层在帧的头部添加发送方的物理地址和连接下一个网络的路由地址流量控制：采用流量控制机制防止接收方过载差错控制：检测与重发损坏帧或丢失帧 网络层：负责将各个分组从源地址传递到目的地址 逻辑寻址：物理寻址负责处理本地网络寻址问题（数据链路层），逻辑寻址负责处理分组通过网络边界的寻址问题路由选择：在互联网中由连接设备（路由器或网关）负责把分组送到指定网络的目的地 传输层：负责一个报文从一个进程到另一个进程的传递 端口寻址：传输层信息的头部必须包含端口地址（服务点地址），将整个报文传送到计算机上的指定进程分段和组装：将报文分解成可传输的片段并进行编号，使得1、传输层可以在接收端将报文正确地组装 2、用来标识和替换传输中丢失的分组连接控制：传输层可以是无连接的或面向连接的流量控制：负责端到端上的流量控制而不是单条链路差错控制：负责进程到进程上的差错控制而不是单条链路上 会话层：负责对话控制和同步 对话控制：允许两个进程之间以半双工或全双工方式进行通信同步：会话层允许一个进程在数据流中增加检查点或同步点 表示层：负责翻译、加密和压缩数据 应用层：负责向用户提供服务 3、TCP/IP协议族【层次组成】：物理层和数据链路层（主机到网络层）、网络层、传输层和应用层 网络层 IP协议：不可靠、无连接、主机到主机协议 组成部分： 地址解析协议（ARP)：将逻辑地址与物理地址联系起来逆地址解析协议（RARP)：允许主机在仅知道物理地址的情况下寻找因特网地址因特网控制报协议（ICMP)：用来向发送方通知数据报所发生的问题因特网组报文协议（IGMP)：用于将一个报文发送给一组接收者 传输层 用户数据报协议（UDP)：进程到进程的协议即端到端的协议传输控制协议（TCP)：是面向连接的、可靠的流传输协议流控制传输协议（SCTP） 4、寻址【物理（链路）地址（MAC地址）】 用于物理层和数据链路层以太网中使用6个字节（48位）物理地址，标明在网卡上，长度格式可变 【逻辑（IP）地址】 用于网络层因特网的逻辑地址是32位地址，唯一地标识了连接到因特网上的一台主机 【端口地址】 用于传输层赋予进程的标识符称为端口地址，长度固定16位地址 跳到跳时物理地址将改变，但逻辑地址和端口地址保持不变 【专用地址】 用于应用层 第二部分 物理层和介质第3章 物理层1、数字信号传输【电平编码】 信号电平数 $L$，编码电平需要比特位数: $N=\\log_2L$ 注：通过对多电平编码可以增加每个电平表示的比特位 数字信号是无穷大带宽的复合模拟信号 【基带传输】$Define:$ 通过通道发送数字信号而不转换为模拟信号，即以信号本身的频谱进行传输 只能用带宽下限频率为 $0$ 的低通通道在基带传输中，所需的带宽与比特率成正比 $Eample\\ 1:$ 基带传输发送比特率 $n=1Mbps$，求低通通道所需带宽 最小带宽、使用第一谐波 $\\Longrightarrow B_1=\\frac{n}{2}=500KHz$ 使用第一、三谐波 $\\Longrightarrow B_3=3\\times B_1=1.5MHz$ 使用第一、三、五谐波 $\\Longrightarrow B_5=5\\times B_1=2.5MHz$ $Eample\\ 2:$ 一条带宽 $B=100kHz$ 的低通通道，求最大比特率 使用第一谐波得到最大比特率 $\\Longrightarrow n = 2\\times B=200kbps$ 【宽带传输】$Define:$ 宽带传输或调制把数字信号转换成模拟信号进行传输 调制允许使用带通通道，即带宽不从0开始的通道发送模拟信号用带通通道 2、典型的传输减损【衰减】$Define:$ 通过某种介质传输时，信号能量下降；分贝表示信号损失或增益强度 $dB=10\\log_{10}\\frac{P_2}{P_1}$ 其中，$P_1$、$P_2$ 表示信号前后的功率 【失真】$Define:$ 不同信号成分具有不同的传播速度导致信号波形失真 【噪声】$Define:$ 外界干扰，电缆中的电子随机移动而产生的额外信号 【信噪比】$Define:$ 信号功率与噪声功率的比率 $SNR = \\frac{P_1}{P_2}$ 其中，$P_1$、$P_2$ 表示平均信号功率和平均噪声功率 分贝单位$\\Longrightarrow SNR_dB = 10\\log_{10}SNR$ 3、数据速率限制【尼奎斯特定理】——无噪声通道 $S = 2B$ 注：有限带宽 $B$ 下，通道的极限波特率(码元速率)为 $2B$ 【奈奎斯特速率】——无噪声通道 $N = 2\\times B\\times log_2L$ 注：定义了给定带宽下理论上的最大比特率 【香农容量定理】——有噪声通道 $C = B\\times \\log_2(1+SNR)$ 其中通道容量是指通道的传输容量，即每秒的比特数等于比特率 注：确定噪声通道理论上的最高数据速率 当 $SNR$ 较大时，$SNR+1\\approx SNR$，则 $C = B\\times \\frac{SNR_{dB}}{3}$ $Eample:$一通道带宽 $B=1MHz$，信噪比 $SNR=63$，求合适的比特率以及信号电平解：由香农公式确定比特率上限： $$C = B\\log_2(1+SNR)=6Mbps$$ 为了获得更好的性能，取通道比特率 $N=4Mbps$由奈奎斯特公式计算信号电平数: $$N = 2B\\log_2L\\rightarrow L=4$$ 香农容量定理给出数据速率的上限，奈奎斯特公式给出所需的信号电平数 4、性能【带宽】——链路的潜在衡量值，链路最大的数据传输速率【吞吐量】——发送速度快慢的实际衡量值，小于带宽【延迟】——第一个位开始发出到整个报文完全到达目标所经历的时间 延迟=传播时间+传输时间+排队时间+处理延迟 传播时间——一个位从源传输到目标所需时间（与介质相关） $$Tp = \\frac{d}{v}$$ 传输时间——传输一个报文的时间 $$Tt = \\frac{LF}{B}$$ 其中，帧长 $LF$ 表示一个报文长度 排队时间——每个中间或端设备在处理报文前保持报文所需的时间 【带宽与延迟乘积】——定义了能充满链路的位数（通常用的是传播时延） 第4章 数字传输1、线路编码——将数字数据（比特位）转换为数字信号（高低电平）的过程【数据元素】表示一块信息的最小实体即位【信号元素】承载数据单元，是数字信号的最小单元$Define:$ 承载比率 $r$: 每个信号元素承载的数据元素的数量 $$ r = \\log_2L $$ 【数据速率（比特率）】表示1秒发送的数据元素（位）的数量（单位：bps）【信号速率（波特率）】表示1秒发送的信号元素的数量（单位：波特baud)比特率和波特率关系: $$S = c\\times N\\times \\frac{1}{r}\\ \\ baud$$ 其中，$N$ 表示比特率，$S$ 表示波特率，$c$ 表示情形因子(一般取 $0.5$)，$r$ 表示承载比率 波特率决定了数字信号的带宽，并且带宽与波特率成正比 【最小带宽】 $$B_{min}=c\\times N\\times \\frac{1}{r}$$ 最小带宽$B_{min}$与波特率相等（至少保证能够传输信号） 当通道带宽为 $B$ 时，得出最大数据速率： $B_{min}=c\\times N\\times\\frac{1}{r}\\leq B\\rightarrow N\\leq \\frac{1}{c}\\times B\\times r$ $\\Longrightarrow N_{max}=\\frac{1}{c}\\times B\\times r$ 注：$B_{min}$ 表示信号所需最小带宽，$B$ 表示通道带宽 【直流分量】——信号电平保持一段时间的恒定，使得频谱中对应的频率很低称为 DC（直流）分量【自同步】——接收方的位间隔必须与发送方的位间隔一致 数字信号在传输的数据中包含有定时信息：提示接收方起始、中间和结束位置的脉冲的跳变 2、线路编码方案不同编码方案平均带宽计算: $B_{min}=S = c\\times N\\times\\frac{1}{r}$ $c=0.5\\Longrightarrow B_{min} = \\frac{N}{2r}$ 单极性编码 极性编码方案(NRZ-L) 极性编码方案(NRZ-I) 归零码(RZ) 正电平定义成位 $1$ 而零电平定义成位 $0$，位中间信号不会回到 $0$ $r=1$，平均带宽 $B = \\frac{N}{2}$ 成本高，$0$ 或 $1$ 的长序列没有自同步，存在 $DC$ 问题 正电平定义成位 $0$ 而零电平定义成位 $1$，位中间信号不会回到 $0$，电平决定位值 $r=1$，平均带宽 $B = \\frac{N}{2}$ 全 $0$ 或全 $1$ 的长序列没有自同步，存在基线偏移，$DC$ 问题 信号电平是否反相转决定了位值，位中间信号不会回到 $0$ 对于本位，如果本位电平相比上位电平有反相，$bite = 1$，否则 $bite=0$ $r=1$，平均带宽 $B = \\frac{N}{2}$ 全 $0$ 的长序列没有自同步，存在基线偏移，$DC$ 问题 使用正值、负值和零三个信号电平 正电平定义成位 $1$，负电平定义成位 $0$，只是信号在位中间跳变回到 $0\\Rightarrow$ 解决同步问题 $r=\\frac{1}{2}$，平均带宽 $B = N$ 能够自同步，没有 $DC$ 问题，但是需要高带宽 双相编码——曼彻斯特编码 双相编码——差分曼彻斯特编码 双极性编码——AMI 双极性编码——伪三元编码 $RZ+NRZ-L$ 使用正值、负值两个电平，正电平定义成位 $0$，负电平定义成位 $1$，位中间跳变成另一电平 $\\Rightarrow$ 解决同步问题 $RZ+NRZ-I$ 使用正值、负值两个电平，正电平定义成位 $0$ 位中间跳变，如果下一位是 $1$，位开始处不跳变，否则进行跳变 $\\Rightarrow$ 解决同步问题 使用正值、负值和零三个电平，位 $0$ 始终由零电平表示，而位 $1$ 由交替正负电平表示 $r=1$，平均带宽 $B = \\frac{N}{2}$ 全 $0$ 的长序列没有自同步，无 $DC$ 问题 使用正值、负值和零三个电平，位 $1$ 始终由零电平表示，而位 $0$ 由交替正负电平表示 $r=1$ 3、块编码：4B/5B、8B/10B(了解)4、扰码【B8ZS】——8零置换的双极编码方案 $$B8ZS:00000000\\Rightarrow 000VB0VB$$ 其中，$V$ 表示与前一个非零脉冲极性相同的极性，$B$ 表示与前一个非零脉冲极性相反的极性 5、脉冲码调制PCM【采样】——方顶采样模拟信号采样周期$T_S$，采样频率$f_S=\\frac{1}{T_S}$根据奈奎斯定理，采样速率必须至少是信号所含最高频率的 $2$ 倍: $$f_S\\geq 2f_m$$ 【量化】 将最低振幅 $V_{min}$ 和最高振幅 $V_{max}$ 范围量化为 $L$ 个区间 区间高度：$\\Delta = \\frac{V_{max}-V_{min}}{L}$ 标准化 $PAM$ 值/振幅= 实际振幅/$\\Delta$ 标准化量化值=样本所在区间的中间量化值(单位为 $\\Delta$) 量化误差=标准化量化值-标准化振幅值，一般 $-\\frac{\\Delta}{2}\\leq$ 误差 $\\leq\\frac{\\Delta}{2}$ 量化码：$0\\thicksim7$ 编码对应 $-4\\Delta\\thicksim 4\\Delta$ 每一个区间 编码码字：$0\\thicksim7\\Longrightarrow 000\\thicksim111$ 【量化等级】——取决于模拟信号的振幅范围【量化误差】对信号 $SNR_{dB}$ 的影响： $$SNR_{dB}=6.02n_b+1.76dB$$ 其中，$n_b$ 表示每个样本的编码位数，$n_b=log_2L$ ($L$ 表示量化等级数即电平数) 【PCM数字化模拟信号的比特率和带宽】 $f_S=2f_m$ $\\Rightarrow N = f_S\\times n_b =2f_m\\times\\log_2L$ $B_{min}=c\\times N\\times\\frac{1}{r}$ $=c\\times f_S\\times n_b\\times \\frac{1}{r}$ $=c\\times 2\\times B_{analog}\\times n_b\\times \\frac{1}{r}$ $=n_b\\times B_{analog}$ 其中，$B_{analog}$ 表示低通模拟信号的带宽即信号最高频率 6、Delta调制 (DM)的概念【调制】 数字数据生成：将模拟信号的值与梯形信号的最后一个值比较，如果模拟信号的振幅大，则数字数据下一个位为 $1$，否则为 $0$;梯形信号生成：如果数字数据下一位为 $1$，则梯形信号的最后一个点上移 $\\delta$，否则下移 $\\delta$; 7、传输模式【并行传输】 使用 $n$ 个通信线路同时发送n位优点：速度快，用于短距离通信缺点：成本高 【串行传输】 包括异步和同步传输优点：成本低，适合远距离通信缺点：速度慢 【异步传输】 在传输中信号的时序并不重要信息的接受和转换通过约定的模式进行字节级异步：将位流组成字节(通常是 $8$ 位)的方式进行分组发送字节内同步：没有同步时钟，每个字节增加起始位和停止位，并且每个字节之间有一个时间间隔 【同步传输】 位流被组合成更长的帧，一帧包含多个字节，按序发送依次发送位流而不含起始位、停止位和间隙，接收方负责将位进行分组帧间可能有不等的时间间隔，常用于大块二进制数据传送 同步传输比异步传输速度快 第5章 模拟传输1、比特率和波特率$Define:$$$r = log_2L\\newlineS=N\\times\\frac{1}{r}$$其中，$L$ 表示不同类型的信号元素个数(数字传输中 $L$ 为电平个数) 2、数字到模拟转换的概念 数字数据转换为带通模拟信号 $\\Rightarrow$ 数字到模拟转换 低通模拟信号转换为带通模拟信号 $\\Rightarrow$ 模拟到模拟转换 【幅移键控（(B)ASK）】 通过改变载波信号的振幅来生成信号元素，只有振幅变化而频率和相位保持不变 【带宽】 $B=(1+d)\\times S$ $S = N\\times \\frac{1}{r}\\Rightarrow B = (1+d)\\times N\\times\\frac{1}{r}$ 反推 $N$ 【频移键控（(B)FSK）】 通过改变载波信号的频率来生成信号元素，只有频率变化而振幅和相位保持不变 【带宽】 $$B=(1+d)\\times S+2\\Delta f$$ 其中，$\\Delta f$ 表示两个信号元素的频率差 【相移键控（PSK）】 通过改变载波信号的相位来生成信号元素，只有相位变化而振幅和频率保持不变 BPSK：二进制PSK，只用两个信号元素，一个相位是$0$ 度，另一个相位是 $180$ 度 QPSK：正交PSK，使用两个独立的BPSK调制，一个是同向的，另一个是正交的 QPSK中相位可能是 $45$ 度，$-45$ 度，$135$ 度和 $-135$度之一，输出信号有 $4$ 种信号元素，每个信号元素可以承载 $2$ 位【带宽】 $B=(1+d)\\times S=(1+d)\\times N\\times\\frac{1}{r}$ $BPSK:\\ r=1\\Longrightarrow B = (1+d)\\times N$ $QPSK:\\ r=2\\Longrightarrow B = (1+d)\\times \\frac{N}{2}$ 【正交振幅调制（QAM）】 ASK+PSK:使用两个载波，一个同向而另一个正交，每个载波都用不同的振幅 【n-QAM带宽】 $$r = \\log_2n\\Rightarrow B = (1+d)\\times N\\times\\frac{1}{r}$$ 第6章 带宽利用1、复用：FDM、同步TDM、统计TDM和WDM概念【复用带宽要求】连接两台设备的介质带宽要比设备间传输所要求的带宽高【频分复用（FDM）】——用于模拟信号 链路带宽（以Hz为单位）大于要传输的信号的带宽之和 将链路带宽进行分频给每个信号通道，通道间存在未使用的带宽即防护频带 【波分复用（WDM）】 用于具有高数据速率传输能力的光缆，是合并多个光信号的模拟多路复用技术 【时分复用（TDM）】 TDM在时间上共享，每个连接占用链路的一个时间段，是组合多个低速的通道为一个高速通道数据的复用技术 【同步TDM】 每个输出单元的持续时间是输入单元的$n$ 分之一，其中 $n$ 表示连接数 链路速率是数据速率的$n$ 倍，并且比单元持续时间短 $n$ 倍 帧同步，每帧开始增加一位帧指示位，交替变换为 $0$ 和 $1$ 【同步TDM数据速率管理】各数据线数据速率不相等时处理技术： 处理策略 使用情况 特点 多级复用 一条输入数据线数据速率是其他一些输入数据线数据速率的整倍数 合并低数据速率通道，$m\\times n$，$m$表示连接数 多时隙复用 在一个帧中允许对一条输入分配多个时隙 分离高数据速率通道，$\\frac{n}{m}$，$m$表示分配的连接数 脉冲填充 输入线的比特率不是其他每个输入线比特率的整数倍 低速率的输入线添加虚位 【统计TDM】——动态分配时隙，提高链路利用率 输出时隙必须携带数据和目的地址(目的地址+数据) $N$ 条输出线编码表示： $$ n=\\log_2N $$ 无同步位，存在通道寻址因此不需要同步位 链路容量小于各通道之和 【脉冲调制PCM体制两大国际标准】 北美24路T1载波 欧洲30路E1载波 服务 $DS-1$ 线路 $T-1$ 速率：$1.544Mbps$ 用途：传输音/视频，也可用于模拟传输 语音通道：$24$ 个 时分多路复用技术(TDM) $DS-1$ 需要 $8kbps$ 开销 欧洲版 $T$ 线路 速率：$2.048Mbps$ 语音通道：$30$ 个 时分多路复用技术(TDM) 我国采用的是欧洲的E1标准 3、波分和码分的概念4、FHSS和DSSS的概念 第7章 传输介质1、有向介质：双绞线及其特点、同轴电缆和光纤的概念2、无线传输介质：无线波谱、无线电波、微波和红外波 第8章 交换（传输时延分析）1、电路交换网络——效率低、延迟最小电路交换网络是由物理链路连接的一组交换机组成的，每条链路划分成 $n$ 个通道，两个站点的连接是由一条或多条链路组成的专用路径来实现 电路交换在物理层资源预留：通信开始前，站点需要对通信所用的资源进行预留连续数据流：数据传输不打包数据传输期间无寻址 【建立阶段】——每条链路上预定一个通道，联合起来指定一条专用路径 建立阶段进行资源预留、端到端寻址 【网络延迟】 延迟时间=建立连接时间+数据传输时间+拆除电路时间 建立连接时间=请求信号传播+请求信号传输时间+确认信号传播时间+确认信号传输时间 数据传输时间=数据传播时间+数据传输时间 2、分组交换网 数据报网络虚电路网络 分组交换网中，不存在资源预留，资源按需分配 3、数据报网络——效率较高，延迟较长 每个分组独立处理，数据报交换在网络层不需要建立连接阶段和拆除阶段每个分组头部包含目的地址，且在分组传送期间保持不变（物理地址会变） 数据报网中的交换机使用基于目的地址的路由表 【网络延迟】 延迟时间=传输时间+传播时间+等待时间 $Example:$ 分组通过两个交换机传送分析： 总延迟时间 $=3\\times$ 传输时间 $+3\\times$ 传播时间 $+$ 在交换机 $1$ 处等待时间 $+$ 在交换机 $2$ 处等待时间 因特网在网络层用数据报方法对数据进行交换 4、虚电路网络—— 电路交换+数据报网络虚电路网络在数据链路层实现在数据传输阶段，存在建立阶段与拆除阶段按需在建立阶段期间分配资源每一分组头部含有目的地址，具有本地权限而非端到端权限（定义下一个交换机和分组的通道地址，虚电路标识符实现）所有分组沿着建立的路径进行传送 【虚电路标识符（VCI）】一个VCI仅是在交换机范围内的小数字，由两个交换机之间的帧来使用，通过交换机时更新VCI【虚电路网络表】 表项构成：输入端口，输入VCI，输出端口，输出VCI 【网络延迟】 延迟时间=传输时间+传播时间+建立阶段延迟+拆除阶段延迟 $Example:$ 分组通过两个交换机传送分析： 总延迟时间 $=3\\times$ 传输时间 $+3\\times$ 传播时间 $+$ 建立阶段延迟 $+$ 拆除阶段延迟 第三部分 数据链路层第10章 检错与纠错1、差错的类型【单个位差错】——数据单元仅有一位发生变化【突发性差错】——数据单元有两位或多位发生变化2、块编码 报文划分成块，每个块有k位——数据字数据字+r个冗余位形成长度n=k+r的块——码字 数据字: $2^k$ 码字: $2^n$ $\\Longrightarrow$ 非法码: $2^n-2^k\\ (n>k)$ 3、纠错方法【汉明距离】——两个相同长度的字的汉明距离是对应位不同的数量 $$10101\\oplus 11110=01011\\Rightarrow d(10101, 11110)=3$$ 【最小汉明距离】——一组字中所有可能对中的最小汉明距离 $d_{min} = \\min${两两间的汉明距离} 为了检测出所有情况下最多$s$个差错，块编码中最小汉明距离一定是$d_{min}=s+1$ 为了纠正所有情况下最多$t$个差错，块编码中最小汉明距离一定是$d_{min}=2t+1$ 4、线性块编码【线性块编码最小距离】——最小汉明距离 最小汉明距离是具有最少1的个数的非$0$ 有效码字中 $1$ 的个数 注：每个非零码字中，具有最少$1$ 的码字对应 $1$ 的个数 【简单奇偶校检码】 校检编码$n=k+1、d_{min}=2$，单个位或奇数个位检错编码，不能纠错 【二维奇偶校检码】——最多能检测 $3$ 个差错【汉明编码】 $n=2^m-1,\\ \\ k=n-m$ $\\Longrightarrow$ 校检位个数: $r=m$ $d_{min}=3\\Rightarrow$ 校检 $2$ 位，纠正 $1$ 位 编码分析 $a_3a_2a_1a_0r_2r_1r_0\\Longrightarrow b_3b_2b_1b_0q_2q_1q_0$ 奇偶校检位: $r_0=a_2+a_1+a_0$ $r_1=a_3+a_2+a_1$ $r_2=a_3+a_1+a_0$ 奇偶校检方程: $s_0=b_2+b_1+b_0+q_0$ $s_1=b_3+b_2+b_1+q_1$ $s_2=b_3+b_1+b_0+q_2$ 校正子 $s_2s_1s_0$ 出错位 6 110 $b_3$ 3 011 $b_2$ 7 111 $b_1$ 5 101 $b_0$ 5、循环冗余编码校检码（CRC码） 数据字：$k$位，码字：$n$位，校检位：$n-k$位，除数：$n-k+1$位，余数：$n-k$位 编码分析 余数=(数据字+($n-k$)位 $0$) $\\%$ 除数 (模 $2$ 除法) $\\Longrightarrow$ 校检位=余数 $\\Longrightarrow$ 码字=数据字+校检位 校检： 校正子=码字$\\%$除数 if 校正子== $0$: 接受数据字 else 丢弃数据字 检错类型 （除数）生成多项式$g(x)$ 捕捉单个位差错 $g(x)$至少有两项并且$x^0$的系数为1 两个独立的单个位差错 $g(x)$不能整除$x^t+1(t\\in [0,n-1], t\\in Z)$ 奇数个差错 $g(x)$有因式$x+1$ 突发性差错 所有$L\\leq r$的差错均可被检测;$L=r+1$的差错被检测概率$P=1-{\\frac{1}{2}}^{r-1}$;$L&gt;r+1$的差错被检测概率$P=1-{\\frac{1}{2}}^r$;（其中$L$表示差错长度，$r$表示冗余位长度 6、校检和及其计算方法 需要将数据划分为多组的16bits数据 第11章 数据链路控制1、组帧 在数据链路层，成帧将一条从源端到目的端的报文分离开来，或者将到不同目的端的报文分离开来 【固定长度成帧】——不需要定义帧的边界，长度本身可以用作分隔符【可变长度成帧】 面向字符协议——帧的开始和结尾加一个字节的标记帧格式：标记+头部+可变数量的字符（来自上层的数据）+尾部+标记转义字节：$01111101$【PPP协议】 标记冲突解决：字节填充，在字符标记的前面添加一个字节（换义字符ESC）以跳过该字符标记 面向位协议帧格式：标记+头部+可变数量的位（来自上层的数据）+尾部+标记特定的标记：$01111110$【HDLC协议】 标记冲突解决：位填充，遇到一个$0$ 后面紧跟 $5$ 个 $1$ 便添加一个 $0$ 数据链路控制：流量控制+差错控制 2、流量控制与差错控制【流量控制】——一系列程序，用来限制发送方在等到确认之前发送的数据数量【差错控制】——基于自动重复请求（ARQ）进行差错检测和重传【ARQ】ARQ技术就是自动请求重发技术，结合了流控和自动重发技术，该技术的主要思想是利用差错检测技术自动对丢失的帧和错误帧请求重发 3、停止等待ARQ——有噪声通道 差错检测由保留已发送帧的副本并当计时器到时重传这个帧来实现使用序列号给帧编号，该序列号基于模 $2$ 运算确认号总是以模2运算宣布期待收到下一帧的编号 【链路利用率】 带宽 $B$，一个位往返时间：$t$，数据帧的长度：$L$ $\\Longrightarrow$ 带宽延迟乘积=$B\\times t$ $\\Longrightarrow$ 链路利用率 = $L$/带宽延迟乘积 4、后退N帧ARQ——有噪声通道 序列号是模 $2^m$，$m$ 表示以位为单位的序列号字段长度一个ACK可以确认一个以上的帧 【协议原理】 后退 $N$ 帧ARQ协议就是从出错处重发已发过的 $N$ 个帧； 在后退 $N$ 帧协议中，发送方按照窗口中帧的编号顺序连续发送帧，接收方窗口大小总是 $1$； 接收方只能按顺序接受，并按顺序发送应答信号； 对于没有按顺序达到的帧丢弃，以后要重新发送 发送方窗口大小$2^m-1$ (一定要小于 $2^m$)，接收方窗口大小为 $1$ 5、选择重发ARQ——有噪声通道 发送方窗口大小 $\\leq2^{m-1}$，接收方窗口大小与发送方一致 6、高级数据链路控制（HDLC） 面向比特的点到点和多点链路进行通信的协议 【正常响应方式】【异步平衡方式】【定义帧】 信息帧 管理帧 无编号帧 7、点到点（PPP）协议——面向字节的方式 第12章 多路访问1、随机访问【纯ALOHA】——每个站点有帧要发送，就发送帧 脆弱时间: $2\\times T_{fr}$ 吞吐量: $S = G\\times e^{-2G}$当 $G=\\frac{1}{2}$ 时，则 $S_{max}=0.184$其中，$G$ 表示一个帧传输时间内系统产生的帧的平均数量 【时隙ALOHA】——强制站点只有在时隙开始之时才能进行发送 脆弱时间: $T_{fr}$ 吞吐量: $S = G\\times e^{-G}$当 $G=1$ 时，则 $S_{max}=0.184$其中，$G$ 表示一个帧传输时间内系统产生的帧的平均数量 【载波侦听多路访问CSMA】——传输前先侦听 脆弱时间=传播时间: $T_{p}$ 吞吐量: $S = G\\times e^{-G}$当 $G=1$ 时，则 $S_{max}=0.184$其中，$G$ 表示一个帧传输时间内系统产生的帧的平均数量 持续方法：1-持续、非持续、p-持续 【带冲突检测的载波侦听多路访问CSMA/CD】——边发边听$Example:$ CMSA/CD网络，带宽 $B=10Mbps$，最大传播时间 $T_{p}=25.6\\mu s$，求帧的最小长度解：帧的传输时间 $T_{fr}=2\\times T_{p}=51.2\\mu s\\ (T_{fr}\\geq T_{p})$帧的最小长度$=B\\times T_{fr}=B\\times 2T_{p}=512\\ bits$ 【带冲突避免的载波侦听多路访问CSMA/CA】 三种方法：帧间间隔、竞争窗口、确认 2、受控访问 预约 轮询 令牌环 3、通道化：FDMA、TDMA、CDMA 第13章 有线局域网：以太网1、IEEE标准 数据链路层划分为两个子层：逻辑链路控制层（LLC）和介质访问控制层（MAC） 2、标准以太网的MAC子层【帧格式】——最小长度 $64$ 字节【MAC地址】 源地址一定是单播地址$6$ 字节 = $12$ 十六进制数字 = $48$位 第一个字节的最低位为0则地址是单播地址否则是多播地址 广播地址是多播地址的一个特例，所有位（48位）都是1 【编码和解码】 标准以太网中实现的编码是曼彻斯特编码 IEEE 802.5中实现的编码是差分曼彻斯特编码 【$10$Base$5$】 传输速度 $10Mbps$，基带传输，传输最大距离 $500$ 米粗缆以太网半双工 【$10$Base$2$】 传输速度 $10Mbps$，基带传输，传输最大距离 $200$ 米细缆以太网半双工 【$10$Base-T】 传输速度 $10Mbps$，基带传输，双绞线最大长度：$100$米双绞线以太网全双工 【$10$Base-F】 传输速度 $10Mbps$，基带传输，光纤最大长度：$2000$ 米光纤以太网全双工 【桥接以太网】 存在网桥——作用：提高带宽和分割冲突域 【交换式以太网】 存在交换机 【全双工以太网】 站点和交换机之间使用两条链路 3、快速以太网、千兆以太网 第14章 无线局域网1、IEEE $802.11$ 标准——涵盖物理层和数据链路层【基本服务集（BSS）】 服务点AP：中央基站 不带AP的BSS称为特别网络，带AP的BSS称为基础网络 【扩展服务集（ESS）】 由两个或多个带有AP的BSS组成各个BSS通过一个分布式系统（通常是有线局域网）连接BSS中的AP而组合起来 2、$802.11$ MAC子层（DCF和PCF）【分布式协调功能DCF】 访问方式：CSMA/CA需要竞争使用信道 【点协调功能PCF】 集中式的、无竞争的轮询访问方式PCF的优先级高于DCF 【帧格式】 帧控制（FC）——$2$ 字节 D——$2$ 字节 地址——有四个地址字段，每个 $6$ 字节 序列控制——$2$ 字节，用于流量控制 帧主体——$0\\sim2312$ 字节 FCS——$4$字节，CRC-$32$的差错检测序列 【帧类型】IEEE $802.11$ 定义帧类型：管理帧、控制帧和数据帧3、隐藏站点和暴露站点【隐藏站点】——B和C对于A来说是相互隐藏的 CSMA/CA握手中的CTS帧可以避免来自隐藏站点的冲突 【暴露站点】——站点被限制使用通道，而这个通道是可用的 第15章 连接局域网、主干网和虚拟局域网1、连接设备【无源集线器】——工作在物理层以下 集线器是冲突点 【中继器】——工作在物理层 中继器连接一个局域网的各个网段，因此不能连接两个不同协议的局域网中继器转发每一帧，没有过滤能力是再生器，重新生成信号，不是放大器 【有源集线器（hub）】——工作在物理层 所有的端口是一个广播域，也是一个冲突域 【网桥】——工作在物理层和数据链路层 所有的端口是一个广播域，每个端口是一个冲突域（需要竞争使用）网桥具有过滤能力，有一个过滤决策的表可靠性高：网络故障只影响其所在的网段不改变帧中所包含的物理地址连接局域网 【透明网桥】 是一个它所连接的站点完全意识不到其存在的网桥 【生成树】 从网桥到LAN的跳数为 $1$，而从LAN到网桥的跳数为 $0$ 选择 $ID$ 最小的网桥作为根网桥 找到从根网桥到其他每个网桥或LAN的最短路径 最短路径的组合生成了最短的树 转发端口：属于生成树部分的端口阻塞端口：不属于生成树部分的端口 【两层交换机】——工作在物理层和数据链路层 没有通信量的竞争对帧的MAC地址具有过滤决策所有端口是一个广播域，每个端口是一个冲突域 【路由器】——工作在物理层、数据链路层和网络层 在硬件上实现了路由器的分组转发逻辑基于分组的逻辑地址进行路由转发每个端口是一个广播域也是一个冲突域 【三层交换机】——工作在物理层、数据链路层和网络层 每个端口是一个广播域也是一个冲突域 【网关】——工作在所有五层或OSI模型全部七层 不仅仅包含路由、交换功能，还包括应用级的功能 2、虚拟局域网 虚拟局域网: 通过软件而非物理线路来配置的局域网 【站点分组的依据】——端口号、MAC地址、IP地址、多播IP地址、联合使用 第18章 虚电路网络：帧中继和ATM1、【帧中继特点】——虚电路广域网 速率较高 允许突发性数据 花费少 工作在物理层和数据链路层 仅在数据链路层有错误检测，没有流量和错误控制 帧中继不提供流量和差错控制，这些必须由上层协议提供 帧中继提供拥塞控制和服务质量 【帧中继的结构】 帧中继是一种虚电路网络，虚电路用数据链路连接标识符（DLCI）定义 帧中继中的VCI（虚电路标识符）称为DLCI 2、异步传输模式（ATM）——信元交换网路 信元中继协议传输的数据单元：信元（长度不变）使用异步时分复用技术处理来自不同通道的信元具有先进的拥塞控制和服务质量需要建立虚电路进行通信 信元网络使用信元作为数据交换的基本单位，信元定义为一个小的、固定大小的信息块($53$B=$5$B头部+$48$B数据) 【传输路径（TP）、虚路径（VP）和虚电路（VC）】 传输路径是一个端点与一个交换机或者两个交换机之间的物理连接 虚路径提供两个交换机之间的一条连接或连接的集合 虚电路是属于同一报文的所有信元沿着同一虚电路传输，同时保持原始次序 【虚路径标识符（VPI）、虚电路标识符（VCI）】 VPI定义特定的VP，VCI定义特定的VC 一个虚连接由一对数字定义：VPI、VCI，其包含在信元的头部 第四部分 网络层第19章 逻辑寻址1、IPv4地址分类，掩码，子网和超网的概念 类别 可指派网络号范围 可指派的网络数 可分配的IP地址数 A 0000 0001— 1111 1110 2^7 -2 2^24 -2 B 128.0—191.255 2^24 2^16 -2 C 192.0.0—223.255.255 2^21 2^8-2 D 多播地址 E 保留 【子网掩码】 将IP地址的主机号部分借用几位作为子网号以区分同一网络下的不同网络(子网) 【超网】 超网(CIDR)消除了传统的A类、B类和C类地址以及划分子网的概念，将网络前缀相同的IP地址组成一个地址块 记法：IP地址 + “/” （斜线后写上网络前缀所占的比特数量） 2、子网划分方法、子网范围计算 子网掩码用连续 $1$ 表示对应的网络号和子网号；连续 $0$ 表示主机号 将IPv4地址与子网掩码“相与”，即可得到所在子网的网络地址 由子网掩码说明只借用了主机号一位，所以共划分出两个子网，每个子网可分配的地址数为： $$2^7-2$$ 3、NAT 为了解决地址短缺，内部可有大量地址，对外通信采用的一个外部格式；能使得大量使用内部专用地址的用户共享外部的全球地址，以访问因特网主机资源 4、IPv6地址及其缩短形式 第20章 IP协议1、IP数据报的格式 固定首部+数据载荷 2、分片与MTU 【MTU】 最大传送单元 : MTU 是链路层可封装数据 的上限 【分片】 更多操作 IP 分组的 MTU 是 1500 字节 , 当网络层的 IP 分组超过 1500 字节 , 此时就要进行分片，将数据报分割，使其能通过不同的网络 根据首部的标识 , 标志 , 片偏移（必须为整数） 进行相应处理 3、IPv4校验和 更多操作将校验和置$0$，以 $16$bit为一组求校验和 4、IPv6分组格式 基本头部固定为$40$B，有效载荷 $Max=65536$B 5、IPv4和IPv6混合 隧道技术：两台使用IPv6电脑的报文通过IPv4区域时，IPv6分组封装成IPv4的技术 头部转换：发送方用IPv6，接收方用IPv4，则IPv6头部应该转换为IPv4 第21章 地址映射、差错报告和多播1、APR 【概念】 逻辑地址映射到物理地址， ARP （Address Resolution Protocol） 【过程】 2、DHCP的概念 可以提供静态/动态/自动/人工的地址配置 3、ICMP 【概念作用】【差错报告】ICMP差错报文总是将报文传递给源方 4、IGMP IGMP是组管理协议，它为多播路由器提供有关连接到该网络上成员的相关信息 第22章 传递、转发和路由协议1、转发技术与转发过程 转发是指将分组路由到它的目的端 下一跳方法：路由表只保留下一跳地址 路由方法：保留完整路由信息 特定主机/特定网络方法 2、路由表、地址聚合和最长掩码匹配3、单播路由协议 【RIP】：以距离向量衡量，用于应用层 【OSPF】：以链路状态衡量，用于传输层 【BGP】：以路径向量衡量，用于应用层 4、多播的概念和多播路由协议（了解） 第五部分 传输层第23章 传输层三种协议：UDP、TCP和SCTP1、端口（重要端口）、套接字 层结构 传输地址 数据链路层 MAC地址 网络层 IP地址 传输层 端口地址 端口号：$16$bits$\\Rightarrow 0\\thicksim 65535$端口划分: 熟知端口: $0\\thicksim 1023$ 注册端口: $1024\\thicksim 49151$(防止端口被重用) 动态端口(临时端口): $49152\\thicksim 65535$(可随意使用) 套接字地址：IP地址+端口号 2、UDP协议 用户数据报协议（UDP）无连接服务、不可靠、无流量控制和差错控制 【数据报结构】 UDP分组称为用户数据报，有8字节的固定头部固定头部：源端口号、目的端口号、长度（定义数据报总长度）、校检和UDP被封装成IP数据报：伪头部是IP分组的头部一部分，而头部是UDP的一部分数据（必须进行填充是数据是16位的倍数） UDP长度=IP长度-IP头部长度 【校检和的计算】——针对UDP的头部加上去除填充的数据 每两个字节模2求和，最后结果取反得到校检和 3、TCP协议 传输控制协议（TCP）全双工、面向连接、可靠的、提供流量控制和差错控制建立虚拟连接，逻辑上的连接TCP允许发送进程以字节流的形式传递数据，并设置有发送和接受缓冲区TCP将多个字节组合在一起成为一个分组，称为段段的头部包含有序号、确认号两个字段（序号指字节序号开始于一个随机数编号而非段序号）段序号指该段的第一个字节的序号，段中确认字段定义了接收方预期接受的下一字节的编号 【连接建立（三次握手）】——SYN表示序列同步号 客户发送第一个段SYN段，用于序列号同步，不携带数据但占用一个序列号 服务器发送第二个段，SYN+ACK段，SYN表示另一方向通信的SYN段（全双工），ACK表示对第一个SYN的确认，不携带数据但占用一个序列号 客户发送第三个段，ACK段进行确认，不携带数据也不占用序列号 【终止连接（三次握手）】——将SYN换做FIN【流量控制】——信贷滑窗协议 面向字节的、窗口大小可变窗口的张开、合拢和收缩由接收方控制 窗口大小=$\\min(rwnd,cwnd)$ 【差错控制】——校检和、确认和重传 ACK段不占用序列号，不需要确认 超时重传：重传计时器到时，快速重传：发送方接收到三个重复的ACK 数据可以失序到达，并被接受的TCP暂时存储，但是TCP确保传递给进程的段是无失序的 第24章 拥塞控制和服务质量1、TCP拥塞控制【慢启动过程】 每次接收到一个确认时，窗口大小增加一个MSS值以 $2$ 的幂次增加，单位是MSS值 在慢启动算法中，拥塞窗口大小按指数规律增长直到达到阈值 【拥塞避免：加性增加】 当拥塞窗口达到慢速启动的阈值时，慢速启动阶段停止，加性增加阶段开始每次整个窗口所有段都被确认时，拥塞窗口才增加 $1$ 拥塞避免算法中，拥塞窗口大小加性增加直到检测到拥塞 【拥塞检测：乘性减少】 发生拥塞时，拥塞窗口阈值下降一半 如果计时器到时，开始一个新的慢速启动阶段如果检测出三个ACK，开始一个新的拥塞避免阶段 2、服务质量【概念】数据流所追求的某种目标 第六部分 应用层第25章 域名系统1、域名空间DNS【域名树】——最多有 $128$ 级，$0$ 级根节点，节点标号为字符串，根节点标号为空串 从下向上读，最后一个字符为 $’.’$全称域名：以空字符串结束，最后一个字符是 $’.’$部分域名：起始于一个节点，但未到根节点 2、域名空间三个部分：反向域、通用域和国家域【通用域】按照已经注册的主机的一般行为对主机进行定义 com edu gov info int mil org pro 【国家域】 cn us 【反向域】用于将地址映射为名字3、域名解析【递归解析】将客户机的请求不断传递给父服务器并等待响应，查询得到解析后响应后向传送直到最终到达发出请求的客户机【迭代解析】服务器或者发送应答，或者返回另一个服务器的IP地址，由客户机负责再次发送请求4、DNS报文【查询报文】——头部+查询记录【响应报文】——头部+查询记录+响应记录+授权部分+附加部分5、URL访问Web的主机统一命名：协议：//主机：//端口：//路径 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top Jiawei Hu, Computer Science and Technology, Xidian University https://jiaweihu-xdu.github.io/ References Behrouz, a.forouzan. (n.d.). 数据通信与网络 (原书第 4 版) http://m.cmpedu.com/books/book/2011466.htm 杨力. 2023年春, 计算机通信与网络, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/231806185.html","link":"/collaboration/ComputerNetwork/"},{"title":"数据库系统概论","text":"第一讲 数据库系统概述数据库基本概念 数据库(DataBase,DB) 概念: 长期存储在计算机内、有组织、可共享的数据集合 特点: 永久存储、有组织、可共享 数据库管理系统(DataBaseManagementSystem,DBMS) 概念: 专门用于管理数据库的软件 组成: 相互关联的数据集合、访问数据的程序 数据库系统(DataBaseSystem,DBS) 概念: 引入数据库之后的计算机系统 特点: DBS = DB + OS + DBMS + App + DBA +Users 数据库发展阶段 人工管理阶段 数据不保存 用户/应用程序管理数据 数据不共享，不独立 数据无结构 文件系统阶段 数据可以长期保存 文件系统管理数据 数据共享性差，冗余度大 物理独立性好，逻辑独立性差 记录内有结构，整体无结构 数据库系统阶段 数据可以永久保存 数据由DBMS管理 数据共享性高，冗余度小 具有高度的物理独立性，较好的逻辑独立性 统一数据模型，整体结构化 数据库管理系统采用外模式-模式-内模式三级模式，外模式/模式和模式/内模式两级映像结构来实现的。 数据模型 是数据及其联系在计算机中的表示和组织形式的描述 组成三要素: 数据结构、数据操纵、数据完整性约束 数据库模型 概念模型 E-R图 逻辑模型 层次模型 树状结构: 每个节点是基本单位称为记录，记录之间的联系以树形结构存储 特点: 只能处理一对多联系，无法处理多对多联系 网状模型 网状结构(有向图): 记录之间的联系用连线表达，联系必须标注名称 特点: 将多对多联系转换为多个一对多联系 关系模型 实体和联系都作为数据文件存储 物理模型 数据库系统结构 数据逻辑独立性：由外模式/模式映像保证（当模式改变，仅修改映像，即可保证外模式不变） 数据物理独立性：由模式/内模式映像保证（当内模式改变，仅修改映像，即可保证模式不变） 第二讲 关系模型关系数据结构关系模式: $R(U, D, Dom(), F)$ (简称: $R(U)$)其中，$R$ 表示关系名，$U$ 表示属性集，$D$ 表示关系的域，$Dom$ 表示属性到域上的映射关系，$F$ 表示数据依赖 关系代数 关系代数(Relational Algebra)是过程化的查询语言，是以集合为基础的运算表达式 传统集合运算 并(Union): From the row angle $R \\cup S$={$t|t\\in R\\vee t\\in S$} 差(Difference): From the row angle $R - S$={$t|t\\in R\\wedge t\\notin S$} 交(Intersection): From the row angle $R \\cap S$ = {$t|t\\in R\\wedge t\\in S$}=$R-(R-S)$ 广义笛卡尔积(Cartesian Product): From the row angle $R \\times S$ = {$\\widehat{t_rt_s}|t_r\\in R\\wedge t_s\\in S$} 注: R:$(k_1, n)$, S:$(k_2,m)\\Longrightarrow$R$\\times$S:$(k_1+k_2, n+m)$ 专门关系运算 选择(Selection): From the row angle $\\sigma_F(R)$ ={$t|t\\in R\\wedge F(t)=True$} 投影(Projection): From the column angle $\\pi_A(R)$ = {$t[A]|t\\in R$} 注: 选择出原关系中某些属性列，为避免重复，还可能会取消某些元组 连接(Join): From the cross angle $R\\underset{A\\theta B}{\\bowtie} S$ = {$t_r\\cup t_s|t_r\\in R\\wedge t_s\\in S\\wedge t_r[A]\\theta t_s[B]$} Solution Steps For $\\theta$ Join: Step 1: 确定结果中的属性列 Step 2: 确定参与比较的属性列 Step 3: 逐一取R中的元组分别和S中与其符合条件的元组进行拼接 等值连接(Equi-Join): $\\theta$ is “=” $R\\underset{A=B}{\\bowtie} S$ = {$t_r\\cup t_s|t_r\\in R\\wedge t_s\\in S\\wedge t_r[A]=t_s[B]$} 自然连接(Natural Join): $\\theta$ is “=” and $As = Bs$ which combines As and Bs columns avoiding repeated attributes(As, Bs means a column or multiple columns) $R\\bowtie S$ = {$t_r\\cup t_s - t_s[B]|t_r\\in R\\wedge t_s\\in S\\wedge t_r[B]=t_s[B]$} Practices Used Tables S Table = S(Sno, Sname, Ssex, Sage, Sdept) Sno Sname Ssex Sage Sdept 95001 李勇 男 20 CS 95002 刘晨 女 18 IS 95003 王敏 女 18 MA 95004 张立 男 19 IS SC Table = SC(Sno, Cno, Grade) Sno Cno Grade 95001 c1 92 95001 c2 65 95001 c4 88 95002 c2 90 95002 c5 73 SC$\\times$SC Table SC1.Sno SC1.Cno SC1.Grade SC2.Sno SC2.Cno SC2.Grade Problems 查询选修了 $C_2$ 和 $C_4$ 课程的学生学号 $$pi_1(\\sigma_{1=4\\wedge 2=’c2’\\wedge 5=’c4’}(SC\\times SC))$$ 查询不学 $C_2$ 课程的学生学号 $$pi_{sno}(S)-\\pi_{cno}(\\sigma_{cno=’c2’}(SC))$$ 关系模型由关系数据结构、关系操作集合和关系完整性约束组成 关系数据结构：单一的结构类型即关系，表示现实世界的实体以及实体间的联系 关系操作集合：查询、插入、删除、修改操作 关系完整性约束：实体完整性、参照完整性、用户定义完整性约束 关系数据库语言的共同特点：非过程化的集合操作语言 关系数据语言：关系代数语言、关系演算语言、SQL 第三讲 数据库完整性数据库完整性包括实体完整性、参照完整性和用户定义完整性。 实体完整性 CREATE TABLE 中用 PRIMARY KEY 定义关系模型的实体完整性 单属性构成的码： 定义为列级约束条件/定义为表级约束条件 多个属性构成的码： 定义为表级约束条件 References BitHachi's Blog 第三讲 SQL概述 SQL概述及数据定义——BitHachi's Blog SQL之数据查询——BitHachi's Blog SQL之基本表更新——BitHachi's Blog 第六讲 关系数据理论之规范化存在的问题关系模式中属性间存在某些依赖关系导致插入异常、删除异常、更新异常以及数据冗余的问题 数据依赖定义: 关系属性与属性之间的一种约束关系，即两个列或列组之间的约束，主要包含函数依赖与多值依赖。 函数依赖 (Functional Dependency, FD)定义: 对于任意关系 $r\\in R(U)$, $r$ 中不可能存在两个元组在 $X$ 上的属性值相等，而在 $Y$ 上的属性值不等。 $X\\rightarrow Y$: $X$ 函数确定 $Y$ 或 $Y$ 函数依赖于 $X$ Notes 函数依赖指 $R$ 的所有关系实例均要满足的约束条件 函数依赖属于语义范畴概念，只能根据数据的语义来确定函数依赖 特殊函数依赖 非平凡的函数依赖：$X\\rightarrow Y$ 且 $Y\\nsubseteq X$ 平凡的函数依赖：$X\\rightarrow Y$ 且 $Y\\subseteq X$ 相互决定: $X\\rightarrow Y$ 且 $Y\\rightarrow X$, denotes $X\\leftrightarrow Y$ $Y$ 不函数依赖于 $X$: $X \\nrightarrow Y$ 完全函数依赖：$X\\rightarrow Y$ 且 $ \\forall X’ \\subset X, X’ \\nrightarrow Y$, denotes $X\\mathop{\\longrightarrow}\\limits^F Y$ 部分函数依赖：$X\\rightarrow Y$ 且 $Y$ 不完全函数依赖于 $X$, denotes $X\\mathop{\\longrightarrow}\\limits^P Y$ 传递函数依赖：$X\\rightarrow Y, Y\\rightarrow Z$ with conditions $Y\\nsubseteq X, Y\\nrightarrow X$，则 $X\\rightarrow Z$, denotes $X\\mathop{\\longrightarrow}\\limits^T Y$ 如果 $Y\\rightarrow X$ 即 $X\\leftrightarrow Y$，则 $Z$ 直接依赖于 $X$ 如果 $Y\\subseteq X$, 则 $X\\mathop{\\longrightarrow}\\limits^P Z$ 候选码(Candidate Key) For $K$ in $R&lt;U, F&gt;$, satisfy $K\\mathop{\\longrightarrow}\\limits^F U$ 主码(Primary Key) 为选定的一个候选码 性质 决定性：$K\\rightarrow U$ 最小性: $\\nexists K’\\subset K$ let $K’\\rightarrow U$ 主属性(Prime Attribute): 所有候选码中出现的属性 非主属性(Nonprime Attribute): 不出现在任何候选码中的属性 全码(All Key): 由关系模式的所有属性构成码 外码(Foreign Key): $X$ 并非是 $R$ 的码，而是另外一个关系模式的码 规范化规范化设计关系表的规范化设计就是要尽可能地减少关系表中列或者列组之间的依赖关系，即函数依赖 范式(Normal Form, NF) Defination 1: 表示关系表的规范程度状态 Defination 2: 表示符合某一种级别的关系模式的集合 第一范式(First Normal Form, 1NF) Defination: 关系模式 $R$ 的所有属性都是不可分的基本数据项，denotes $R\\in 1NF$ 不满足第一范式的数据库模式不是关系数据库 第二范式(Second Normal Form, 2NF) Defination: $R\\in 1NF$ 并且每一个非主属性都完全函数依赖于 $R$ 的任一候选码, denotes $R\\in 2NF$ Notes 不存在非主属性对码的部分依赖 不属于 $2NF$ 关系模式问题：插入异常、删除异常、数据冗余大、修改异常 第三范式(Third Normal Form, 3NF) Defination: $R&lt;U, F&gt;$ 中不存在码 $X$、属性组 $Y$ 及非主属性 $Z(Z\\nsubseteq Y)$ 使得 $X\\rightarrow Y(Y\\nrightarrow X), Y\\rightarrow Z$, denotes $R\\in 3NF$ Notes If $Z\\subseteq Y$, then when $X\\rightarrow Y$, get $X\\rightarrow Z$ 不存在非主属性对码的传递依赖 不属于 $3NF$ 关系模式问题：插入异常、删除异常、数据冗余大、修改异常 修正第三范式(Boyce Codd Normal Form, BCNF) Defination: $R\\in 1NF$, for any $X\\rightarrow Y(Y\\nsubseteq X)$ and $X$ 必包含码, denotes $R\\in BCNF$ Notes 每一个函数依赖的决定因素都包含码 Handwritten Notes 数据库系统期末复习笔记 数据库系统课程实验报告 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top Changrong You, Computer Science and Technology, Xidian University https://cryoushiwo.github.io/ References 李翠敏. 2023年秋, 数据库系统, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/236212833.html","link":"/collaboration/DataBase/"},{"title":"Signal Filters Design Based on Digital Signal Processing","text":"ThoeriesI. Fourier Series Expansion AlgorithmWe can utilize the Fourier Series to produce the analog signal with some frequency components. For any signal, its Fourier series expansion is defined as $$x(t) = \\frac{A_0}{2}+\\sum_{n=1}^{\\infty}A_n\\cos(n\\Omega t+\\varphi_n)$$ In the equation，$\\frac{A_0}{2}$ represents the DC component, $A_1\\cos(\\Omega t+\\varphi_1)$, represents the fundamental component of the signal, $A_n\\cos(n\\Omega t+\\varphi_n)$ represents the nth harmonic component of the signal. Moreover, analog angular frequency $\\Omega = \\frac{2\\pi}{T}=2\\pi f$.Therefore, in this project we select three different frequency components, that is $f_1, f_2, f_3$, to synthesize the final required analog signal: $$x(t) = \\frac{A_0}{2}+A_1\\cos(2\\pi f_1t+\\varphi_1)+A_2\\cos(2\\times 2\\pi f_2t+\\varphi_2)+A_3\\cos(3\\times 2\\pi f_3t+\\varphi_3)$$ For simplicity, there we respectively select these values: $A_0=0, A_1=1, A_2=1, A_3=1$ $$ \\varphi_1=\\varphi_2=\\varphi_3=0 $$ Following above expression, we can get the generated analog signal: $$ x(t) = \\cos(2\\pi f_1t)+\\cos(4\\pi f_2t)+\\cos(6\\pi f_3t) $$ II. Sample the Analog SignalTime Domain Sampling TheoremAccording to the time domain sampling theorem, the sampling frequency must be greater than twice the signal cutoff frequency.Let’s assume that the sampling frequency is $F_s$, and the generated analog signal frequency satisfies: $F_1&lt;F_2&lt;F_3$, so the signal cutoff frequency is $F_c = F_3$. The sampling theorem is formally expressed as: $$F_s &gt; 2F_c$$ In this experiment，we respectively selected $F_1=10Hz, F_2=20Hz, F_3=30Hz$ to produce analog signal. So we can get the period and cutoff frequency of sampled signal: $$T_c = \\frac{1}{F_1}=0.1s, F_c = F_3 = 30Hz$$ Time-domain WindowFor periodic continuous signals, we intercept at integer multiples of the period to obtain a sequence for spectrum analysis. $$T_p=N*T_c, N\\in Z^+$$ Sampling FrequencyFor a specific sampling frequency, we can get the sampling period $T_s$, and the number of sampling points $N$: $$T_s = \\frac{1}{F_s}, N=T_p*F_c$$ Therefore, we use sampling frequency of $F_s=90Hz, F_s=60Hz, F_s=40Hz$ to get time-domain signals. Spectral ResolutionSpectral resolution is defined as the minimum separation between two signals of different frequencies: $$\\Delta f = \\frac{F_s}{N}=\\frac{1}{NT_s}=\\frac{1}{T_p}$$ III. Spectral AnalysisIn this section, we will analyse the Amplitude-Frequency Characteristics and Phase-Frequency Characteristics of the sampled signal. Convert to FrequencyWhen analysing the spectral, we need to convert the $0\\sim N-1$ to frequency sequence: $$f_k = k*\\frac{F_s}{N}, k=0,1,…N-1$$ Convert to Real AmplitudeAfter we apply Discrete Fourier Transform to the sampled signal, the frequency-domain signal is complex-valued. And due to the time-domain signal is real-valued, the the frequency-domain signal is conjugate symmetric: $$X(k) = X^*(N-k), k=0,1,…N-1$$ For complex values, that means its real part is even symmetric about the middle point, and its imaginary part is odd symmetric about the middle point. This will be showed in the following figures. ExperimentsExperiment I: $T_p=3T_c, F_s=90$Hz Samping Frequency $F_s = 3F_c(F_s &gt; 2F_c)$We use the sampling frequency of $F_s=90$Hz under the condition of $T_p=3T_c$. ConclusionsThe sampling frequency satisfies the Time Domain Sampling Theorem so we can see there is no overlap in frequency domain about the amplitude-frequency characteristic. And when $f=10$Hz, $f=20$Hz, $f=30$Hz, we can get the amplitude very close to $1$ which is us defined in analop signal. Experiment II: $T_p=3T_c, F_s=60$Hz Samping Frequency $F_s = 2F_c(F_s = 2F_c)$We use the sampling frequency of $F_s=60$Hz under the condition of $T_p=3T_c$. ConclusionsThe sampling frequency equals the threhold of Time Domain Sampling Theorem so we can easily see that it will just become overlapping in frequency domain. And when $f=30$Hz that is also $F_s/2$ point, we can get this point very close to its symmetric frequency point. Experiment III: $T_p=3T_c, F_s=40$Hz Samping Frequency $F_s = \\frac{4}{3}F_c(F_s &lt; 2F_c)$We use the sampling frequency of $F_s=40$Hz under the condition of $T_p=3T_c$. ConclusionsThe sampling frequency do not equal the Time Domain Sampling Theorem so we can obviously see that it has discarded the third frequency $f=30$Hz, which is caused by overlapping in frequency domain. Note: in order to clearly analyse spectral of sampled signal, we also select the Time-domain Window of $T_p=50T_c$ to conduct experiments. Results Codesmain12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182%% Project Introduction:% This project is developed to design some signal filters based on digital% signal processing.clear, close all;%% Produce and sample digital signalf1 = 10;f2 = 20;f3 = 30; % so the fc = f3 = 30HzNp = 50; % number of periods for time-domain window%% Experiment 1 (Choosing samling frequency fs = 3fc (fs &gt; 2fs))fs1 = 90; % sampling frequencyxn1 = ProduceSamplingSignal(f1, f2, f3, fs1, Np, 'Sampling Analog Signal(fs = 3fc)');DFTAnalysis(xn1, fs1, 'Frequency Response Characteristics(fs = 3fc)');%% Experiment 2 (Choosing samling frequency fs = 2fc)fs2 = 60; % sampling frequencyxn2 = ProduceSamplingSignal(f1, f2, f3, fs2, Np, 'Sampling Analog Signal(fs = 2fc)');DFTAnalysis(xn2, fs2, 'Frequency Response Characteristics(fs = 2fc)');%% Experiment 3 (Choosing samling frequency fs &lt; 2fc)fs3 = 40; % sampling frequencyxn3 = ProduceSamplingSignal(f1, f2, f3, fs3, Np, 'Sampling Analog Signal(fs &lt; 2fc)');DFTAnalysis(xn3, fs3, 'Frequency Response Characteristics(fs &lt; 2fc)');%% Experiment Description% Experiment 4-7: Design a digital filter respectively with band pass, high% pass, low pass, band stop based on ellipord.%% Experiment 4: Design a digital filter with band pass using ellipordfpl = 15; fpu=25; fsl=13; fsu=28;rp = 1; rs = 40;ellipBandPass(fpl, fpu, fsl, fsu, rp, rs, xn1, fs1, f1, Np, 'Digital Filter With Band Pass Using Ellipord(fs = 3fc)');ellipBandPass(fpl, fpu, fsl, fsu, rp, rs, xn2, fs2, f1, Np, 'Digital Filter With Band Pass Using Ellipord(fs = 2fc)');ellipBandPass(8, 10, 6, 12, rp, rs, xn3, fs3, f1, Np, 'Digital Filter With Band Pass Using Ellipord(fs &lt; 2fc)');%% Experiment 5: Design a digital filter with high pass using ellipordfpz = 16; fsz = 13;rp = 1; rs = 40;ellipHighPass(fpz, fsz, rp, rs, xn1, fs1, f1, Np, 'Digital Filter With High Pass Using Ellipord(fs = 3fc)');ellipHighPass(fpz, fsz, rp, rs, xn2, fs2, f1, Np, 'Digital Filter With High Pass Using Ellipord(fs = 2fc)');ellipHighPass(15, 12, rp, rs, xn3, fs3, f1, Np, 'Digital Filter With High Pass Using Ellipord(fs &lt; 2fc)');%% Experiment 6: Design a digital filter with low pass using ellipordfpz = 23; fsz=28; rp = 1; rs = 40;ellipLowPass(fpz, fsz, rp, rs, xn1, fs1, f1, Np, 'Digital Filter With Low Pass Using Ellipord(fs = 3fc)');ellipLowPass(fpz, fsz, rp, rs, xn2, fs2, f1, Np, 'Digital Filter With Low Pass Using Ellipord(fs = 2fc)');ellipLowPass(12, 15, rp, rs, xn3, fs3, f1, Np, 'Digital Filter With Low Pass Using Ellipord(fs &lt; 2fc)');%% Experiment 7: Design a digital filter with band stop using ellipordfpl = 15; fpu=25; fsl=17; fsu=22;rp = 1; rs = 40;ellipBandStop(fpl, fpu, fsl, fsu, rp, rs, xn1, fs1, f1, Np, 'Digital Filter With Band Stop Using Ellipord(fs = 3fc)');ellipBandStop(fpl, fpu, fsl, fsu, rp, rs, xn2, fs2, f1, Np, 'Digital Filter With Band Stop Using Ellipord(fs = 2fc)');ellipBandStop(5, 17, 8, 12, rp, rs, xn3, fs3, f1, Np, 'Digital Filter With Band Stop Using Ellipord(fs &lt; 2fc)');%% Experiment Description% Experiment 8-11: Design a digital filter respectively with high pass, low% pass, band pass, band stop based on hamming window.%% Experiment 8: Design a digital filter with high pass using hamming windowfpz = 16; fsz = 13;firlHighPass(fpz, fsz, xn1, fs1, f1, Np, 'Digital Filter With High Pass Using Hamming Window(fs = 3fc)');firlHighPass(fpz, fsz, xn2, fs2, f1, Np, 'Digital Filter With High Pass Using Hamming Window(fs = 2fc)');firlHighPass(15, 12, xn3, fs3, f1, Np, 'Digital Filter With High Pass Using Hamming Window(fs &lt; 2fc)');%% Experiment 9: Design a digital filter with low pass using hamming windowfpz = 23; fsz = 28;firlLowPass(fpz, fsz, xn1, fs1, f1, Np, 'Digital Filter With Low Pass Using Hamming Window(fs = 3fc)');firlLowPass(fpz, fsz, xn2, fs2, f1, Np, 'Digital Filter With Low Pass Using Hamming Window(fs = 2fc)');firlLowPass(13, 17, xn3, fs3, f1, Np, 'Digital Filter With Low Pass Using Hamming Window(fs &lt; 2fc)');%% Experiment 10: Design a digital filter with band pass using hamming windowfpl = 15; fpu = 25;firlBandPass(fpl, fpu, xn1, fs1, f1, Np, 'Digital Filter With Band Pass Using Hamming Window(fs = 3fc)');firlBandPass(fpl, fpu, xn2, fs2, f1, Np, 'Digital Filter With Band Pass Using Hamming Window(fs = 2fc)');firlBandPass(7, 15, xn3, fs3, f1, Np, 'Digital Filter With Band Pass Using Hamming Window(fs &lt; 2fc)');%% Experiment 11: Design a digital filter with band stop using hamming windowfsl = 15; fsu = 25;firlBandStop(fsl, fsu, xn1, fs1, f1, Np, 'Digital Filter With Band Stop Using Hamming Window(fs = 3fc)');firlBandStop(fsl, fsu, xn2, fs2, f1, Np, 'Digital Filter With Band Stop Using Hamming Window(fs = 2fc)');firlBandStop(7, 15, xn3, fs3, f1, Np, 'Digital Filter With Band Band Stop Hamming Window(fs &lt; 2fc)'); ProduceSamplingSignal1234567891011121314151617181920212223242526272829303132333435363738394041function xn = ProduceSamplingSignal(f1, f2, f3, fs, Np, Alltitle)% Function Description: % We want to make a digital signal composed of three frequency% components and sample the produced signal.% Inputs: % f1, f2, f3: means our selected frequency components, fs% represents the sampling frequency.% Np: means the number of periods.% Outputs:% xn: represents the sampled signal. period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points % t = 0: 0.0001: T; % analog time sequence % Step I: Produce digital signal xt = cos(2*pi*f1*t) + cos(2*pi*f2*t) + cos(2*pi*f3*t); % Step II: Sample produced signal xn = cos(2*pi*f1*t) + cos(2*pi*f2*t) + cos(2*pi*f3*t); % Step III: Visualize produced signal and sampled signal figure('Position', [210, 80, 950, 750]); subplot(2, 1, 1); plot(t, xt); title('Time-domain signal $x(t)$', 'Interpreter', 'latex', 'FontSize', 12); xlabel('$t/s$', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); ylim([-2.5, 3.5]); grid on subplot(2, 1, 2); stem(t, xn); title('Time-domain sampled signal $x(n)$', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); xlabel('$t/s$', 'Interpreter', 'latex', 'FontSize', 12); ylim([-2.5, 3.5]); grid on sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end DFTAnalysis12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455function DFTAnalysis(xn, fs, Alltitle)% Function Description:% This function calculates the DFT[x(n)] and do spectral analysis.% Inputs:% xn: digital discrete signal% fs: sampling frequency% Outputs:% No return N = length(xn); % number of sampling points df = fs / N; % spectral resolution f1 = (0:N-1)*df; % tranverse to the frequncy sequence f2 = 2*(0:N-1)/N; % DFT using FFT algorithm Xk = fft(xn, N); % Tranverse to the real amplitude RM = 2*abs(Xk)/N; Angle = angle(Xk); figure('Position', [210, 80, 950, 750]); % Amplitude-Frequency Characteristics subplot(4,1,1); stem(f1, RM,'.'); title('Amplitude-Frequency Characteristics', 'Interpreter', 'latex', 'FontSize', 12); xlabel('$f$/Hz', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; % Phase-Frequency Characteristics subplot(4,1,2); stem(f1, Angle,'.'); line([(N-1)*df, 0],[0,0]); title('Phase-Frequency Characteristics', 'Interpreter', 'latex', 'FontSize', 12); xlabel('$f$/Hz', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); grid on; % Amplitude-Frequency Characteristics subplot(4,1,3); plot(f2, abs(Xk)); title('Amplitude-Frequency Characteristics', 'Interpreter', 'latex', 'FontSize', 12); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; % Phase-Frequency Characteristics subplot(4,1,4); plot(f2, Angle); title('Phase-Frequency Characteristics', 'Interpreter', 'latex', 'FontSize', 12); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); ylim([-3.5, 3.5]); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end ellipBandPass12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function ellipBandPass(fpl, fpu, fsl, fsu, rp, rs, x, fs, f1, Np, Alltitle) wp = [2*fpl/fs, 2*fpu/fs]; ws = [2*fsl/fs, 2*fsu/fs]; [N, wn] = ellipord(wp, ws, rp, rs); % 获取阶数和截止频率 [B, A] = ellip(N, rp, rs, wn, 'bandpass'); % 获得转移函数系数 filter_bp_s = filter(B, A, x); X_bp_s = abs(fft(filter_bp_s)); X_bp_s_angle = angle(fft(filter_bp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; % 带通滤波器频谱特性 figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 512; wk = 0:pi/M:pi; Hz = freqz(B,A,wk); plot(wk/pi, 20*log10(abs(Hz))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('带通滤波器频谱特性'); axis([0.2,0.9,-80,20]);set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20); grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_bp_s); xlabel('t/s', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_bp_s); title('带通滤波后频域幅度特性'); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_bp_s_angle); title('带通滤波后频域相位特性'); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); ylim([-3.5, 3.5]); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end ellipHighPass123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354function ellipHighPass(fpz, fsz, rp, rs, x, fs, f1, Np, Alltitle) wpz = 2*fpz/fs; wsz = 2*fsz/fs; [N, wn] = ellipord(wpz, wsz, rp, rs); % 获取阶数和截止频率 [B, A] = ellip(N, rp, rs, wn, 'high'); % 获得转移函数系数 filter_hp_s = filter(B, A, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; % 高通滤波器频谱特性 figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 512; wk = 0:pi/M:pi; Hz = freqz(B,A,wk); plot(wk/pi, 20*log10(abs(Hz))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('高通滤波器频谱特性'); axis([0.2,0.8,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20); grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('高通滤波后时域图形'); xlabel('t/s', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('高通滤波后频域幅度特性'); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('高通滤波后频域相位特性'); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); ylim([-3.5, 3.5]); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end ellipLowPass123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354function ellipLowPass(fpz, fsz, rp, rs, x, fs, f1, Np, Alltitle) wpz = 2*fpz/fs; wsz = 2*fsz/fs; [N, wn] = ellipord(wpz, wsz, rp, rs); % 获取阶数和截止频率 [B, A] = ellip(N, rp, rs, wn, 'low'); % 获得转移函数系数 filter_hp_s = filter(B, A, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; % 低通滤波器频谱特性 figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 512; wk = 0:pi/M:pi; Hz = freqz(B,A,wk); plot(wk/pi, 20 * log10(abs(Hz))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('低通滤波器频谱特性'); axis([0.2,0.9,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20) grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('低通滤波后时域图形'); xlabel('t/s', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('低通滤波后频域幅度特性'); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('低通滤波后频域相位特性'); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); ylim([-3.5, 3.5]); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end ellipBandStop123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354function ellipBandStop(fpl, fpu, fsl, fsu, rp, rs, x, fs, f1, Np, Alltitle) wp = [2*fpl/fs, 2*fpu/fs]; ws = [2*fsl/fs, 2*fsu/fs]; [N, wn] = ellipord(wp, ws, rp, rs); % 获取阶数和截止频率 [B, A] = ellip(N, rp, rs, wn, 'stop'); % 获得转移函数系数 filter_bp_s = filter(B, A, x); X_bp_s = abs(fft(filter_bp_s)); X_bp_s_angle = angle(fft(filter_bp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; % 带阻滤波器频谱特性 figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 512; wk = 0:pi/M:pi; Hz = freqz(B,A,wk); plot(wk/pi, 20*log10(abs(Hz))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('带阻滤波器频谱特性'); axis([0.2,0.9,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20); grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_bp_s); title('带阻滤波后时域图形'); xlabel('t/s', 'Interpreter', 'latex', 'FontSize', 12); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_bp_s); title('带阻滤波后频域幅度特性'); ylabel('Amplitude', 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_bp_s_angle); title('带阻滤波后频域相位特性'); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('Phase', 'Interpreter', 'latex', 'FontSize', 12); ylim([-3.5, 3.5]); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end firlHighPass1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162function firlHighPass(fpz, fsz, x, fs, f1, Np, Alltitle) wpz = 2 * pi * fpz / fs; wsz = 2 * pi * fsz / fs; DB = wpz - wsz; % 计算过渡带宽度 N0 = ceil(6.2 * pi / DB); % 计算所需h(n)长度N0 N = N0 + mod(N0 + 1, 2); % 确保h(n)长度N是奇数 wc = (wpz + wsz) /2 / pi; % 计算理想高通滤波器通带截止频率 hn = fir1(N-1, wc, 'high', hamming(N)); filter_hp_s = filter(hn, 1, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 1024; k = 1:M / 2; wk = 2*(0:M/2-1)/M; Hz = freqz(hn, 1); plot(wk, 20*log10(abs(Hz(k)))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('高通滤波器频谱特性') axis([0.2,0.8,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20) grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('高通滤波后时域图形'); txt = xlabel('t/s', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('高通滤波后频域幅度特性'); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('高通滤波后频域相位特性'); txt = ylabel('Phase', 'FontSize', 12); ylim([-3.5, 3.5]); xlabel('\\omega/\\pi', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end firlLowPass1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162function firlLowPass(fpz, fsz, x, fs, f1, Np, Alltitle) wpz = 2 * pi * fpz / fs; wsz = 2 * pi * fsz / fs; DB = wsz - wpz; N0 = ceil(6.2 * pi / DB); N = N0 + mod(N0 + 1, 2); wc = (wpz + wsz) / 2 / pi; hn = fir1(N-1, wc, 'low', hamming(N)); filter_hp_s = filter(hn, 1, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 1024; k = 1:M / 2; wk = 2*(0:M/2-1)/M; Hz = freqz(hn, 1); plot(wk, 20*log10(abs(Hz(k)))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('低通滤波器频谱特性') axis([0.2,0.9,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20) grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('低通滤波后时域图形'); txt = xlabel('t/s', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('低通滤波后频域幅度特性'); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('低通滤波后频域相位特性'); txt = ylabel('Phase', 'FontSize', 12); ylim([-3.5, 3.5]); xlabel('\\omega/\\pi', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end firlBandPass1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function firlBandPass(fpl, fpu, x, fs, f1, Np, Alltitle) wpl = 2 * fpl / fs; wpu = 2 * fpu / fs; fpass = [wpl, wpu]; N = 111; hn = fir1(N-1, fpass, 'bandpass', hamming(N)); filter_hp_s = filter(hn, 1, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 1024; k = 1:M / 2; wk = 2*(0:M/2-1)/M; Hz = freqz(hn, 1); plot(wk, 20*log10(abs(Hz(k)))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('带通滤波器频谱特性') axis([0.2,0.9,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20) grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('带通滤波后时域图形'); txt = xlabel('t/s', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('带通滤波后频域幅度特性'); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('带通滤波后频域相位特性'); txt = ylabel('Phase', 'FontSize', 12); ylim([-3.5, 3.5]); xlabel('\\omega/\\pi', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end firlBandStop1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function firlBandStop(fsl, fsu, x, fs, f1, Np, Alltitle) wsl = 2 * fsl / fs; wsu = 2 * fsu / fs; fstop = [wsl, wsu]; N = 111; hn = fir1(N-1, fstop, 'stop', hamming(N)); filter_hp_s = filter(hn, 1, x); X_hp_s = abs(fft(filter_hp_s)); X_hp_s_angle = angle(fft(filter_hp_s)); % plot the graphs period = 1/f1; % the period of analog signal(assuming f1 is the minimal) T = Np*period; % sampling time-domain window(several periods) Ts = 1 / fs; % sampling timestep t = 0: Ts : T; % samping sequence of discrete sampling points N = length(x); % number of sampling points f = 2*(0:N-1)/N; figure('Position', [210, 80, 950, 750]); subplot(4,4,[1,2,5,6]); M = 1024; k = 1:M / 2; wk = 2*(0:M/2-1)/M; Hz = freqz(hn, 1); plot(wk, 20*log10(abs(Hz(k)))); xlabel('\\omega/\\pi', 'FontSize', 12); ylabel('$20lg|Hg(\\omega)|$', 'Interpreter', 'latex', 'FontSize', 12); title('带阻滤波器频谱特性') axis([0.2,0.9,-80,20]); set(gca,'Xtick',0:0.1:1,'Ytick',-80:20:20) grid on; subplot(4,4,[3,4,7,8]); plot(t, filter_hp_s); title('带阻滤波后时域图形'); txt = xlabel('t/s', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[9, 10, 11, 12]); plot(f, X_hp_s); title('带阻滤波后频域幅度特性'); txt = ylabel('Amplitude', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; subplot(4,4,[13, 14, 15, 16]); plot(f, X_hp_s_angle); title('带阻滤波后频域相位特性'); txt = ylabel('Phase', 'FontSize', 12); ylim([-3.5, 3.5]); xlabel('\\omega/\\pi', 'FontSize', 12); set(txt, 'Interpreter', 'latex', 'FontSize', 12); grid on; sgtitle(Alltitle, 'FontName', 'Times New Roman', 'FontSize', 14);end 数字信号处理学习笔记 本章节主要是在课程学习过程中整理出的笔记文档。 数字信号处理学习笔记，计算机科学与技术嵌入式系统方向，西安电子科技大学 https://github.com/LZHMS/LZHMS.github.io/blob/master/source/pdf/collaboration/DigitalSignalProcessingNotes.pdf Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top Reference 王文俊. 2023年秋, 数字信号处理, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/236249651.html","link":"/collaboration/DigitalSignalProcessing/"},{"title":"嵌入式程序设计","text":"前言 课程实验、复习、期末试题资源详见阿里云盘链接 思维导图 用 Qt 编写嵌入式 GUI 程序——加减乘除四则运算器设计头文件calculator.h1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#ifndef CALCULATOR_H#define CALCULATOR_H //对 calculator.h 头文件的声明#include &lt;QWidget&gt; //包含主窗体类#include &lt;QPushButton&gt; //包含按键类#include &lt;QVBoxLayout&gt; //包含垂直布局器类#include &lt;QHBoxLayout&gt; //包含水平布局器类#include &lt;QLineEdit&gt; //包含显示框类#include &lt;QStack&gt;class Calculator : public QWidget //计算器继承自主窗体类{ Q_OBJECT //必须加上这句，如果要调用信号，槽函数的操作的话public: Calculator(); //计算器类的构造函数 ~Calculator(); //计算器类的析构函数public slots: //定义各个按键按下后对应操作处理的槽函数 void zeroButtonPress(); void oneButtonPress(); void twoButtonPress(); void threeButtonPress(); void fourButtonPress(); void fiveButtonPress(); void sixButtonPress(); void sevenButtonPress(); void eightButtonPress(); void nineButtonPress(); void addButtonPress(); void subButtonPress(); void mulButtonPress(); void divButtonPress(); void clearButtonPress(); void equButtonPress();private: QLineEdit *operateEdit;//声明显示框 QPushButton *zeroButton;//声明数字按键¹ QPushButton *oneButton; QPushButton *twoButton; QPushButton *threeButton; QPushButton *fourButton; QPushButton *fiveButton; QPushButton *sixButton; QPushButton *sevenButton; QPushButton *eightButton; QPushButton *nineButton; QPushButton *clearButton;//声明运算符按键 QPushButton *addButton; QPushButton *subButton; QPushButton *divButton; QPushButton *mulButton; QPushButton *equButton; QHBoxLayout *firstLayout;//声明水平布局器，该布局器主要对 16 个按键进行布局 QHBoxLayout *secondLayout; QHBoxLayout *thirdLayout; QHBoxLayout *fourthLayout; QVBoxLayout *mainLayout;//声明垂直布局器，该布局器主要对主窗体上面的空间进行排布 QString expression; int precedence(QChar op); float calculator(float a,float b,QChar op);};#endif // CALCULATOR_H 源文件calculator.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421#include&quot;calculator.h&quot;Calculator::Calculator(){ operateEdit = new QLineEdit(this);//初始化显示框 operateEdit-&gt;setReadOnly(true); //设置显示框为只读 operateEdit-&gt;setText(tr(&quot;0&quot;));//初始化显示框显示数据为0 zeroButton = new QPushButton;//初始化按键 zeroButton-&gt;setText(tr(&quot;0&quot;));//设置按键上显示的标签，以下对按键相关的操作类似 oneButton = new QPushButton; oneButton-&gt;setText(tr(&quot;1&quot;)); twoButton = new QPushButton; twoButton-&gt;setText(tr(&quot;2&quot;)); threeButton = new QPushButton; threeButton-&gt;setText(tr(&quot;3&quot;)); fourButton = new QPushButton; fourButton-&gt;setText(tr(&quot;4&quot;)); fiveButton = new QPushButton; fiveButton-&gt;setText(tr(&quot;5&quot;)); sixButton = new QPushButton; sixButton-&gt;setText(tr(&quot;6&quot;)); sevenButton = new QPushButton; sevenButton-&gt;setText(tr(&quot;7&quot;)); eightButton = new QPushButton; eightButton-&gt;setText(tr(&quot;8&quot;)); nineButton = new QPushButton; nineButton-&gt;setText(tr(&quot;9&quot;)); clearButton = new QPushButton; clearButton-&gt;setText(tr(&quot;Clear&quot;)); addButton = new QPushButton; addButton-&gt;setText(tr(&quot;+&quot;)); subButton = new QPushButton; subButton-&gt;setText(tr(&quot;-&quot;)); mulButton = new QPushButton; mulButton-&gt;setText(tr(&quot;*&quot;)); divButton = new QPushButton; divButton-&gt;setText(tr(&quot;/&quot;)); equButton = new QPushButton; equButton-&gt;setText(tr(&quot;=&quot;)); firstLayout = new QHBoxLayout;//初始化水平布局器 firstLayout firstLayout-&gt;addWidget(zeroButton); //把按键 zeroButton 添加到 firstLayout firstLayout-&gt;addWidget(oneButton); //把按键 oneButton 添加到 firstLayout firstLayout-&gt;addWidget(twoButton); //把按键 twoButton 添加到 firstLayout firstLayout-&gt;addWidget(addButton); //把按键 threeButton 添加到 firstLayout，以下对水平布局器的操作类似 secondLayout = new QHBoxLayout; secondLayout-&gt;addWidget(threeButton); secondLayout-&gt;addWidget(fourButton); secondLayout-&gt;addWidget(fiveButton); secondLayout-&gt;addWidget(subButton); thirdLayout = new QHBoxLayout; thirdLayout-&gt;addWidget(sixButton); thirdLayout-&gt;addWidget(sevenButton); thirdLayout-&gt;addWidget(eightButton); thirdLayout-&gt;addWidget(mulButton); fourthLayout = new QHBoxLayout; fourthLayout-&gt;addWidget(nineButton); fourthLayout-&gt;addWidget(clearButton); fourthLayout-&gt;addWidget(equButton); fourthLayout-&gt;addWidget(divButton); mainLayout = new QVBoxLayout(this);//初始化垂直布局器 mainLayout mainLayout-&gt;addWidget(operateEdit); //把显示数据框 operateEdit 加到 mainLayout mainLayout-&gt;addLayout(firstLayout); //把水平布局器 firstLayout 添加到 mainLayout mainLayout-&gt;addLayout(secondLayout); //把水平布局器 secondLayout 添加到mainLayout mainLayout-&gt;addLayout(thirdLayout); //把水平布局器 thirdLayout 添加到 mainLayout mainLayout-&gt;addLayout(fourthLayout); //把水平布局器 fourthLayout 添加到 mainLayoutconnect(zeroButton,SIGNAL(clicked()),this,SLOT(zeroButtonPress()));//把按键 zeroButton 的按下事件同 zeroButtonPress()绑定到一起，以下操作类似 connect(oneButton,SIGNAL(clicked()),this,SLOT(oneButtonPress())); connect(twoButton,SIGNAL(clicked()),this,SLOT(twoButtonPress())); connect(threeButton,SIGNAL(clicked()),this,SLOT(threeButtonPress())); connect(fourButton,SIGNAL(clicked()),this,SLOT(fourButtonPress())); connect(fiveButton,SIGNAL(clicked()),this,SLOT(fiveButtonPress())); connect(sixButton,SIGNAL(clicked()),this,SLOT(sixButtonPress())); connect(sevenButton,SIGNAL(clicked()),this,SLOT(sevenButtonPress())); connect(eightButton,SIGNAL(clicked()),this,SLOT(eightButtonPress())); connect(nineButton,SIGNAL(clicked()),this,SLOT(nineButtonPress())); connect(addButton,SIGNAL(clicked()),this,SLOT(addButtonPress())); connect(subButton,SIGNAL(clicked()),this,SLOT(subButtonPress())); connect(mulButton,SIGNAL(clicked()),this,SLOT(mulButtonPress())); connect(divButton,SIGNAL(clicked()),this,SLOT(divButtonPress())); connect(equButton,SIGNAL(clicked()),this,SLOT(equButtonPress())); connect(clearButton,SIGNAL(clicked()),this,SLOT(clearButtonPress())); this-&gt;setWindowTitle(tr(&quot;Calculator&quot;));//设置窗体标题为 Calculator expression=&quot;&quot;;}Calculator::~Calculator(){ if (operateEdit != NULL) { delete operateEdit; operateEdit = NULL; } if (zeroButton != NULL) { delete zeroButton; zeroButton = NULL; } if (oneButton != NULL) { delete oneButton; oneButton = NULL; } if (twoButton != NULL) { delete twoButton; twoButton = NULL; } if (threeButton != NULL) { delete threeButton; threeButton = NULL; } if (fourButton != NULL) { delete fourButton; fourButton = NULL; } if (fiveButton != NULL) { delete fiveButton; fiveButton = NULL; } if (sixButton != NULL) { delete sixButton; sixButton = NULL; } if (sevenButton != NULL) { delete sevenButton; sevenButton = NULL; } if (eightButton != NULL) { delete eightButton; eightButton = NULL; } if (nineButton != NULL) { delete nineButton; nineButton = NULL; } if (clearButton != NULL) { delete clearButton; clearButton = NULL; } if (addButton != NULL) { delete addButton; addButton = NULL; } if (subButton != NULL) { delete subButton; subButton = NULL; } if (mulButton != NULL) { delete mulButton; mulButton = NULL; } if (divButton != NULL) { delete divButton; divButton = NULL; } if (equButton != NULL) { delete equButton; equButton = NULL; } if (firstLayout != NULL) { delete firstLayout; firstLayout = NULL; } if (secondLayout != NULL) { delete secondLayout; secondLayout = NULL; } if (thirdLayout != NULL) { delete thirdLayout; thirdLayout = NULL; } if (fourthLayout != NULL) { delete fourthLayout; fourthLayout = NULL; } if (mainLayout != NULL) { delete mainLayout; mainLayout = NULL; }}void Calculator::zeroButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression += &quot;0&quot;; } else { expression.append(&quot;0&quot;); } operateEdit-&gt;setText(expression);}void Calculator::oneButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;1&quot;; } else { expression.append(&quot;1&quot;); } operateEdit-&gt;setText(expression);}void Calculator::twoButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;2&quot;; } else { expression.append(&quot;2&quot;); } operateEdit-&gt;setText(expression);}void Calculator::threeButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;3&quot;; } else { expression.append(&quot;3&quot;); } operateEdit-&gt;setText(expression);}void Calculator::fourButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;4&quot;; } else { expression.append(&quot;4&quot;); } operateEdit-&gt;setText(expression);}void Calculator::fiveButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;5&quot;; } else { expression.append(&quot;5&quot;); } operateEdit-&gt;setText(expression);}void Calculator::sixButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;6&quot;; } else { expression.append(&quot;6&quot;); } operateEdit-&gt;setText(expression);}void Calculator::sevenButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;7&quot;; } else { expression.append(&quot;7&quot;); } operateEdit-&gt;setText(expression);}void Calculator::eightButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;8&quot;; } else { expression.append(&quot;8&quot;); } operateEdit-&gt;setText(expression);}void Calculator::nineButtonPress(){ if(expression.isEmpty() || expression.endsWith('0')) { expression = &quot;9&quot;; } else { expression.append(&quot;9&quot;); } operateEdit-&gt;setText(expression);}void Calculator::addButtonPress(){ if(!expression.isEmpty() &amp;&amp; !expression.endsWith('+') &amp;&amp; !expression.endsWith('-') &amp;&amp; !expression.endsWith('*') &amp;&amp; !expression.endsWith('/')) { expression.append(&quot;+&quot;); } operateEdit-&gt;setText(expression);}void Calculator::subButtonPress(){ if(!expression.isEmpty() &amp;&amp; !expression.endsWith('+') &amp;&amp; !expression.endsWith('-') &amp;&amp; !expression.endsWith('*') &amp;&amp; !expression.endsWith('/')) { expression.append(&quot;-&quot;); } operateEdit-&gt;setText(expression);}void Calculator::mulButtonPress(){ if(!expression.isEmpty() &amp;&amp; !expression.endsWith('+') &amp;&amp; !expression.endsWith('-') &amp;&amp; !expression.endsWith('*') &amp;&amp; !expression.endsWith('/')) { expression.append(&quot;*&quot;); } operateEdit-&gt;setText(expression);}void Calculator::divButtonPress(){ if(!expression.isEmpty() &amp;&amp; !expression.endsWith('+') &amp;&amp; !expression.endsWith('-') &amp;&amp; !expression.endsWith('*') &amp;&amp; !expression.endsWith('/')) { expression.append(&quot;/&quot;); } operateEdit-&gt;setText(expression);}void Calculator::clearButtonPress(){ expression.clear(); operateEdit-&gt;setText(&quot;0&quot;);}//等号操作响应函数void Calculator::equButtonPress(){ if(expression.isEmpty()) { return; } QStack&lt;float&gt; numbers; QStack&lt;QChar&gt; operators; QString number; for(int i = 0; i &lt; expression.size(); ++i) { QChar c = expression.at(i); if(c.isDigit() || c == '.') { number.append(c); } else { if(!number.isEmpty()) { numbers.push(number.toFloat()); number.clear(); } while(!operators.isEmpty() &amp;&amp; precedence(operators.top()) &gt;= precedence(c)) { float second = numbers.pop(); float first = numbers.pop(); QChar op = operators.pop(); numbers.push(calculator(first, second, op)); } operators.push(c); } } if(!number.isEmpty()) { numbers.push(number.toFloat()); } while(!operators.isEmpty()) { float second = numbers.pop(); float first = numbers.pop(); QChar op = operators.pop(); numbers.push(calculator(first, second, op)); } float result = numbers.pop(); expression = QString::number(result, 'f', 7); operateEdit-&gt;setText(expression);}int Calculator::precedence(QChar op){ if(op == '+' || op == '-') { return 1; } else if(op == '*' || op == '/') { return 2; } return 0;}float Calculator::calculator(float a, float b, QChar op){ switch(op.toLatin1()) { case '+': return a + b; case '-': return a - b; case '*': return a * b; case '/': return a / b; } return 0;} 主函数main.cpp123456789#include &lt;QApplication&gt;//包含应用程序类#include &quot;calculator.h&quot;//包含计算器类int main(int argc, char *argv[])//main 函数的标准写法{ QApplication app(argc, argv); //创建一个 QApplication 对象，管理应用程序的资源 Calculator mainwindow; //产生一个计算器对象 mainwindow.showMaximized();//显示计算器窗体(默认以最大化的形式显示) return app.exec();//让程序进入消息循环，等待可能的菜单、工具条、鼠标等的输入，} 编写嵌入式 Linux 设备驱动程序——LED驱动程序Notes insmod led_driver.ko 加载 LED 驱动模块 lsmod 查看目标机中已经加载的所有模块 cat /proc/devices 查看目标机中已经加载的所有设备，包括字符设备、块设备 rmmod led_driver.ko 卸载 LED 驱动模块 mknod /dev/XXX c #### x 创建 LED 设备文件节点 XXX 表示设备名，Linux 根据设备名创建设备目录；本实验中表示 led_light2 即指 LED 设备的第二个驱动程序，默认驱动程序为 led_light; c 表示字符设备 #### 表示主设备号 x 表示次设备号 ls /dev 查看创建的所有设备 rmmod led_driver.ko 卸载 LED 驱动模块 Codes Modification实验手册中给定的模块删除代码为： 12345678910/*模块的退出*/static void __exit s5pv210_led_exit(void){/* -------------------------------- */device_destroy(led_dev_class,DEVICE_NODE);/* ---------------------------------- */class_destroy(led_dev_class);cdev_del(cdev_p);unregister_chrdev_region(num_dev,1);} 根据设备文件节点是无法移除设备的，Linux 通过分配的设备号（主设备号、次设备号）来注册设备的，因此需要删除设备对应的设备号 num_dev，修改后的代码为： 12345678910/*模块的退出*/static void __exit s5pv210_led_exit(void){/* -------------------------------- */device_destroy(led_dev_class,num_dev);/* ---------------------------------- */class_destroy(led_dev_class);cdev_del(cdev_p);unregister_chrdev_region(num_dev,1);} 模块驱动程序led_driver.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;#include&lt;linux/sched.h&gt;#include&lt;linux/kernel.h&gt;#include &lt;asm/uaccess.h&gt;#include &lt;plat/gpio-cfg.h&gt;#include &lt;linux/gpio.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/fs.h&gt; #include &lt;linux/device.h&gt;/*定义设备目录*/#define DEVICE_LIST &quot;led_test2&quot;/*定义设备文件节点*/#define DEVICE_NODE &quot;led_light2&quot;#define LED1 0x01#define LED2 0x02#define LED3 0x04#define LED4 0x08/*定义申请设备号(主设备号+次设备号)的变量*/static dev_t num_dev; /*字符设备的变量定义*/static struct cdev *cdev_p;/*定义一个 class 类*/static struct class *led_dev_class;/*定义一个全局变量，表示 LED 灯的状态*/static unsigned char led_status = 0;/*设置 LED 灯的状态*/static void set_led_status(unsigned char status){/*表示 LED 灯的状态是否发生变化*/unsigned char led_status_changed;led_status_changed= led_status^(status &amp; 0xF);/*数据变化检测*/led_status=(status &amp; 0xF);/*如果 4 个 LED 灯的状态发生了变化*/if(led_status_changed!=0x00){/*判断是否改变 LED1 灯的状态*/if(led_status_changed&amp;LED1){if(led_status&amp;LED1)gpio_direction_output(S5PV210_GPH0(0),0);elsegpio_direction_output(S5PV210_GPH0(0),1);}/*判断是否改变 LED2 灯的状态*/if(led_status_changed&amp;LED2){if(led_status&amp;LED2)gpio_direction_output(S5PV210_GPH0(1),0);elsegpio_direction_output(S5PV210_GPH0(1),1);}/*判断是否改变 LED3 灯的状态*/if(led_status_changed&amp;LED3){if(led_status&amp;LED3)gpio_direction_output(S5PV210_GPH0(2),0);elsegpio_direction_output(S5PV210_GPH0(2),1);}/*判断是否改变 LED4 灯的状态*/if(led_status_changed&amp;LED4){if(led_status&amp;LED4)gpio_direction_output(S5PV210_GPH0(3),0);elsegpio_direction_output(S5PV210_GPH0(3),1);} } }/*读取 LED 灯的状态*/static ssize_t s5pv210_led_read(struct file * file,char * buf,size_t count,loff_t * f_ops){ /*从用户空间读取数据,获取 LED 灯的状态*/ copy_to_user(buf, (char *)&amp;led_status, sizeof(unsigned char)); return sizeof(unsigned char); }/*定义实现 LED 灯的写操作*/static ssize_t s5pv210_led_write (struct file * file,const char * buf, size_t count,loff_t * f_ops){unsigned char status;if(count==1){/*向用户空间写数据,如果写失败，则返回错误*/if(copy_from_user(&amp;status, buf,sizeof(unsigned char)))return -EFAULT;set_led_status(status);return sizeof(unsigned char); }else return -EFAULT;}/*打开 LED 设备*/static ssize_t s5pv210_led_open(struct inode * inode,struct file * file){ /*增加管理此设备的 owner 模块的使用计数*/try_module_get(THIS_MODULE);return 0;}/*释放 LED 设备*/static ssize_t s5pv210_led_release(struct inode * inode, struct file * file){/*减少管理此设备的 owner 模块的使用计数*/module_put(THIS_MODULE);return 0;}/*定义具体的文件操作*/static const struct file_operations s5pv210_led_ctrl_ops={ .owner = THIS_MODULE, .open = s5pv210_led_open, .read = s5pv210_led_read, .write = s5pv210_led_write, .release = s5pv210_led_release,};/*LED 灯的初始化和 LED 设备驱动的加载*/static int s5pv210_led_ctrl_init(void){int err;struct device* temp=NULL;unsigned int gpio;/*GPIO 口的初始化 LED1,LED2,LED3,LED4，设置为输出*/for(gpio=S5PV210_GPH0(0);gpio&lt;S5PV210_GPH0(4);gpio++){s3c_gpio_cfgpin(gpio, S3C_GPIO_SFN(1));}/*动态注册 led_test 设备,num_dev 为动态分配出来的设备号(主设备号+次设备号)*/err=alloc_chrdev_region(&amp;num_dev,0,1,DEVICE_LIST);if (err &lt; 0) {printk(KERN_ERR &quot;LED: unable to get device name %d/n&quot;, err);return err;}/*动态分配 cdev 内存空间*/cdev_p = cdev_alloc();cdev_p-&gt;ops = &amp;s5pv210_led_ctrl_ops;/*加载设备驱动*/err=cdev_add(cdev_p,num_dev,1);if(err){printk(KERN_ERR &quot;LED: unable to add the device %d/n&quot;, err);return err;}/*在/sys/class 下创建 led_test 目录*/led_dev_class=class_create(THIS_MODULE,DEVICE_LIST);if(IS_ERR(led_dev_class)){ err=PTR_ERR(led_dev_class);goto unregister_cdev;}/*基于/sys/class/led_test 和/dev 下面创建 led_light 设备文件*/temp=device_create(led_dev_class, NULL,num_dev, NULL, DEVICE_NODE);if(IS_ERR(temp)){err=PTR_ERR(temp);goto unregister_class;}return 0;unregister_class:class_destroy(led_dev_class);unregister_cdev:cdev_del(cdev_p);return err;}/*模块的初始化*/static int __init s5pv210_led_init(void){int ret;ret = s5pv210_led_ctrl_init();if(ret){printk(KERN_ERR &quot;Apply: S5PV210_LED_init--Fail !!!/n&quot;);return ret;}return 0;}/*模块的退出*/static void __exit s5pv210_led_exit(void){device_destroy(led_dev_class,num_dev);class_destroy(led_dev_class);cdev_del(cdev_p);unregister_chrdev_region(num_dev,1);}MODULE_LICENSE(&quot;GPL&quot;);MODULE_DESCRIPTION(&quot;LED driver test&quot;);module_init(s5pv210_led_init);module_exit(s5pv210_led_exit); Makefile1234567891011121314INSTALLDIR= /opt/tftpifneq ($(KERNELRELEASE),)obj-m:=led_driver.oelseKERNELDIR:=/opt/cross-compiler/kernel-embv210PWD:=$(shell pwd)default: $(MAKE) -C $(KERNELDIR) M=$(PWD) modulesclean: rm -rf *.o *.order .*.cmd *.ko *.mod.c *.symversendifinstall: led_driver.ko mkdir -p $(INSTALLDIR) cp --target-dir=$(INSTALLDIR) led_driver.ko 测试文件led_test.c12345678910111213141516171819202122232425262728293031323334// LED test programme#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#define DEVICE_NODE &quot;/dev/led_light2&quot;int main(int argc,char **argv){int fd,i,j;unsigned char status;unsigned char t;/*打开设备节点*/fd = open(DEVICE_NODE,O_RDWR);if(fd == -1) {printf(&quot;open device %s error \\n&quot;,DEVICE_NODE);return -1;}for(i=0;i&lt;3;i++){for(j=0;j&lt;4;j++){//依次点亮 LED1..LED4t=(unsigned char)((1&lt;&lt;j)&amp;0x0F);write(fd,&amp;t,sizeof(t));if(read(fd,&amp;status,1)!=0){printf(&quot;led status:%0x\\n&quot;,status);}sleep(1);} }close(fd);return 0;} Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 付少峰. 2024年春, 嵌入式程序设计, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/240785528.html","link":"/collaboration/EmbeddedProgramming/"},{"title":"自主可控嵌入式系统设计","text":"第一讲 嵌入式系统概述嵌入式系统三要素 嵌入性：嵌入到对象体系中，有对象环境要求 专用性：软、硬件按对象要求裁剪 计算机：实现对象的智能化功能 嵌入式系统定义 标准定义：以应用为中心、以计算机技术为基础，软、硬件可裁剪，适应应用系统对功能、可靠性、成本、体积、功耗等严格要求的专用计算机系统。 核心要义：嵌入到对象体中的专用计算机系统 嵌入式系统的核心：计算技术；嵌入式系统的灵魂：软件技术 嵌入式系统的分类 嵌入式处理器的分类嵌入式系统硬件的核心部件是嵌入式处理器，按照用途可以为分： 嵌入式微控制器 (Micro Controller Unit, MCU): 单片机 嵌入式 DSP (Digital Signal Processor, DSP) 嵌入式微处理器 (Micro Processor Unit, MPU): ARM SOC(System on a Chip, SOC) SOPC(System on a Programmable Chip, SOPC) 嵌入式操作系统的分类操作系统：连接计算机硬件与应用程序的系统程序 非实时操作系统: Linux 实时操作系统: RTOS (Real-Time Operating System, 程序对时间要求十分严格: 计算的正确性不仅取决于程序的逻辑正确性，更取决于结果产生的时间) 第二讲 嵌入式系统基础体系结构-存储器组织冯诺依曼体系结构 冯诺依曼体系理论 计算机的数制采用二进制 计算机按照程序顺序执行 要点 程序存储、程序执行 输入、存储、运算、控制和输出 程序指令存储器和数据存储器共用同一存储器，统一编址；程序指令和数据的宽度相同 哈佛体系结构 程序指令存储器和数据存储器使用两个独立的存储器，实现并行处理； 使用独立的两条总线，用于CPU与两个存储器进行通信 基本概念 CPU 字长: 微处理器一次执行处理的数据宽度 指令集: CPU 所能执行的所有指令的集合 复杂指令集(CISC, Complex Instruction Set Computer) 具有大量指令和寻址方式 大多数程序只使用少量的指令就能够运行 精简指令集(RISC, Reduced Instruction Set Computer) 只包含最有用的指令 数据通道快速执行每一条指令 特点对比 RISC指令格式和长度固定，指令类型少，功能简单，寻址方式少，采用规则的硬布线逻辑(组合逻辑型) CISC使用微码ROM进行指令译码(存储逻辑型) RICS大多数指令单周期运行，分开的Load/Store结构的存取指令，固定指令格式 CISC强调硬件的复杂性，RISC注重编译器的复杂性 数据通道对比(RISC的任何运算只能在REG上执行，ALU的数据来源只能是REG，提高执行效率，对比CISC有数量级上的改善) 多任务程序结构前后台程序结构 前台 中断实现 处理对时间要求严格事件、突发事件 后台 轮询多任务实现 处理对时间要求不严格事件 注：前后台是两种服务模式，前台对接时间严格事件，通过中断方式进行响应；后台对接时间不严格事件，分配时间片轮询处理每个任务 事件触发结构 状态机：实际上是有限状态机，类比马尔可夫决策 事件查询：(在状态中判断事件)主体是某一特定状态，决策是采取的不同事件，结果是执行不同功能，迁移到新状态 事件触发：(在事件中判断状态)主体是某一特定事件，决策是执行的不同动作，依据是当前的状态，结果是执行不同功能，迁移到新状态 操作系统 实现多任务运行，进程调度 第三讲 ARM 基本编程模型 ARM=Advanced RISC Machines ARM处理器特点 Load/Store 体系结构 16位/32位双指令集 3地址指令格式 Thumb 技术开发背景 RISC代码密度低，需要比较大的存储器空间(RISC指令简单，完成同一个功能需要多条指令，因此需要更大的存储器空间) 需要32位RISC处理器的性能和16位CISC处理器的代码密度(32位RISC的性能, 16位CISC的代码密度) Thumb 概述 技术概述 16位的指令长度 32位的执行效率 拥有2套独立的指令集 ARM处理器工作状态ARM状态(ARM指令集) 执行32位的字对齐的ARM指令 Thumb状态(Thumb指令集) 执行16位的、半字对齐的Thumb指令 状态切换 两个指令集均有切换处理器状态的指令 开始执行代码时处于ARM状态；异常处理时也处于ARM状态；异常处理返回时，可以返回到Thumb状态 运行模式 特权模式：除了用户模式外的其他模式 异常模式：除了用户模式、系统模式外的其他模式 功能说明 系统模式运行特权操作系统任务(与用户模式有完全相同的寄存器组)异常模式主要处理中断和异常 寄存器组织ARM有37个32位长的寄存器： 1个PC(Program Counter), 30个通用寄存器, 1个CPSR(Current Program Status Register), 1个SPSR(Saved Program Status Register) 31个通用32位寄存器，6个状态寄存器 寄存器功能说明 R0$\\sim$R13: 保存数据/地址值的通用寄存器，无特殊用途 R0$\\sim$R7: 未分组寄存器，是所有处理器模式对应的通用寄存器，无特殊处理模式 R8$\\sim$R12: 一个分组用于除FIQ模式之外的所有寄存器模式，另一组用于FIQ模式，目的：发生FIQ中断时，可以加速FIQ的处理速度，解释：专门为FIQ中断保留一组特定寄存器，能够保证在发生FIQ中断时，没有其他模式占用这一分组的寄存器(数据占用，处理器只能处于一个模式)，可以使得中断处理更加迅速，因此也称为快中断模式 R13$\\sim$R14: 有6个分组的寄存器，一个用于用户与系统模式，其余5个分别用于5中异常模式，解释：寄存器设置也同理，异常模式下，每当发生特定异常时，处理器需要进行异常处理，需要保证存在相应的寄存器能够为之提供服务，而不至于被其他模式所占用 R13: 堆栈指针寄存器，常作为堆栈指针(SP) 不严谨解释: 用户和系统模式共用同一R13，存放程序的指令代码以及其他数据；异常模式具有自己独立的物理寄存器R13：当程序进入不同的异常模式时，可以将需要保护的寄存器放入对应的R13所指向的堆栈中，当程序从异常模式返回时，则从对应的堆栈中恢复， 初始化要求：需要初始化每种模式下的R13 R14: 链接寄存器(LR)，模式本身的R14用于保存子程序返回地址；进入异常模式时对应的R14用于保存异常返回地址 子程序调用返回：调用子程序时，指令先将下一条指令的PC值拷贝到R14，执行完子程序后，再将R14的值拷贝到PC，从而实现子程序的返回 异常处理的返回 R15: 程序计数器(PC)，指向正在取指的地址 ARM状态下，位[1:0]为0，位[31:2]保存PC Thumb状态下，位[0]为0，位[31:1]保存PC ARM体系结构采用多级流水线技术，使得PC值为当前指令的地址值加8个字节 CPSR、SPSR: 程序状态寄存器，程序状态保存寄存器，SPSR仅在异常模式下能够被访问: 进入异常模式时，SPSR保存CPSR的值，异常返回时，通过SPSR的值恢复CPSR的值 Thumb 状态下的寄存器可以直接访问的寄存器: 8个通用寄存器R0$\\sim$R7，程序计数器(PC)，堆栈指针(SP)，链接寄存器(LR)，程序状态寄存器(CPSR)，程序状态保存寄存器(SPSR) 第四讲 ARM 指令系统Load/Store 结构 所有操作数都存储在通用寄存器中 图解: MEM $\\rightarrow$ REG $\\rightarrow$ ALU $\\rightarrow$ MEM ARM 指令 指令分类：数据处理指令，Load/Store 指令，跳转指令，CPSR处理指令，异常产生指令，协处理器指令; 特殊指令：CPSR 处理指令 ARM 状态下，指令根据 CPSR 中条件码状态和指令条件域条件执行 嵌入式微处理器指令集：强调指令的灵活性，对称性，简单性 指令编码说明: bit $12\\sim15$: 4 bits 编码表示 $16$ 个通用寄存器 bit $28\\sim31$: 指令条件码占据指令的高 $4$ bits, 并且条件编码 “1111” 为系统保留 ARM 寻址方式 理解ARM三地址指令格式的特点 立即寻址: 操作数(立即数)包含在指令的 $32$ 位编码中 指令说明 只有第二源操作数可用立即数 立即数以 “#” 为前缀，”#” 后加 “0x” 或 “&amp;” 表示十六进制，”0b” 表示二进制，”0d” 或缺省表示十进制 Example ADD R$0$, R$0$, #$1$ AND R$3$, R$4$, #$0$xFF 立即数的表示 指令中立即数编码比特位: $12$位 扩散数据表示范围: $12$ 位数据表示 $32$ 位数据空间 立即数组成: $8$(常数) $+$(偶数移位个数)$=12$ 移位方式: 循环右移 特点: 所有有效位必须小于等于 $8$ 位，右移位数必须为偶数 扩散数据原理 寄存器寻址: 操作数在寄存器中，指令地址码字段编码寄存器编号 Example MOV R$1$, R$2$ ; R$1$ = (R$2$) SUB R$0$, R$1$, R$2$ ; R$0$ = (R$1$) - (R$2$) 寄存器移位寻址: ARM 指令集特有寻址方式，主要为了增强精简指令的执行效率 指令说明 ARM 移位寻址中，在取操作数送往ALU过程中，就已经在总线上完成了移位运算操作 Example MOV R$0$, R$2$, LSL #3 ; R$0$ = (R$2$) &lt;&lt; 3 ANDS R$1$, R$2$, LSL R$3$ ; R$1$ = (R$1$) &amp; (R$2$) &lt;&lt; (R$3$) 移位方式 LSL(Logical Shift Left) LSR(Logical Shift Right) ASL(Arithmetic Shift Left) ASR(Arithmetic Shift Right) ROR(Rotate Right) RRX(Rotate Right Extended by 1 Place) 基址寻址: 存储器地址在寄存器中 指令说明寄存器中存储的是存储单元的地址 Example LDR R$0$, [R$1$] STR R$0$, [R$1$] 变址寻址: 基址寄存器+地址偏移量 地址偏移量 立即数 控制位 U=$1$时加偏移量，U=$0$时减偏移量 偏移量占 $12$ Bit(立即数) Example: LDR R$0$, [R$1$, #4] LDR R$0$, [R$1$, #-4] 寄存器 控制位 U=$1$时加索引寄存器值，U=$0$时减索引寄存器值 Example: LDR R$0$, [R$1$, R$2$] LDR R$0$, [R$1$, -R$2$] 寄存器及移位常数 地址偏移量由寄存器通过移位得到 Example: LDR R$0$, [R$1$, R$2$, LSL #2] 变址模式 前变址模式 LDR R$0$, [R$1$, #$4$] ; R$0$ = Mem$32$[R$1$+$4$] 自动变址模式(事先更新方式) LDR R$0$, [R$1$, #$4$]! ; R$0$ = Mem$32$[R$1$+$4$], R$1$ = R$1$ + $4$ 后变址模式(事后更新方式) LDR R$0$, [R$1$], #$4$ ; R$0$ = Mem$32$[R$1$], R$1$ = R$1$ + $4$ 3种地址偏移格式与3种变址模式，可以组合出9种类型的变址寻址方式。 相对寻址: 基址寄存器是程序计数器 PC 主要用于分支指令 Example 1234 BL SUBR ; jump to SUBRSUBR ; entry of subprogram .... MOV PC, R14 块拷贝寻址 多寄存器传送指令 LDM/STM 的寻址方式 寄存器组可以是 $16$ 个通用寄存器的任意子集 地址增长顺序: IA(Increment After), IB(Increment Before), DA(Decrement After), DB(Decrement Before) Example 堆栈寻址 堆栈形式 满递增(指令：LDMFA, STMFA) 空递增(指令：LDMEA, STMEA) 满递减(指令：LDMFD, STMFD) 空递减(指令：LDMFD, STMFD)注：FD(Full Decrement), ED(Empty Decrement), FA(Full Aggrandizement), EA(Empty AdvanceAggrandizement) Example ARM指令中的堆栈 STMFD SP!, {R$1$-R$7$, LR} LDMFD SP!, {R$1$-R$7$, LR} Thumb指令中的堆栈 PUSH {R1-R7, LR} POP {R1-R7, PC} ARM 指令集概述数据处理指令 主要完成寄存器中数据的算术和逻辑运算操作 数据宽度：所有操作数都是 $32$ 位宽度 Load/Store 指令该类指令用于寄存器与内存中数据传送，因为ALU的数据来源只能是寄存器，寄存器中数据要提前从内存中获取。 单寄存器存取指令(LDR/STR)(Load Register/Store Register) 加载/存储字/半字/字节(32位对齐/16位对齐/8位对齐) 多寄存器存取指令(LDM/STM)(Load Multiple Registers/Store Multiple Registers) 堆栈操作和块拷贝 存储器与寄存器交换指令SWP 杂项指令第五讲 ARM 指令详细介绍 体会 ARM 指令体系的规整性 数据处理指令数据传送指令(2条) MOV 指令格式: MOV{条件}{S} 目的寄存器, 源操作数 源操作数: 寄存器、被移位的寄存器、立即数 S: 存在S时表示更新CPSR中条件标志位 Example MOV R0, #100 MOV R0, R1 MOV R0, R1, LSL #2 MVN(Move Not) 指令格式: MVN{条件}{S} 目的寄存器, 源操作数 源操作数: 寄存器、被移位的寄存器、立即数 指令说明: 将源操作数按位取反传送到目的寄存器，实现逻辑非 S: 存在S时表示更新CPSR中条件标志位 Example MVN R0, #0 ; 寄存器置1操作 算术运算指令(6条) 三地址指令格式 ADD 指令格式: ADD{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 + 操作数2 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example ADD R0, R1, R2 ADD R0, R1, #100 ADD R0, R1, R2 LSL #1 ADC 指令格式: ADC{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 + 操作数2 + CF 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 128位数加法 ; 128Num1: R7-R4, 128Num2: R11-R8, 128Sum: R3-R0 ADDS R0, R4, R8 ; 加低位的字 ADCS R1, R5, R9 ; 加第二个字，带进位 ADCS R2, R6, R10 ; 加第三个字，带进位 ADC R3, R7, R11 ; 加高8位，带进位 SUB 指令格式: SUB{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 - 操作数2 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: SUB R0, R1, R2 SUB R0, R1, #256 SUB R0, R1, R2 LSL #1 SBC 指令格式: SBC{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 - 操作数2 - $\\overline{CF}$ 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 64位数减法 ; 64Num1: R1-R0, 64Num2: R3-R2, 64Sub: R1-R0 SUBS R0, R0, R2 ; 加低位的字 SBC R1, R1, R3 ; 加第二个字，带进位 注解: 假设R3-R0为4位寄存器，做减法: 46H-24H; 6H-4H = [6H]补 + [-4H]补 = 0110B + 1100B = 0010B $\\Rightarrow$ R0 = 2H with CF = 1 (数据有溢出) 4H-2H-$\\overline{CF}$ = [4H]补 + [-2H]补 = 0100B + 1110B = 0010B $\\Rightarrow$ R1 = 2H with CF = 1 (数据有溢出) RSB(Reverse Subtract) 指令格式: RSB{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数2 - 操作数1 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: RSB R0, R1, R2 RSB R0, R1, #256 RSB R0, R1, R2 LSL #1 RSC 指令格式: RSC{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数2 - 操作数1 - CF 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 64位数减法 ; 64Num1: R1-R0, 64Num2: 0, 64Sub: R3-R2 RSBS R2, R0, #0 RSC R3, R1, #0 逻辑运算指令(4条) AND 指令格式: AND{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 &amp; 操作数2 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 屏蔽操作数1的某些位 AND R1, R1, #3 ORR 指令格式: ORR{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 | 操作数2 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 设置操作数1的某些位 ORR R0, R0, #3 EOR 指令格式: EOR{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = 操作数1 ^ 操作数2 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: 反转操作数1的某些位 EOR R0, R0, #3 ; 低位反转 BIC 指令格式: BIC{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 清除操作数1的某些位，操作数2作为操作数1的掩码，如果操作数2置位，则清除操作数1对应位 操作数1: 寄存器 操作数2: 寄存器、被移位的寄存器、立即数 Example: BIC R0, R0, #3 ; 清除低两位 比较指令(2条) CMP 指令格式: CMP{条件} 操作数1, 操作数2 指令说明: 操作数1-操作数2=操作数1+[-操作数2]补码=操作数1+[操作数2]求补，不存储结果，只影响CPSR中标志位 操作数1: 寄存器 操作数2: 寄存器、立即数 Example: CMP R1, R0 CMP R1, #100 CMN 指令格式: CMN{条件} 操作数1, 操作数2 指令说明: 操作数1-[操作数2]求补=操作数1+[-[操作数2]求补]补码=操作数1+[[操作数2]求补]求补=操作数1+操作数2，不存储结果，只影响CPSR中标志位 操作数1: 寄存器 操作数2: 寄存器、立即数 Example: CMN R1, R0 CMN R1, #100 测试指令(2条) TST 指令格式: TST{条件} 操作数1, 操作数2 指令说明: 操作数1 &amp; 操作数2，不存储结果，只影响CPSR中标志位(ZF); 操作数2一般作为位掩码 操作数1: 寄存器 操作数2: 寄存器、立即数 Example: TST R1, #1 ; 测试最低位是否为1 TST R1, #0xffe TEQ 指令格式: TEQ{条件} 操作数1, 操作数2 指令说明: 操作数1 ^ 操作数2，不存储结果，只影响CPSR中标志位(ZF); 通常用于比较操作数1和操作数2是否相等 操作数1: 寄存器 操作数2: 寄存器、立即数 Example: TEQ R1, R2 乘法指令(6条) MUL(32位有符号或无符号乘法) 指令格式: MUL{条件}{S} 目的寄存器, 操作数1, 操作数2 指令说明: 目的寄存器 = [操作数1 * 操作数2][31…0]，影响CPSR中标志位 操作数1: 寄存器 操作数2: 寄存器 Example: MUL R0, R1, R2 MULS R0, R1, R2 MLA(32位有符号或无符号乘加法, Mulliply Add) 指令格式: MLA{条件}{S} 目的寄存器, 操作数1, 操作数2, 操作数3 指令说明: 目的寄存器 = [操作数1 * 操作数2 + 操作数3][31…0]，影响CPSR中标志位 操作数1: 寄存器 操作数2: 寄存器 Example: MLA R0, R1, R2, R3 MLAS R0, R1, R2, R3 SMULL(64位有符号数乘法, Signed Mulliply Long) 指令格式: SMULL{条件}{S} 目的寄存器Low, 目的寄存器High, 操作数1, 操作数2 指令说明: 目的寄存器 = [操作数1 * 操作数2][63…0]，影响CPSR中标志位 操作数1: 32位寄存器 操作数2: 32位寄存器 Example: SMULL R0, R1, R2, R3 ; R0(Low32) = (R2R3)(Low32), R1(High32) = (R2R3)(High32) SMULLS R0, R1, R2, R3 SMLAL(64位有符号数乘加法, Signed Mulliply ADD Long) 指令格式: SMLAL{条件}{S} 目的寄存器Low, 目的寄存器High, 操作数1, 操作数2 指令说明: 目的寄存器 = [操作数1 * 操作数2 + 目的寄存器][63…0]，影响CPSR中标志位 操作数1: 32位寄存器 操作数2: 32位寄存器 Example: SMLAL R0, R1, R2, R3 ; R0(Low32) = (R2R3)(Low32) + R0(Low32), R1(High32) = (R2R3)(High32) + R1(High32) SMLALS R0, R1, R2, R3 UMULL(64位无符号数乘法, Unsigned Mulliply Long) 指令格式: UMULL{条件}{S} 目的寄存器Low, 目的寄存器High, 操作数1, 操作数2 指令说明: 目的寄存器 = [操作数1 * 操作数2][63…0]，影响CPSR中标志位 操作数1: 32位寄存器 操作数2: 32位寄存器 Example: UMULL R0, R1, R2, R3 ; R0(Low32) = (R2R3)(Low32), R1(High32) = (R2R3)(High32) UMULLS R0, R1, R2, R3 UMLAL(64位无符号数乘加法, Unsigned Mulliply ADD Long) 指令格式: UMLAL{条件}{S} 目的寄存器Low, 目的寄存器High, 操作数1, 操作数2 指令说明: 目的寄存器 = [操作数1 * 操作数2 + 目的寄存器][63…0]，影响CPSR中标志位 操作数1: 32位寄存器 操作数2: 32位寄存器 Example: UMLAL R0, R1, R2, R3 ; R0(Low32) = (R2R3)(Low32) + R0(Low32), R1(High32) = (R2R3)(High32) + R1(High32) UMLALS R0, R1, R2, R3 Load/Store指令 ARM中用于在寄存器和存储器之间传送数据的指令 单寄存器存取指令(6条) LDR(字数据加载指令) 指令格式: LDR{条件} 目的寄存器, &lt;存储器地址&gt; 指令说明: 目的寄存器 = Mem[Address]——32位字数据 Example: LDR R0, [R1] ; R0 = Mem[R1] LDR R0, [R1, R2] ; R0 = Mem[R1+R2] LDR R0, [R1, #4] ; R0 = Mem[R1+4] LDR R0, [R1, R2]! ; R0 = Mem[R1+R2], R1 = R1 + R2 LDRB(字节数据加载指令) 指令格式: LDR{条件}B 目的寄存器, &lt;存储器地址&gt; 指令说明: 目的寄存器[7…0] = Mem[Address]——8位字节数据, 目的寄存器[31…8] = 0 Example: LDRB R0, [R1] ; R0 = Mem[R1] LDRB R0, [R1, #8] ; R0 = Mem[R1+8] LDRH(半字数据加载指令) 指令格式: LDR{条件}H 目的寄存器, &lt;存储器地址&gt; 指令说明: 目的寄存器[15…0] = Mem[Address]——16位字节数据, 目的寄存器[31…16] = 0 Example: LDRB R0, [R1] ; R0 = Mem[R1] LDRB R0, [R1, #8] ; R0 = Mem[R1+8] STR(字数据存储指令) 指令格式: STR{条件} 源寄存器, &lt;存储器地址&gt; 指令说明: Mem[Address] = 源寄存器——32位字数据 Example: STR R0, [R1], #8 ; Mem[R1] = R0, R1 = R1 + 8 STR R0, [R1, #4] ; Mem[R1+4] = R0 STR R0, [R1, R2]! ; Mem[R1+R2] = R0, R1 = R1 + R2 STRB(字节数据存储指令) 指令格式: STR{条件}B 源寄存器, &lt;存储器地址&gt; 指令说明: Mem[Address] = 源寄存器Low8——8位字节数据 Example: STRB R0, [R1] ; Mem[R1] = R0(Low8) STRB R0, [R1, #8] ; Mem[R1+8] = R0(Low8) STRH(半字数据存储指令) 指令格式: STR{条件}H 源寄存器, &lt;存储器地址&gt; 指令说明: Mem[Address] = 源寄存器Low16——16位半字数据 Example: STRH R0, [R1] ; Mem[R1] = R0(Low16) STRH R0, [R1, #8] ; Mem[R1+8] = R0(Low16) Check Point: Load/Store指令的基址寻址于变址变址 多寄存器存取指令(2条)ARM中支持的批量数据加载/存储指令可以一次在一片连续的存储器单元和多个寄存器之间传送数据，通常用于堆栈操作 STM(批量数据存储指令) 指令格式: STM{条件}{类型} 基址寄存器{!}, 寄存器列表{^} 指令说明: 多个寄存器中字数据传送到基址寄存器指向的连续存储器单元中 类型——地址增长顺序: IA(Increment After), IB(Increment Before), DA(Decrement After), DB(Decrement Before) Example: STMFD R0!, {r1-r4} LDM(批量数据加载指令) 指令格式: LDM{条件}{类型} 基址寄存器{!}, 寄存器列表{^} 指令说明: 基址寄存器指向的连续存储器单元中字数据传送到多个寄存器中 Example: LDMFD R0!, {r1-r4} 存储器和寄存器交换指令(2条) 主要用于实现信号量操作，信号量用于进程的同步与互斥 SWP 指令格式: SWP{条件} 目的寄存器, 源寄存器1, [源寄存器2] 指令说明: 目的寄存器=Mem[源寄存器2]，Mem[源寄存器2] = 源寄存器1 Example: 寄存器和存储器交换 SWP R0, R0, [R2] 跳转指令ARM程序跳转概述 PC寄存器中写入目标地址值 实现4GB地址空间的任意跳转 跳转指令实现 向前或向后32MB地址空间跳转 ARM程序跳转 B(Branch) 分支跳转指令，根据条件进行分支跳转 B{条件} 目标地址 不加条件时，表示无条件跳转指令 BL(Branch with Link) 分支链接指令 BL{条件} 目标地址 将下一条指令的地址拷贝到链接寄存器(R14/LR)中，然后跳转到指定的地址运行程序 BX(Branch and eXchange) 分支交换指令 BX{条件} 目标地址 带状态切换的跳转指令，具体状态有目标寄存器最低位决定 BLX(Branch with Link and eXchange) 分支链接交换指令 BLX 目标地址 带状态切换的分支链接指令 程序状态寄存器访问指令用于在程序状态寄存器(CPSR/SPSR)和通用寄存器之间传送数据 MRS 指令格式: MRS{条件} 通用寄存器, 程序状态寄存器 指令说明: 状态寄存器的内容读取到通用寄存器, Rn$\\rightarrow$ CPSR/SPSR Example: 临时保存程序状态寄存器的内容 异常处理或进程切换时，先读再存程序状态寄存器中的值 MSR 指令格式: MSR{条件} 程序状态寄存器_&lt;域&gt;, 操作数 指令说明: 将操作数的内容传送到状态寄存器的特定域中,操作数可以为通用寄存器或立即数 域：对32位程序状态字寄存器的划分，分为4个8位域 c位[7:0]为控制位域, 表示为c x位[15:8]为扩展位域, 表示为x s位[23:16]为状态位域, 表示为s f位[31:24]为条件标志位域, 表示为f Example: MSR CPSR, R0 MSR CPSR_c, R0 异常产生指令 SWI 软件中断指令 BKPT 断点中断指令 协处理器指令第六讲 ARM汇编ARM汇编语言源程序一般由ARM指令、伪操作(包括伪指令)和宏指令组成；其中伪操作(包括伪指令)是由汇编器在对源程序汇编期间由汇编程序处理的。 伪操作符号定义伪操作用于定义ARM汇编程序中的变量，对变量赋值和寄存器重命名 定义全局变量(GBLA(GloBaL Arithmetic), GBLL(GloBaL Logical), GBLS(GloBaL String)) 指令格式: GBLA(GBLL/GBLS) 全局变量名 指令说明: GBLA算术, GBLL逻辑, GBLS字符串 定义ARM程序中全局变量并初始化为0 Example: GBLA Test1 Test1 SETA 0xaa GBLL Test2 Test2 SETL {TRUE} GBLS Test3 Test3 SETS “Testing” 定义局部变量(LCLA(LoCaL Arithmetic), LCLL(LoCaL Logical), LCLS(LoCaL String)) 指令格式: LCLA(LCLL/LCLS) 局部变量名 指令说明: LCLA算术, LCLL逻辑, LCLS字符串 定义ARM程序中局部变量并初始化为0 Example: LCLA Test1 Test1 SETA 0xaa LCLL Test2 Test2 SETL {TRUE} LCLS Test3 Test3 SETS “Testing” 对变量进行赋值(SETA(SET Arithmetic), SETL(SET Logical), SETS(SET String)) 指令格式: 变量名 SETA(SETL/SETS) 表达式 指令说明: 为已定义过的全局变量或局部变量进行赋值 Example: LCLA Test1 Test1 SETA 0xaa LCLL Test2 Test2 SETL {TRUE} 命名通用寄存器列表(RLIST(Register List)) 指令格式: 名称 RLIST {寄存器列表} 指令说明: 用于对一个通用寄存器列表定义名称，列表中寄存器访问次序为寄存器的编号由低到高 Example: Reglist RLIST {R0-R5, R8, R10} 数据定义伪操作汇编控制伪操作 控制汇编程序的执行流程 IF…ELSE…ENDIF WHILE…WEND MACRO…MEND(Macro) 宏定义伪操作，标识一个宏的开始与结束 MEXIT 从宏定义中跳转出去 信息报告伪操作 ASSERT 指令格式: ASSERT Logical_Expression 指令说明: 断言表达式成立否则报错，并且该伪操作在第二次扫描汇编程序中判断 Example: ASSERT Top&lt;&gt;Temp INFO 指令格式: INFO numeric_expr, string_expr 指令说明: 该伪操作在第一次或第二次扫描时报告诊断信息 参数说明: numeric_expr = 0 第一遍扫描时报告，否则第二遍时；string_expr: 诊断信息 Example: INFO 0, “Version 0.1” 其他伪操作 AREA 指令格式: AREA 段名, 属性1, 属性2, … 指令说明: CODE属性(代码段)，DATA属性(数据段)，READONLY属性，READWRITE属性 Example: AREA Init，CODE，READONLY … END CODE 指令格式: CODE16/CODE32 指令说明: 通过CODE16伪操作通知编译器其后指令为16位的Thumb指令；CODE32通知编译器其后指令为32位的ARM指令；以此进行ARM的状态切换 ENTRY 指令格式: ENTRY 指令说明: ENTRY伪操作用于指定汇编程序入口点; 在一个完整的汇编程序中至少要有一个ENTRY Example: AREA Init，CODE，READONLY ENTRY END 指令格式: END 指令说明: END伪操作用于通知编译器已经到了源程序的结尾 Example: AREA Init，CODE，READONLY … END EQU 指令格式: 名称 EQU 表达式 {，类型} 指令说明: EQU伪操作用于为程序中的标号、数字常量和寄存器的值等定义一个字符名称；可以用’*’代替 Example: Test EQU 50 Addr * 0x55，CODE32 ; 定义Addr的值为0x55, 且该处为32位的ARM指令(类型) EXPORT/GLOBAL 指令格式: EXPORT 标号 指令说明: 用于在程序中声明一个全局的标号 Example: 1234AREA Init CODE，READONLY EXPORT Test ; 声明一个可全局引用的标号Test ... END IMPORT 指令格式: IMPORT 标号 指令说明: 用于通知编译器要使用的标号在其他的源文件中定义，但要在当前源文件中引用; 如果没有引用，该标号实际上会被加入到当前源文件中 Example: 1234AREA Init CODE，READONLY IMPORT Main ; 引用一个全局的标号Main ... END EXTERN 指令格式: EXTERN 标号 指令说明: 用于通知编译器要使用的标号在其他的源文件中定义，但要在当前源文件中引用; 如果没有引用，该标号实际上不会被加入到当前源文件中 GET 指令格式: GET 文件名 指令说明: GET伪操作用于将一个源文件包含到当前的源文件中，并将被包含的源文件在当前位置进行汇编处 可以使用INCLUDE代替GET ARM语言伪指令伪指令不是真正的ARM指令,在汇编过程中会被替换成对应的ARM指令或指令序列 ADR(AdDRess) 指令格式: ADR {cond} register, 标号 指令说明: 将基于PC的地址值(程序标号)或基于寄存器的地址值加载到寄存器中 Example: 123start MOV R0, #0 ADR R1, start =&gt; SUB R1, pc, #0xC ADRL(AdDRess Large) 指令格式: ADRL {cond} register, 标号 指令说明: 将基于PC的地址值(程序标号)或基于寄存器的地址值加载到寄存器中,可被替换成两条合适的指令，所以加载的地址范围更大 Example: 1234start MOV R0, #0 ADRL R1, start + 60000 =&gt; ADD R1, pc, 0xE800 =&gt; ADD R1, R1, 0x254 LDR(Load Register) 指令格式: LDR {cond} register, = expr 或 label-expr 指令说明: 可将任意一个32位常数或地址值加载到寄存器中 Example: 1234LDR R1, =0xFF=&gt; MOV R1, 0xFFLDR R1, =0xFFF=&gt; LDR R1, [PC, OFFSET_TO_LPOOL] NOP(NO Operation) 指令格式: NOP 指令说明: 汇编时会被替换成一条无用指令, 不影响CPSR中的条件标志位 Example: 12NOP=&gt; MOV R0, R0 第七讲 ARM下的C编程了解C运行时库C运行时库(C Runtime Library)用于在C程序运行时提供支持的函数和例程集合，包含C语言所需的基本功能和支持： ARM的C编译器支持ANSI C运行时库 ARM C运行时库以二进制形式提供 用户可以建立自己的运行时库 宏和函数的区别宏：在C程序中定义的命名代码段。 编译器会将相关代码放到宏名出现的每一个地方，宏的代码在任何出现宏名的地方都会编译一次；使用宏时不需要保存/恢复上下文，也不必返回 在编译器预处理阶段会被直接展开到代码中，编译时用宏内容替换宏调用位置，可能导致代码膨胀 代码简单用宏 函数： 函数的代码只需要编译一次 在编译时定义，但实际执行发生在运行时，会有函数调用开销 代码复杂用函数 三、什么是内嵌汇编 标识符：_ _asm：用于告诉编译器后面是汇编代码 内嵌汇编12345678910void enable_IRQ(void){ int temp; __asm { MRS tmp, CPSR BIC tmp, tmp, #0x80 MSR CPSR_c, tmp }} _irq、volatile关键字的作用_irq：使用该关键字声明的函数可以被用作异常中断的中断处理程序，该函数通过将lr-4的值赋予PC寄存器，并将 SPSR的值赋予CPSR实现函数返回 volatile：用于声明变量，告诉编译器该变量可能在程序之外修改；编译时不能优化对volatile变量的操作；不能对volatile变量使用缓冲技术 汇编和 C 的混合编程参数传递规则： 参数个数可变的子程序参数传递规则： 参数不超过4个时，使用R0～R3来传递； 参数超过4个时，可以使用数据栈来传递 参数个数固定的子程序参数传递规则: 第一个整数参数，通过R0～R3来传递 其他参数通过数据栈来传递 有关浮点运算，需特别处理 子程序结果返回规则: 结果为一个32位整数时，可以通过寄存器R0返回 结果为一个64位整数时，可以通过寄存器R0和R1返回， 依次类推 ARM 异常响应过程 ARM异常处理 当异常中断发生时, 系统执行完当前指令后，跳转到相应的异常中断处理 程序处执行 执行完成后，程序返回到发生中断的指令的下一条指 令处执行 进入异常中断处理程序时要保存现场，返回时要恢复 现场 异常向量表 当异常发生时，处理器会把PC设置为一个特定的存储器地址 这一地址放在被称为向量表(vector table)的特定地址范围内 异常向量表通常放在存储地址的低端 第八讲 RISC-V&amp;华为鲲鹏指令集架构(ISA)和国内ISA生态 指令：是指处理器进行操作的最小单元（如算术/逻辑运算）； 指令集：顾名思义是指一组指令的集合； 指令集架构：又称为“处理器架构”，不仅是指令的集合，还包括编程需要的硬件信息，如支持的数据类型、存储器、寄存器状态、寻址模式和寄存器模型等； 指令集架构（ISA, Instruction Set Architecture）才是区分不同CPU的标准； 微架构：处理器的具体硬件实现方案称为微架构； 常见指令集架构：x86(CISC), SPARC, MIPS, Power(国产), Alpha(国产), ARC, ARM(RISC), Intel RISV-V的主要特征RISC-V，是一种基于“精简指令集（RISC）”原则的指令集架构，它具有开源、重新设计(后发优势)、简单哲学、模块化指令集、指令集可扩展的特点。 华为鲲鹏 鲲鹏 920 使用的指令集架构是 ARM v8 64 位 鲲鹏 920 生产使用的制程是 7nm 相比于上一代的鲲鹏 916，鲲鹏 920 处理器的计算核数提升 1 倍，最多支持 64 核 第九讲 最小系统设计嵌入式系统最小系统CPU能够运行所需的模块有(最小系统)：电源、时钟、复位、内存、调试接口（JTAG） DC-DC 转换器的常见形式线性稳压器、开关稳压器和充电泵 晶体和晶振时钟一般由晶体振荡器提供，而晶体和晶振是构成晶体振荡器的两种方式: 晶体(无源) 封装内部只含有晶体, 没有内部电源 驱动电路由设计者提供 晶振(有源) 封装中包含了完整的晶体振荡器电路 需要电源 复位的基本功能 在系统上电时提供复位信号 保证能够进行手动复位 SRAM,DRAM,SDRAM和Flash SRAM(静态RAM) 数据存入静态RAM后，只要电源维持不变，其中存储的数据就能够一直维持不变 , 不需要刷新操作 读写速度快 由触发器构成基本单元，接口简单 存储单元结构复杂，集成度较低 常常用作高速缓冲存储器[读写速度快] 处理器内部集成存储器多选择SRAM DRAM(动态RAM) 依靠电容存储信息，需要不断刷新 读写速度慢 集成度高，成本低 地址引脚少，地址总线采用多路技术，接口复杂 多用于外部存储器扩展(外存)[读写速度慢] SDRAM(同步动态RAM) SDRAM因为要同CPU和芯片组共享时钟，所以芯片组可以主动的在每个时钟的上升沿发给引脚控制命令 动态RAM加上同步特性[在每个时钟的上升沿发给引脚控制命令] Nor Flash 芯片内执行 读速度快（相比Nand Flash） 写入与擦除速度很低 擦除按块进行，写入前必须先擦除 带有SRAM接口，有足够的地址引脚来寻址，可以很容易地存取其内部的每一个字节 常用来存储代码 Nand Flash NAND读和写操作按512字节的块进行 写入与擦除速度比Nor Flash快 擦除按块进行，写入前必须先擦除 NAND的擦除单元更小，相应的擦除电路更少 NAND器件使用复杂的I/O口来串行地存取数据 常用来存储数据 存储器映射存储器映射到物理地址, 通过将存储器按照物理地址划分为不同模块, 进行RAM, DRAM, SDRAM, FLASH等存储设计. 第十讲 外部设备及通信接口常用外部接口I/O（Input/Output）接口是一个微控制器必须具备的最基本的外设功能. 每个I/O口一般都对应了两个寄存器: 数据寄存器：数据寄存器的各位都直接引到芯片外部 控制寄存器：控制数据寄存器中每位的信号流通方向和方式 GPIO General-Purpose I/O ports，也就是通用I/O口，是I/O的最基本形式 LCD 液晶显示器(Liquid Crystal Display): 晶显示器是一种被动光源的显示器，自身不能发光，只能借助外界光源, 具有省电、体积小、低成本、低功率等特点，被广泛应用于嵌入式系统中 液晶: 以液态形式存在的晶体 有电流流过，液晶分子会以电流的方向进行排列；没有电流时，平行排列 基本原理: 通过给不同的液晶单元供电，控制其光线的通过与否而达到显示的目的 触摸屏 触摸屏由触摸检测部件和触摸屏控制器组成, 按照触摸屏的工作原理和传输信息的介质主要分为: 电阻式, 电容感应式, 红外线式, 表面声波式四种 ADC 模/数转换器就是把电模拟量转换成数字量的电路 DAC 数/模转换器就是把数字量转换成模拟量的电路 第十一讲 嵌入式操作系统嵌入式操作系统相对于通用操作系统，嵌入式操作系统更为精巧, 但并不意味着可以通过裁剪通用操作系统来实现, 它有自身的特点: 实时性 可移植性 可配置、可裁剪性 可靠性 应用编程接口 每个操作系统提供的系统调用的功能和种类都不同 嵌入式操作系统的任务主要任务是尽可能地屏蔽底层硬件的差异，对上层应用软件和底层硬件提供标准化服务 嵌入式操作系统的功能内核是嵌入式操作系统的基础, 具有以下功能: 任务管理 中断管理 通信, 同步和互斥机制 内存管理 I/O管理 嵌入式操作系统的实时性实时性是实时内核最重要的特征之一 实时系统的正确性不仅依赖于系统计算的逻辑结果(计算逻辑)，还依赖于产生这些结果的时间(计算时间) 相关概念 确定性 实时性是指内核应该尽可能快的响应外部事件 确定性是指对事件响应的最坏时间是可预知的 响应性 确定性关心系统在识别外部事件之前的延迟(响应启动延迟) 响应性关心的是在识别外部事件后，系统要花多长时间来服务该事件(响应时间) 响应时间 确定性和响应性结合在一起构成事件响应时间。 中断响应时间 = 最长关中断时间 + 保护CPU内部寄存器的时间 + 进入中断服务函数的执行时间 + 开始执行中断服务程序(ISR)的第一条指令时间 任务响应时间 = 中断响应时间+中断服务时间 对于强实时内核，响应时间应该在 $\\mu s$ 级 多任务程序设计结构前后台结构 后台循环, 前台中断 后台行为: 应用程序是一个无限的循环，循环中调用相应的函数完成相应的操作，这部分可以看成后台行为 前台行为: 中断服务程序处理异步事件，这部分可以看成前台行为 多任务系统的相关概念嵌入式实时系统中，多采用多任务程序设计的方法，其特点有： 单个任务规模较小，容易编码和调试 任务间独立性高、耦合性小，便于扩充功能 系统实时性强，以保证紧急事件得到优先处理 任务的概念进程是资源分配的最小单位, 线程是进程内部一个相对独立的控制流，是调度执行的最小单位【基本概念】 大多数实时内核都把整个应用当作一个没有定义的进程，应用则被划分为多个任务来处理 整个内核是一个单进程/多线程模型，简单称为多任务模型 【概念阐述】多任务系统是一个单进程或多进程的系统内核, 其中多个进程是由内核将整个应用划分成多个任务进行处理而建立的.【任务的要素】 代码: 一段可执行的程序 初始数据: 程序执行所需的相关数据 堆栈: 保存局部变量和现场的存储区 任务控制块: 包含任务相关信息的数据结构以及任务执行过程中所需要的所有信息 【任务的特点】 动态性(就绪, 运行或等待), 并行性(同时存在多个任务, 宏观上并行), 异步独立性(各任务相互独立,运行速度不可预知) 任务的基本状态及转换 运行状态(running) 该任务已获得运行所必需的资源，它的程序正在处理机上执行 阻塞状态(wait) 任务正等待着某一事件的发生而暂时停止执行; 这时，即使给它CPU控制权，它也无法执行, 则称该任务处于阻塞态 就绪状态(ready) 任务已获得除CPU之外的运行所必需的资源，一旦得到CPU控制权，立即可以运行 就绪$\\longrightarrow$运行 调度程序选择一个新的进程运行(进程被调度) 运行$\\longrightarrow$就绪 运行进程用完了时间片(时间片用完) 运行进程被中断，因为一高优先级进程处于就绪状态(被高优先级进程抢占) 运行$\\longrightarrow$等待 进程必须等待某个事件： OS尚未完成服务 对一资源的访问尚不能进行 初始化I/O 且必须等待结果 等待$\\longrightarrow$就绪 所等待的事件已经发生 任务的切换 保存当前任务的上下文 当多任务内核决定运行另外的任务时，任务切换要求保存正在运行任务的当前状态，即CPU寄存器中的全部内容被保存到任务的当前状态保存区(任务自己的堆栈区) 恢复需要运行任务的上下文 原任务状态入栈工作完成后，就把下一个将要运行任务的当前状态从该任务的堆栈中重新装入CPU寄存器，并开始下一个任务的运行 任务的调度【调度的功能】调度只是一个函数调用，可在内核各个部分调用 用来确定多任务环境下任务执行的顺序(任务执行顺序) 用来确定任务获得CPU资源后能够执行的时间(任务执行时间)[基于时间片的调度] 【调度点与调度时机】调用调度程序的具体位置称为调度点： 中断服务程序的结束位置 任务因等待资源而进入等待状态 调度策略 实时任务就绪的原因 中断处理过程中使实时任务就绪: 存在任务请求中断, 中断服务程序会使得中断请求任务就绪【中断处理程序】 当前运行任务调用操作系统功能，使实时任务就绪【系统调用】 非抢占式调度 低优先级任务运行过程中，一个中断到达; 若中断被允许，CPU进入中断服务程序; 中断处理过程使一个高优先级任务就绪; 中断完成后，CPU归还给原先被中断的低优先级任务; 低优先级任务继续运行; 低优先级任务完成或因其它原因被阻塞而释放CPU，内核进行任务调度，切换到就绪的高优先级任务;【调度点】 高优先级任务运行 特点 任务运行空间是封闭的，几乎不需要使用信号量保护共享数据 内核的任务级响应时间是不确定的，完全取决于当前任务何时释放CPU 抢占式调度 低优先级任务运行过程中，一个中断到达; 若中断被允许，CPU进入中断服务程序; 中断处理过程使一个高优先级任务就绪; 中断完成后，内核进行任务调度，让刚就绪的高优先级任务获得CPU;【调度点】 高优先级任务运行; 高优先级任务完成或因其它原因被阻塞而释放CPU，内核进行任务调度;【调度点】 低优先级任务获得CPU，从被中断的代码处继续运行 特点 最高优先级的任务一旦就绪，总能得到CPU的控制权 任务运行空间不再是封闭的，任务不可使用不可重入型函数 需要对共享数据进行必要的保护 实时操作系统大多基于抢占式内核 可重入型函数的理解 可重入型函数 该函数可以被一个以上的任务调用，而不必担心数据被破坏[基本特点] 可重入型函数任何时候都可以被中断，一段时间以后又可以运行，而相应数据不会丢失[可以随时中断或运行] 可重入型函数只使用局部变量，即变量保存在CPU寄存器中或堆栈中 【注解】这使得可重入型函数在发生中断时，其数据会被中断处理程序自动保存，当中断返回后，数据从堆栈中自动恢复，因此不会丢失任何数据. 不可重入型函数1234567int temp;void swap(int *x, int *y){ temp = *x; *x = *y; *y = temp;} 可重入型函数1234567void swap(int *x, int *y){ int temp; temp = *x; *x = *y; *y = temp;} 对临界区的理解【基本概念】临界区，又称为代码的临界区，指处理时不可分割的代码，代码一旦开始执行，则不允许任何中断打断.【临界区的保护】 在进入临界区之前要关中断 临界区代码执行完以后要立即开中断 【内核的关中断时间】 关中断影响中断延迟时间 内核在中断响应时间上的差异主要来自内核最大关中断时间 对共享资源的互斥管理 关中断 禁止任务切换 使用测试并置位指令 使用信号量（提供任务间通信、同步和互斥的最优选择 实时内核的重要性能指标【时间性能指标】 中断延迟时间 指从中断发生到系统获知中断，并开始执行中断服务程序所需要的最大滞后时间 中断延迟时间 = 最大关中断时间 + 中断嵌套的时间+ 硬件开始处理中断到开始执行ISR第一条指令之间的时间 实时内核应尽量使内核最大关中断时间减小 缩短关中断时间: 在临界区的一些非关键代码段开中断，增加内核代码中的可抢占点 中断响应时间 中断响应时间指从中断发生到开始执行用户中断服务程序的第一条指令之间的时间 中断响应时间 = 中断延迟时间 + 保存CPU内部寄存器的时间 + 该内核的ISR进入函数的执行时间 中断恢复时间 中断恢复时间指用户中断服务程序结束后回到被中断代码之前的时间。(对抢占式内核还应包括可能发生的任务切换时间) 中断恢复时间 = 恢复CPU内部寄存器的时间 + 执行中断返回指令的时间 任务响应时间 任务响应时间指从任务对应的中断产生到该任务真正开始运行所花费的时间，又称调度延迟 内核调度算法是决定调度延迟的主要因素 基于优先级的抢占式调度内核中，调度延迟比较小 第十二讲 $\\mu$C/OS-II的内核结构$\\mu$C/OS-II 中任务的状态$\\mu$C/OS–II支持最多64个任务，每个任务有一个特定的优先级，且优先级越高，其数值越小 运行态(运行) 任何时刻只能有一个任务处于运行态 就绪态(可以运行) 任务一旦建立，这个任务就进入就绪态，准备运行 挂起态(不可运行) 正在运行的任务可能需要等待某一事件的发生或将自己延迟一段时间 中断服务态(不属于多任务管理的范围) 正在运行的任务是可以被中断的，除非该任务将中断关闭; 被中断了的任务进入了中断服务态 休眠态(不属于多任务管理的范围) 任务创建之前的状态，仅驻留在程序空间，还没有交给$\\mu$C/OS-II管理 【任务控制块(TCB)】任务控制块是管理任务的数据结构: 任务控制块OS_TCB保存着该任务的相关参数 任务堆栈指针、状态、优先级、任务表位置、任务链表指针等 所有的任务控制块均在$\\mu$C/OS-II初始化时生成，分别存在于两条链表中: 空闲链表和使用链表 任务就绪表的工作机制空闲任务列表 初始态：所有任务控制块都被放置在任务控制块列表数组中 系统初始化: 所有任务控制块被链接成空任务控制块的单向链表 任务建立: 空任务控制块指针指向的任务控制块分配给该任务，链表中指针进行后移 任务队列一般情况下，操作系统通过任务队列的方式进行任务管理。将任务组织为就绪队列和等待队列: 任务就绪时，把任务控制块放在就绪队列尾 任务挂起时，把任务控制块放在等待队列尾 从就绪任务队列选择当前运行任务 【特点】任务处理时间与任务数量密切相关 优先级位图算法【任务就绪表】【注解】 优先级位图: 任务状态分为就绪态和非就绪态，对应两个状态，一比特位编码 任务优先级(0$\\sim 63$)划分为组号(高三位)与组内编号(低三位)，并且高优先级对应小的优先级号，其中组号索引OSRdyTbl，用组内编号索引OSRdyTbl OSRdyTbl类似二维数组，每个元素对应就绪表每一行 OSRdyGrp数组标记OSRdyTbl的每一行是否存在1，即全组任务中没有一个进入就绪态时，OSRdyGrp的相应位才为零 掩码数组OSMapTbl[7]用于对OSRdyTbl和OSRdyGrp置位，预存数组，使用时只是一次取内存的操作 OSMapTbl[0]=$2^0$=0x01(0000 0001) OSMapTbl[1]=$2^1$=0x02(0000 0010) OSMapTbl[7]=$2^7$=0x80(1000 0000) Op1: 使任务进入就绪态prio是任务的优先级，也是任务的识别号，则将任务放入就绪表，或使任务进入就绪态的方法： OSRdyGrp |= OSMapTbl[prio>>3] OSRdyTbl[prio>>3] |= OSMapTbl[prio & 0x07] Op2: 使任务脱离就绪态将任务就绪表OSRdyTbl[prio&gt;&gt;3]相应元素的相应位清零(掩码取反)，而且当OSRdyTbl[prio&gt;&gt;3]中的所有位都为零时，即全组任务中没有一个进入就绪态时，OSRdyGrp的相应位才为零 If((OSRdyTbl[prio>>3] &= ∼OSMapTbl[prio & 0x07])== 0) OSRdyGrp &= ∼OSMapTbl[prio>>3] Op3: 根据就绪表确定最高优先级$$\\min j (j=0, 1, \\cdots, 7), \\min i (j=0, 1, \\cdots, 7)$$ $\\max prio = j*8+i$ 查表法优化[优先级判定表] 查表法具有确定的时间，增加了系统的可预测性，$\\mu$C/OS中所有的系统调用时间都是确定的 High3 = OSUnMapTbl[OSRdyGrp] Low3 =OSUnMapTbl[OSRdyTbl[High3]] Prio =(Hign3> 3] pevent->OSEventTbl[prio >> 3] |= OSMapTbl[prio & 0x07] 注解：取出prio的低三位利用掩码数组OSMapTbl对组内编号置位，pevent是当前的任务控制块 从等待事件任务列表中使任务脱离等待状态(释放等待时间) if ((pevent->OSEventTbl[prio >> 3] &= ~OSMapTbl[prio & 0x07]) == 0) pevent->OSEventGrp &= ~OSMapTbl[prio >> 3] 在等待事件任务列表中查找优先级最高的任务(寻找最高优先级) y = OSUnMapTbl[pevent->OSEventGrp] x = OSUnMapTbl[pevent->OSEventTbl[y]] prio = (y < 3) + x","link":"/collaboration/EmbeddedSystem/"},{"title":"微型计算机原理与系统设计","text":"第一章 绪论：微型计算机概述第一讲 微型计算机概述基本概念 微型计算机系统的三个层次：微处理器、微型计算机、微型计算机系统 微处理器：由 1 片或几片大规模集成电路组成的中央处理器，也即微型计算机中的 CPU (中央处理单元），具体包括控制器、运算器、寄存器以及连接三者的片内总线； 微型计算机：微处理器、内存、I/O 接口以及连接三者的系统总线或芯片组的集合，也即裸机； 微型计算机系统：以微型计算机为中心，配以相应的外围设备以及控制微型计算机工作的软件，简称为微机； 软件：系统软件和应用软件； 外设：外存和 I/O 设备； 单片机：CPU、内存、I/O接口以及使三者互连的总线在一个芯片上的集成，也即微型计算机在一个芯片上的集成； 单片机系统：由单片机、专用软件和 I/O设备组成的系统，常用于特定任务的控制或处理； 单片机系统具有专用性，微型计算机系统具有通用性 微处理器概述 Intel微处理器发展 时间 型号 位宽 主频 制造工艺 1971年 4004 4位 108KHz 10$\\mu$ 1972年 8008 8位 500-800KHz 10$\\mu$ 1974年 8080 8位 2MHz 6$\\mu$ 1978年 8086 16位 5MHz 3$\\mu$ 1979年 8088 16位 5MHz 3$\\mu$ 1982年 80286 16位 6MHz 1.5$\\mu$ 1985年 80386 32位 16MHz 1.5$\\mu$ 1989年 80486 32位 25MHz 1$\\mu$ 1993年 Pentium I 32位 66MHz 0.8$\\mu$ 2001年 Itanium 64位 66MHz 0.8$\\mu$ 第二章 Intel 单核/多核处理器第一讲 单核处理器（Intel 8086处理器）8086/8088 处理器功能特性 16 位微处理器（内部数据总线） 引进指令级流水 引入分段管理机制，扩大寻址空间 只有整数运算能力，配套数值协处理器 8087、输入/输出协处理器 8089，具备较强大计算能力和 I/O处理能力 8086：16位；8088：8位（外部数据总线） 8086处理器的体系架构 【组成部分】 8086处理器分为两个部分：执行单元 (Execution Unit, EU) 和总线接口单元 (Bus Interface Unit, BIU) 执行单元 EU负责指令的执行，包括ALU（运算器）、通用寄存器组和状态寄存器 执行的运算：算术、逻辑、移位运算及段内偏移地址（即有效地址）的计算 总线接口单元 BIU负责与主存和I/O设备的接口，由段寄存器、指令指针、地址加法器和指令队列缓冲器等组成 主要操作：取指令、与主存或I/O设备交换数据 【工作机理】 EU与BIU并行工作 BIU在指令队列缓冲器有2个以上字节时就不断从主存连续地址单元中取得指令送入指令队列缓冲器中，EU则不断从指令队列缓冲器中取出指令加以译码执行 异常情况: 当6个字节的指令队列缓冲器满，且EU没有主存或I/O访问请求时，BIU进入空闲状态； 当EU执行访存或I/O指令时，BIU在执行完当前周期后，暂停取指令操作，在下一总线周期执行EU所要求的主存或I/O读写操作，之后再继续BIU的取指操作 当EU执行转移、调用、返回等程序跳转类指令时，BIU会清除之前读入指令队列缓冲器的无效指令，并根据EU提供的跳转指令，重新获取跳转后的程序段指令 【创新特点】 8086处理器引入指令队列缓冲器使得预取指令变为现实，取指令和执行指令可以并行执行，从而加速了程序的运行. 8086处理器的寄存器 8086处理器有14个寄存器：8个通用寄存器（4个数据寄存器、2个指针寄存器和2个变址寄存器）、2个控制寄存器和4个段寄存器. 【数据寄存器】 16位数据寄存器：AX、BX、CX和DX，可以存放16位的源操作数或目的操作数 为了支持字节操作，每个寄存器又分为两个8位的高、低字节寄存器：AH、AL、BH、BL、CH、CL、DH、DL 【指针寄存器】 SP(Stack Pointer)堆栈指针寄存器用于存放主存中堆栈区的偏移地址，指示堆栈的当前操作位置 BP(Base Pointer)基数指针寄存器用于存放主存的基本偏移地址 【变址寄存器】 SI(Source Index)源变址寄存器，指向源操作数，具有自动修改内容的功能 DI(Destination Index)目的变址寄存器，指向目的操作数，具有自动修改内容的功能 【控制寄存器】 IP(Instruction Pointer)指令指针寄存器，指示当前指令所在存储单元的段内偏移地址；当8086 CPU根据CS和IP取得一个指令字节后，IP便自动加1(顺序执行)，指向下一条待读取指令 分析8086处理器采用分段存储管理机制，CS段寄存器存放当前指令所在内存段的首地址，IP存放当前指令所在内存段内偏移地址，以此来获取指令的地址；操作系统执行程序时，将首地址加载至CS和IP中，转移类指令执行时：如果目标地址与程序首地址所在同一段，就用目标地址修改IP；如果目标地址与程序首地址在不同段，就用目标地址同时修改CS和IP. PSW(Program Status Word)程序状态字，也称程序寄存器或标志寄存器，存放CPU工作过程中的状态信息 【标志位】——16位暂定义了9个标志位 C——进位标志位，加减运算时标识最高位出现进位或借位，受逻辑运算、位移和循环指令的影响 P——奇偶标志位，标识运算结果低8位中1的个数是否为偶数 A——半加进位标志位，加减运算时标识低4位向高4位是否进位或借位，用于对BCD结果的校正 Z——零标志位，标识运算结果是否为全0 S——符号标志位，标识运算结果是否为负数，当运算结果最高位为1时，该标志位置为1 T——单步标志位（陷阱标志位），标志位置为1时，8086处理器进入单步执行指令方式；每条指令执行完毕时，CPU测试T标志位：若T=1则在当前指令执行后产生单步中断（陷阱中断），CPU执行陷阱中断处理程序：该程序能够显示当前指令执行结果，为程序调试提供必要的信息 I——中断允许标志位，该标志位为1时，CPU可响应可屏蔽中断请求，否则不响应可屏蔽中断请求 D——方向标志位，若该标志位为1，则SI和DI在串操作指令执行中自动减量，即从高地址到低地址处理字符串，否则在串操作指令执行中自动增量 O——溢出标志位，标识带符号数运算结果是否超出8位或16位表示范围 【段寄存器】 组成：代码段寄存器 CS(Code Segment)、数据段寄存器 DS(Data Segment)、堆栈段寄存器 SS(Stack Segment)和附加段寄存器 ES(Extra Segment) 作用：存储不同属性段的段地址，与有效的段内偏移地址一起确定主存的物理地址; CS指示程序区，DS和ES指示数据区，SS指示堆栈区 8086 主存储器和 I/O结构【主存分段存储管理机制】 8086处理器的主存物理地址由段地址和段内偏移地址确定，且主存空间: $1MB$，每段大小: $64KB$，则可以划分的虚拟段数为: $$\\frac{1MB}{64KB}=\\frac{2^{20}B}{2^{16}B}=2^4$$ 因此 1MB 主存可以划分为$2^4$ 个不重叠的存储段，对于段起始地址（有效高四位）采用低位对齐策略即段起始地址的低4位全为 0，可以使得 $20$ 位段地址降低为 $16$ 位，调整段起始地址又可以指定不同存储段因此又可以划分为 $2^{16}$ 个重叠的存储段；段内偏移地址（有效低16位）可以决定段内的地址.$BIU$ 中有一个地址加法器，作用是将 $16$ 位段地址左移 $4$ 位，然后与 $16$ 位段内偏移地址相加，生成 $20$ 位的物理地址: $$Memory\\ Address=CS\\times16+IP$$ 每个存储单元的地址标识：$20$ 位物理地址/逻辑地址（段地址 $16$ 位：段内偏移地址 $16$ 位）由上式可以看出，8086处理器可以提供20位的地址，对主存单元寻址使用全部20位地址，对I/O设备端口寻址使用其低16位地址：1M的主存存储空间、64K的I/O设备端口空间【主存结构设计】 支持字节操作：8086处理器采用字节编址方式，即主存或I/O的一个地址单元内存储一个字节，实现根据地址进行1字节的存储器或I/O设备的读/写操作 支持16位数据操作：字节编址方式下使用两个连续地址来访问16位数据，并按小段模式存储，实现16位存储器或I/O操作 【主存和I/O系统的分体结构】 主存的存储空间和I/O的端口空间均采用奇、偶双体存储器，偶地址对应低字节的访问，通过低字节允许信号 $A_0=0$ 选择；奇地址空间对应高字节的访问，通过高字节允许信号 $\\overline{BHE}=0$ 选择； $\\overline{BHE}$ $A_0$ 操作说明 $0$ $0$ 高字节体与低字节体同时有效，给定地址$n^*$，从主存或 I/O 空间读写16位数据 $0$ $1$ 高字节体有效，给定奇地址$n$，从主存或 I/O 空间读写8位数据 $1$ $0$ 低字节体有效，给定偶地址$n$，从主存或 I/O 空间读写8位数据 $1$ $1$ 高字节体和低字节体无效，不能访问主存或 I/O 空间 注 $^*$:当 $n$ 为偶地址时，仅需一个总线周期就可以完成 $2$ 字节的读/写，其中 地址 $n$ 读/写数据低 $8$ 位，地址 $n+1$ 读/写数据高 $8$ 位（主存按字节编址）；当 $n$ 为奇地址时，则需要两个总线周期才可以完成 $2$ 字节的读/写，其中第一个总线周期从地址 $n$ 读/写数据低 $8$ 位，第二个总线周期从地址 $n+1$ 读/写数据高 $8$ 位（主存按字节编址）；（总线周期：CPU通过系统总线对主存或 I/O 设备进行一次读/写访问所需的时间） 【数据按属性分段存储】8086处理器设置了 $4$ 个属性的存储段：程序段（代码段）、数据段、堆栈段和附加段，并用段寄存器 $CS$、$DS$、$SS$ 和 $ES$ 分别为 $4$ 个属性段提供段地址. 在访存操作中，段地址由“默认”或“指定”的段寄存器提供： 段寄存器的默认使用情况 段寄存器的指定使用情况 通过在指令中增加一个字节的段超越前缀指令来实现：$MOV\\ AL,ES:[BX]$(从存储单元 ($ES$:$BX$) 中读取数据) 8086处理器芯片引脚 关注方面 作用 引脚功能 引脚信号的定义、作用 信号的流向 输出、输入、双向 有效电平 高电平有效、低电平有效、上升沿有效、下降沿有效 三态能力 低电平、高电平、高阻 【8086 CPU 引脚分析——工作条件】 名称 方向 有效电平 功能 $VCC$ $Input$ $+5V$ 工作电源 $GND$ $Input$ $1$ 接地端 $CLK$ $Input$ $5MHz$ 时钟信号 $RESET$ $Input$ $1$ 复位信号 $MN$ $Input$ $1$ 最小工作模式 $MX$ $Input$ $0$ 最大工作模式 $AD_0\\sim AD_{15}$ $Input/Output$ 三态 地址或数据总线 $A_{16}\\sim A_{19}$ $Output$ 三态 地址总线 $BHE$ $Output$ 三态 高字节允许信号 $INTR$ $Input$ $1$ 可屏蔽中断信号 $INTA$ $Output$ 三态 对$INTR$ 请求信号的响应信号 $READY$ $Input$ $1$ 准备就绪信号 $TEST$ $Input$ $0$ 测试信号 $DT/\\overline{R}$ $Output$ 三态 数据发送/接受控制信号 $DEN$ $Output$ 三态 数据有效信号 $ALE$ $Output$ $1$ 地址锁存信号 I. 两种工作模式下的共用信号【$A_{16}\\sim A_{19}/S_3\\sim S_6$】$A_{16}\\sim A_{19}$ 与 $S_3\\sim S_6$ 分时复用信号，$S_6$ 始终为0，$S_5$ 表示中断允许标志的状态，$S_4$、$S_3$ 指示 CPU 正在使用的寄存器；【$\\overline{BHE}/S_7$】分时复用信号，$\\overline{BHE}$ 在总线周期的 $T_1$ 时钟周期起作用；$S_7$ 为备用状态；【$RESET$】复位信号，当 $RESET$ 返回低电平时，CPU重新启动；【$READY$】CPU读写主存或 I/O 设备时，在总线周期的 $T_3$ 时钟周期采样 $READY$ 信号；当为低电平时，需要在 $T_3$ 周期之后插入等待周期 $T_{WAIT}$ ；【$INTR$】CPU 在每条指令执行的最后一个时钟周期采样该信号，以决定是否进入中断响应周期；【$NMI$】非屏蔽中断请求信号，上升沿有效，中断不可被屏蔽，$NMI$ 请求的优先级高于 $INTR$ 请求；【$\\overline{INTA}$】在响应中断过程中，由 $\\overline{INTA}$ 送出两个负脉冲，在第二个 $INTA$ 周期 CPU 获得外部中断源的中断向量码；【$DT/\\overline{R}$】数据发送/接受控制信号，高电平控制数据发送；低电平控制数据接受；【$\\overline{DEN}$】数据有效信号，表示 $D_0\\sim D_{15}$ 的数据是否有效；该信号在最小模式下由 8086 提供，低电平有效，在最大模式下由 8288 提供，高电平有效；【$ALE$】地址锁存信号，高电平有效，表示 $A_0\\sim A_{19}$ 上的地址有效； II. 最小工作模式当$MN/\\overline{MX}=1$ 时， 8086 CPU工作在最小模式，微机中只有一个处理器，系统总线仅由CPU信号形成； 【$M/\\overline{IO}$(输出、三态)】低电平访问 I/O 设备；高电平访问主存；【$\\overline{RD}$(输出、三态)】低电平有效，表示CPU正在读主存或 I/O 接口；【$\\overline{WR}$(输出、三态)】低电平有效，表示CPU正太写主存或 I/O 接口；【$HOLD$(输入)】保持请求信号，高电平有效，表示某总线设备请求使用系统总线；【$HLDA$(输出、三态)】保持允许信号，高电平有效，表示 CPU 对 HOLD 请求的响应信号； III. 最大工作模式当$MN/\\overline{MX}=0$ 时， 8086 CPU工作在最大模式，微机中除了主处理器8086，还允许接入其他协处理器（运算处理器8087、I/O 处理器8089）构成多微处理器系统，系统总线由 8086 和总线控制器 8288 提供的信号共同形成； 【$\\overline{S_0}$、$\\overline{S_1}$、$\\overline{S_2}$(输出、三态)】表示该总线周期存取哪种设备的状态信号，是 $8288$ 产生控制信号的依据； 【$8288$ 不同之处】 8288 的 $DEN$ 信号为高电平有效； 8288 通过 $\\overline{MRDC}$(存储器读信号)，$\\overline{MWTC}$(存储器写信号)、$\\overline{IORC}$(I/O 读信号)、$\\overline{IOWC}$(I/O 写信号)来控制对主存或I/O的访问； 【$\\overline{LOCK}$(输出、三态)】总线索存信号，低电平有效，信号有效期间，总线请求信号被封锁； 【$QS_0, QS_1$(输出)】表示指令队列缓冲器存取的状态信号: QS1 QS0 性能 0 0 无操作 0 1 队列中操作码的第一个字节 1 0 队列空 1 1 队列中非第一个操作码字节 8086处理器工作时序【指令周期】在冯诺依曼计算机中，将CPU取得并执行一条指令所花的时间定义为一个指令周期。【总线周期】CPU通过系统总线对主存或I/O设备进行一次读/写访问所需的时间。8086 CPU的一个总线周期由 4 个时钟周期（T1、T2、T3、T4）组成。【基本总线时序】等待周期 $T_{WAIT}$ 一般插入到 $T_3$ 后面 I. 写总线周期(Concise Mode)$T_1:\\ Load\\ Address$ $A_{16}\\sim A_{19}/S_3\\sim S_6\\Longrightarrow A_{16}\\sim A_{19}$ $\\overline{BHE}/S_7\\Longrightarrow \\overline{BHE}$ $AD_0\\sim AD_{15}\\Longrightarrow A_0\\sim A_{15}$ $A_0\\sim A_{19}, \\overline{BHE}\\stackrel{ALE}\\Longrightarrow$ 锁存器 $T_1:\\ Select\\ Interface$ $M/\\overline{IO}==1\\Longrightarrow A_0\\sim A_{19}(Memory\\ Unit)$ $M/\\overline{IO}==0\\Longrightarrow A_0\\sim A_{15}\\ with\\ A_{16}\\sim A_{19}=0(IO\\ Interface)$ $T_2:\\ Load\\ Data$$AD_0\\sim AD_{15}\\Longrightarrow D_0\\sim D_{15}$ $\\overline{WR},\\ M/\\overline{IO},\\ A_0\\sim A_{19}\\Longrightarrow Memory/IO(Minimal\\ Mode)$ $\\overline{MWTC},\\ \\overline{IOWC},\\ A_0\\sim A_{19}\\Longrightarrow Memory/IO(Maximal\\ Mode)$ $T_3:\\ Continue\\ T_2$READY信号：解决主存或I/O接口实际写入时间长于CPU提供的时间的问题 $(T_3$ 开始时刻即下降沿 $):\\ Test\\ READY==0$ $\\Longrightarrow Insert\\ T_{WAIT}$ $(T_{WAIT}$ 开始时刻即下降沿 $):\\ Test\\ READY==0$ $\\Longrightarrow Insert\\ T_{WAIT}\\Rightarrow Continue\\ Loop$ $Test\\ READY==1\\Longrightarrow T_4$ $T_4:\\ Restore\\ States$ II. 读总线周期(Concise Mode)——对比写总线周期$DT/\\overline{R}$ $DT/\\overline{R}==0,Bus\\stackrel{data}\\Longrightarrow CPU(Read\\ Mode)$ $DT/\\overline{R}==1,CPU\\stackrel{data}\\Longrightarrow Bus(Write\\ Mode)$ III. 中断响应周期(Concise Mode)$Response\\ Conditions:$ $INTR == 1\\ and\\ IF == 1\\ (Request\\ and\\ permission)$ $INTA\\ Period:\\ from\\ T_2\\ to\\ T_4$$First\\ INTA\\ Period$: 通知提出 $INTA$ 请求的中断源，请求已得到响应，并封锁总线 $Second\\ INTA\\ Period$: 总线封锁信号 $\\overline{LOCK}$ 无效，中断源 $\\stackrel{中断向量码}\\Longrightarrow D_0\\sim D_7$ $D_0\\sim D_7\\stackrel{中断向量码}\\Longrightarrow CPU$ 8086系统总线的形成系统总线：地址总线(AB)、数据总线(DB)、控制总线(CB) I. 最小模式的系统总线8086 CPU 工作在最小模式下，系统总线信号全部来自CPU 地址总线 AB: $A_0\\sim A_{19}$、$\\overline{BHE}/S_7$ (ALE信号由 8086 CPU 提供) 双向数据总线 DB: $D_0\\sim D_{15}$ 控制总线 CB: 8086 CPU 在最小模式下提供的所有控制信号 II. 最大模式的系统总线8086 CPU 工作在最大模式下，系统总线信号来自 CPU 和总线控制器 8288 地址总线 AB: $A_0\\sim A_{19}$、$\\overline{BHE}/S_7$ (ALE信号由总线控制器 8288 提供) 双向数据总线 DB: $D_0\\sim D_{15}$ 控制总线 CB: 最大模式下的控制总线信号由 8086 CPU 和总线控制器 8288 共同提供 III. 常用芯片引脚分布【74LS373——8位锁存器】 【74LS245——双向驱动器】 【74LS244——单向驱动器】 第三章 Intel 处理器指令系统及汇编语言第一讲 指令寻址方式操作数的寻址方式指令格式：操作码+操作数（操作数本身/操作数地址/地址的一部分/操作数地址的指针/其他操作数信息） 立即寻址 Example: MOV AX, im 指令格式：操作数包含在指令中存储形式：操作码 $[n]+imL[n+1]+imH[n+2]$（小端存储）存储位置：与操作码一起存放在代码段区域中指令用途：主要用来给寄存器/存储器赋初值 Operand = AH &lt;&lt; 8 + AL = imH &lt;&lt; 8 + imL 直接寻址 Example: MOV AX, DS:[offset] 指令格式：16位段内偏移地址包含在指令中存储形式：操作码 $[n]+offsetL[n+1]+offsetH[n+2]$（小端存储）存储位置：与操作码一起存放在代码段区域中 Address = DS &lt;&lt; 4 + offsetOperand = AH &lt;&lt; 8 + AL = Mem[Address] &lt;&lt; 8 + Mem[Address+1] 寄存器寻址 Example: MOV DS, AX 指令格式：操作数包含在CPU的内部寄存器中存储位置：存放在寄存器中 Operand = (Reg) 寄存器间接寻址 Example: MOV AX, [SI] 指令格式：操作数的16位段内偏移地址存放在 $SI/DI/BP/BX$ 中, 其中 $SI/DI/BX$ 间接寻址时操作数通常存放在现行数据段中; $BP$ 间接寻址时操作数存放在堆栈段中存储位置：操作数存放在存储器中 Address = (DS) &lt;&lt; 4 + (SI/DI/BX) / (SS) &lt;&lt; 4 + (BP)Operand = AH &lt;&lt; 8 + AL = Mem[Address] &lt;&lt; 8 + Mem[Address+1] 寄存器相对寻址 Example: MOV AX, DISP[SI] 指令格式：指令中存放段内偏移地址的寄存器 $SI/DI/BX/BP$ + $8/16$ 位带符号相对地址偏移量 $DISP$存储位置：操作数存放在存储器中 Address = (DS) &lt;&lt; 4 + (SI/DI/BX) + DISP / (SS) &lt;&lt; 4 + (BP) + DISPOperand = AH &lt;&lt; 8 + AL = Mem[Address] &lt;&lt; 8 + Mem[Address+1] 基址、变址寻址 Example: MOV AX, [BX][SI] 指令格式：指令指定一个基址寄存器 $BX/BP$ 和一个变址寄存器 $SI/DI$存储位置：操作数存放在存储器中 Address = (DS) &lt;&lt; 4 + (BX) + (SI/DI) / (SS) &lt;&lt; 4 + (BP) + (SI/DI)Operand = AH &lt;&lt; 8 + AL = Mem[Address] &lt;&lt; 8 + Mem[Address+1] 基址、变址、相对寻址 Example: MOV AX, [BX][SI] 指令格式：指令指定一个基址寄存器 $BX/BP$、一个变址寄存器 $SI/DI$ 和相对偏移地址 $DISP$存储位置：操作数存放在内存中 Address = (DS) &lt;&lt; 4 + (BX) + (SI/DI) + DISP / (SS) &lt;&lt; 4 + (BP) + (SI/DI) + DISPOperand = AH &lt;&lt; 8 + AL = Mem[Address] &lt;&lt; 8 + Mem[Address+1] 隐含寻址 Example: 乘法指令 MUL BL 十进制调整指令 DAA 串传送指令 MOVSW 指令格式：操作数的地址隐含在指令操作码中 转移地址的寻址方式 段内直接寻址（相对寻址） Example: JMP DSP1 指令格式：指令指明8位或16位带符号相对地址偏移量 $DISP$(补码表示)指令说明：相对寻址指的是在程序计数器的基础上加上偏移量进行相对位移 Jump Address = (CS) &lt;&lt; 4 + ((IP) + DISP) 段内间接寻址 Example: JMP CX 指令格式：指令指明存放段内偏移地址的寄存器或存储器单元地址，按指令码中规定的寻址方式取得转移地址指令说明：间接寻址指的是通过寄存器或存储器单元获取得到新的段内偏移地址赋值给程序计数器而段地址不变 Jump Address = (CS) &lt;&lt; 4 + (CX) 段间直接寻址 Example: JMP FAR PTR OPRD PTR 属性运算符: 给指令中的操作数指定一个临时属性，暂时忽略当前属性 作用于操作数时，重载操作数的类型(字节或字)或属性(NEAR或FAR) NEAR, SHORT, FAR 表示操作数的属性 SHORT 表示段内短转移, IP 偏移量: $-128\\sim127$ 字节($8$ 位，一个字节) NEAR 表示段内近转移, IP 偏移量: $-32768\\sim32767$ 字节($16$ 位，两个字节) FAR 表示段间转移 指令格式：指令码指明段地址和偏移地址所在存储单元的首地址: OPRD (标号或立即数, 标号会在编译时由 CPU 转换为对应的地址)指令说明：操作码后连续四个字节，低字表示段内转移地址，高字表示段地址，直接赋值给 IP, CS (直接寻址) Jump Address = (CS) &lt;&lt; 4 + (IP) 段间间接寻址 Example: JMP DWORD PTR [BP][DI] 指令格式：依据指令码寻址方式确定存储单元的首地址，前两个单元：段内偏移地址，后两个单元：段地址指令说明：需要确定段地址 ($16$位) 和段内偏移地址 ($16$位) $32$ 位信息，只适用于存储器寻址方式 Address = SS + BP + DICS = Mem[Address+3] &lt;&lt; 8 + Mem[Address+2], IP = Mem[Address+1] &lt;&lt; 8 + Mem[Address]Jump Address = (CS) &lt;&lt; 4 + (IP) 第二讲 汇编语言 引言：汇编语言的用途 嵌入式系统中，程序大小和运行速度需要高度优化 设计驱动程序、操作系统内核以及编译程序 高级语言中嵌入汇编 汇编语言的访问层次 OS函数 BIOS功能（一组固化到计算机内主板上一个ROM芯片上的程序，保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序） 硬件 汇编语言程序结构 操作系统装入程序：初始化CS为正确的代码段地址，初始化SS为正确的堆栈段地址 ASSUME 伪指令：指明段与段寄存器的对应关系 编译、链接和运行程序 汇编语言基本元素 […] 中的参数可选，{…|…} 多选一（由’|’隔开） 整数常量 digits[radix] radix 进制 radix 进制 radix 进制 radix 进制 radix 进制 h 十六进制 b 二进制 q/o 八进制 d 十进制 r 编码实数 保留字 指令助记符: 标识特定的指令，Example: MOV, ADD 伪指令: 指明 MASM 如何编译程序 属性: 变量和操作数的尺寸以及使用方式的说明 运算符: 常量表达式中 预定义符号: Example: @data (编译时返回整数常量) 定义数据伪指令 符号常量伪指令不占用任何实际的存储空间 等号伪指令 Example:COUNT = 500mov cx COUNT EQU伪指令 TESTEQU伪指令 操作符 OFFSET 返回数据标号的偏移地址（标号距数据段开始的距离，以字节为单位） 保护模式下偏移: $32$ 位，实模式下偏移: $16$ 位 Example: Address[bVal] = $00300$h 12345.databVal DB ?wVal DW ?mov si, OFFSET bVal ; SI=0000Hmov si, OFFSET wVal ; SI=0001H SEG 返回变量或数据标号的段基址 Example: 1234.databuffer DB ?mov ax, SER buffermov ds, ax PTR 重载操作数的默认尺寸 标准数据类型：DB, SDB, WORD, SWORD, DWORD, SDWORD, FWORD, QWORD, TDB Example: 1234567.datamyDouble DD 12345678h ; Data Double Words: 32位数据.codemov ax, myDouble ; ax为16位寄存器，数据长度不一致引发报错mov ax, DW PTR myDouble ; Data Word: 16位数据, ax=5678hmov ax, DW PTR [myDouble+2] ; ax=1234hmov bl, DB PTR myDouble ; Data Byte: 8位数据, bl=78h TYPE 返回按字节计算的变量单个元素的大小 Example: 12345.datavar1 DB ? ; Data Bytevar2 DW ? ; Data Wordvar3 DD ? ; Data Double Wordsvar4 DQ ? ; Data Quanter Words 表达式 值 TYPE var$1$ $1$ TYPE var$2$ $2$ TYPE var$3$ $4$ TYPE var$4$ $8$ LENGTHOF 计算数组中元素个数 Example: 123456.dataDB1 DB 10, 20, 30array1 DW 30 DUP(?), 0, 0array2 DW 5 DUP(3, DUP(?))array3 DD 1, 2, 3, 4digitStr DB &quot;12345678&quot;, 0 表达式 值 LENGTHOF DB$1$ $3$ LENGTHOF array$1$ $30+2$ LENGTHOF array$2$ $5\\times3$ LENGTHOF array$3$ $4$ LENGTHOF digitStr $9$ SIZEOF SIZEOF返回值=LENGTHOF返回值 $\\times$ TYPR返回值 Example: 12.dataintArray DW 32 DUP(0) 表达式 值 TYPE intArray $2$ LENGTHOF intArray $32$ SIZEOF intArray $64$ 第三讲 指令系统数据传送指令 操作数类型 立即数 (Immediate) Label imm: $8$、$16$、$32$ 位立即数 imm8: $8$ 位立即数 imm16: $16$ 位立即数 imm32: $32$ 位立即数 立即数只能用作源操作数 立即数类型 $8$ 位 $16$ 位 无符号数 $00H\\sim FFH(0\\sim 255)$ $0000H\\sim FFFFH(0\\sim 65535)$ 有符号数 $80H\\sim 7FH(-128\\sim 127)$ $8000H\\sim 7FFFH(-32768\\sim 32767)$ 寄存器操作数 (Register) Label reg: 任意的通用寄存器 sreg: $16$ 位段寄存器 (CS, DS, SS, ES, FS, GS) r8: AH, AL, BH, BL, CH, CL, DH, DL r16: AX, BX, CX, DX r32: EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP SI, DI, SP, BP 只能存放字操作数 不允许将立即数传送到段寄存器 内存操作数 (Memory) Label mem: $8$、$16$ 或 $32$ 内存操作数 不允许两个操作数同时为存储器操作数 Example: 12345.codemov [8000H], [1000H] ; Errormov buff1, buff2 ; Errormov al, [buff2] ; 编译器自动将名称转换为地址偏移量mov al, [buff1+1] ; 直接偏移操作数 数据传送指令 MOV 指令格式：mov desination, source Special Rules: 两个操作数类型尺寸必须一致 目的操作数不能是 CS 和 IP (保护程序执行) 特殊用法 (AX作桥梁) 123456789; 存储器 -&gt; 存储器MOV AX, MEM1MOV MEM2, AX; 段寄存器 -&gt; 段寄存器MOV AX, DSMOV ES, AX; 立即数 -&gt; 段寄存器MOV AX, 1000HMOV DS, AX MOVZX (move with zero-extend, 高位填充 $0$) 指令格式: movzx r32, r/m8 movzx r32, r/m16 movzx r16, r/m8 Example: 1234.codemov bx, 0A69Bhmovzx eax, bxmovzx ax, bl MOVSX (move with sign-extend, 高位填充符号位) 指令格式: movzx r32, r/m8 movzx r32, r/m16 movzx r16, r/m8 Example: 12345.codemov bx, 0A69hmovsx eax, bx ; eax = FFFFA69Bhmovsx edx, bl ; edx = FFFFFF9Bhmovsx ax, bl ; ax = FF9Bh 字节-字转换命令 指令格式: CBW: 把 AL 的符号位复制到 AH CWD: 把 AX 的符号位复制到 DX 用途: 用于有符号数的除法 XCHG (exchange data) 指令格式: xchg reg, reg xchg reg, mem xchg mem, reg Rules: 两个操作数至少有一个在寄存器中 操作数不能是段寄存器和立即数 操作数类型一致 Example: 1234.codemov ax, val1xchg ax, val2mov val1, ax 堆栈操作指令概述 以字 ($16$ 位) 为单位进行数据压入和弹出操作，但是存储单元仍是 $8$ 位 SS 指示堆栈段的段基址，SP 始终指向堆栈的顶部，即最后一个存储单元 进栈方向从高地址向低地址发展 (SP 的初值决定了所用堆栈区的大小) 堆栈用途 作为临时保存区域，保存局部变量 备份寄存器状态，以便恢复其原始值 CALL 指令执行时，CPU 用堆栈保存当前过程的返回地址 调用过程中，通过堆栈传递参数 PUSH 指令格式: PUSH SRC (SRC 为 $16/32$ 位操作数，对应 SP 以 $2/4$ 递减) Example: 12345.codepush ax; (SP-1) &lt;- AH; (SP-2) &lt;- AL; (SP) &lt;- (SP)-2 小端存储，注意括号寻址 POP 指令格式: POP DEST (DEST 为 $16/32$ 位操作数，对应 SP 以 $2/4$ 递增) 指令功能: 从堆栈顶部连续取两个单元的内容送到 DEST 指定的位置 Example: 1234.codepop ax ; 寄存器pop ds ; 数据段寄存器pop [bx] ; 内存单元 PUSHFD ($32$ 位程序) 在堆栈上压入 $32$ 位 EFLAGS 寄存器的值 Example: 1234567.datasaveFlags DWORD ?.codepushfd ; 标志入栈，不需指定pop saveFlags ; 拷贝到变量push saveFlags ; 将保存的标志入栈popfd ; 恢复标志，不需指定 POPFD ($32$ 位程序) 将堆栈顶部的值弹出并送至 EFLAGS 寄存器 PUSHF (实地址模式) 在堆栈上压入 $16$ 位 FLAGS 寄存器的值 POPF (实地址模式) 将堆栈顶部的值弹出 $16$ 位的值并送至 FLAGS 寄存器 PUSHAD (Push All Data) 在堆栈上按顺序压入所有 $32$ 位通用寄存器: EAX, ECX, EDX, EBX, ESP, EBP, ESI, EDI POPAD (Pop All Data) 在堆栈上按相反的顺序弹出所有 $32$ 位通用寄存器: EDI, ESI, EBP, ESP, EBX, EDX, ECX, EAX PUSHA ($80286$ 处理器) 在堆栈上按顺序压入所有 $16$ 位通用寄存器: AX, CX, DX, BX, SP, BP, SI, DI POPA ($80286$ 处理器) 在堆栈上按相反的顺序弹出所有 $16$ 位通用寄存器: DI, SI, BP, SP, BX, DX, CX, AX LEA (Load Effective Address) 指令格式: LEA reg, mem 指令功能: 将指定存储器的 $16$ 位偏移地址送到指定的寄存器 Example: 123LEA BX, BUFFER ; 符号地址为 BUFFER 的存储单元的偏移地址取到 BX 中MOV BX, BUFFER ; 符号地址为 BUFFER 的存储单元中内容送至 BX 中LEA BX, BUFFER = MOV BX, OFFSET BUFFER ; LEA 可以取动态的地址, OFFSET 只能取静态的地址 LDS (Load DS) 指令格式: LDS reg, mem32 指令功能: $mem32$ 开始的四个内存单元 $\\rightarrow$ DS:reg (高 $16$ 位 $\\rightarrow$ DS, 低 $16$ 位 $\\rightarrow$ reg) LES (Load ES) 指令格式: LES reg, mem32 指令功能: $mem32$ 开始的四个内存单元 $\\rightarrow$ ES:reg (高 $16$ 位 $\\rightarrow$ ES, 低 $16$ 位 $\\rightarrow$ reg) Special Rules(LEA, LDS, LES): 源操作数必须是一个内存操作数 目的操作数必须是一个 $16$ 位的通用寄存器 算术运算类指令 加法和减法指令 INC 指令格式: INC OPRD 指令功能: 操作数 + $1$ $\\rightarrow$ 目的操作数 DEC 指令格式: DEC OPRD 指令功能: 操作数 - $1$ $\\rightarrow$ 目的操作数 Special Rules(INC, DEC): 不影响 CF, 影响 OF, SF, ZF, AF, PF ADD 指令格式: ADD DEST, SRC 指令功能: 源操作数+目的操作数 $\\rightarrow$ 目的操作数 ADC 指令格式: ADC DEST, SRC 指令功能: 源操作数+目的操作数+ CF $\\rightarrow$ 目的操作数 指令用途: 多用于多字节加法运算中 Example: 有两个 $4$ 字节的数分别存放在 FIRST 和 SECOND 开始的两个存储区中，试将两数相加并将结果放回 FIRST 存储区中 1234567.codemov ax, FIRST ; 第一个数的低 16 位送 axadd ax, SECOND ; 两数的低 16 位相加送 axmov FIRST, ax ; 低 16 位相加结果送 FIRST 和 FIRST+1 单元 (小端存储)mov ax, FIRST+2 ; 第一个数的高 16 位送 axadc ax, SECOND+2 ; 高 16 位同低位进位相加送 ax mov FIRST+2, ax ; 高 16 位相加的结果存入 FIRST+2 和 FIRST+3 单元 SUB 指令格式: SUB DEST, SRC 指令功能: 目的操作数 - 源操作数 $\\rightarrow$ 目的操作数 SBB 指令格式: SBB DEST, SRC 指令功能: 目的操作数 - 源操作数 - CF $\\rightarrow$ 目的操作数 指令用途: 多用于多字节减法运算中 影响标志位: CF, ZF, SF, OF, AF, PF NEG 指令格式: NEG OPRD 指令功能: 0 - (OPRD) $\\rightarrow$ OPRD (OPRD 可以为 REG/MEM) 指令说明: 将操作数按位求反、末位加一 (求补运算) 影响标志位: CF, ZF, SF, OF, AF, PF Example: 12345.dataval DB FCH.codemov al, valneg al ; (al) = 04H, CF = 1 乘法和除法指令 MUL 指令格式: MUL r/m$8$/m$16$/m$32$ 指令功能: 无符号乘法 被乘数 乘数 积 CF=$1$的条件 AL r/m$8$ AX AH$\\neq0$ AX r/m$16$ DX:AX DX$\\neq0$ EAX r/m$32$ EDX:EAX EDX$\\neq0$ IMUL 指令格式: IMUL r/m$8$/m$16$/m$32$ 指令功能: 有符号乘法 指令说明: 积的高半部分不是第半部分的符号扩展，则设置 CF 和 OF DIV 指令格式: DIV r/m8/m16/m32) 指令功能: 无符号除法，影响 OF 被除数 除数 商 余数 AX r/m8 AL AH DX:AX r/m16 AX DX EDX:EAX r/m32 EAX EDX IDIV 指令格式: IDIV r/m$8$(/$16$/$32$) 指令功能: 有符号除法，影响 OF 被除数 除数 商 余数 AX r/m8 AL AH DX:AX r/m16 AX DX EDX:EAX r/m32 EAX EDX CBW 将AL中的符号位扩展到AH CWD 将AX中的符号位扩展到DX CDQ 将EAX中的符号位扩展到EDX 溢出 商太大，目的操作数无法容纳 -&gt; 使用32位除数 除数 = 0 $\\rightarrow$ 跳过，不执行 逻辑运算和移位指令 逻辑运算类指令 AND 指令格式: AND DEST, SRC 指令功能: DEST &amp; SRC $\\rightarrow$ DEST (对特定位清零，同时保留其他位) 影响的标志位: 清除 OF 和 CF, 修改 SF, ZF, PF Example: 大小写字母的转换(大写转小写方法：将位 $5$ 设置为 $1$, 加32得到小写字母) ‘a’: 61h, 即 $01\\boldsymbol{1}00001$ ‘A’: 41h, 即 $01\\boldsymbol{0}00001$ 123456789.data array DB 50 DUP(?).code mov cx, LENGTHOF array mov si, OFFSET arrrayL1: and byte PTR [si], 11011111b inc si loop L1 OR 指令格式: OR DEST, SRC 指令功能: DEST | SRC $\\rightarrow$ DEST (对特定位设 $1$，同时保留其他位) Example: $0\\sim9$ 数字转换为 ASCII 码数字 (方法：将位 $4$ 和位 $5$ 设置为 $1$, 数字加48得到数字字符) $05$h: 00000101b $30h$: 00$\\boldsymbol{11}$0000b 123.code mov dl, 05h or dl, 30h XOR 指令格式: XOR DEST, SRC 指令功能: DEST ^ SRC $rightarrow$ DEST (对特定位取反，同时保留其他位) Example: 判断 $16$ 位或 $32$ 位值奇偶性 简单数据加密 $(X\\oplus Y)\\oplus Y=X$ 对 Reg 清零 (自身异或) 把 Reg/Mem 得某几位取反 (与 $1$ 异或) 123.code mov ax, 64C1h xor ah, al 寄存器清零 MOV AX, $0$ XOR AX, AX AND AX, $0$ SUB AX, AX NOT 指令格式: NOT Reg/Mem 指令功能: 对数据位取反，结果为反码 (不影响任何状态标志) 比较测试指令 CMP 指令格式: CMP DEST, SRC 指令功能: 目的操作数 - 源操作数, 但不回送结果只影响标志位 影响标志位: CF, ZF, SF, OF, AF, PF 判读比较结果 两个无符号数 CMP Result ZF CF DEST &lt; SRC 0 1 DEST &gt; SRC 0 0 DEST = SRC 1 0 两个有符号数 CMP Result Sign DEST &lt; SRC SF$\\neq$ OF DEST &gt; SRC SF=OF DEST = SRC ZF=1 TEST 指令格式: TEST DEST, SRC 指令功能: DEST &amp; SRC, 根据结果设置标志位但不回送结果 影响标志位: 清除 OF, CF；修改 SF, ZF, PF Example: 测试操作数的某一位是 $0$ 或 $1$ 123.codetest al, 80H ; 检查 al 操作数是否是负数 (D7=1)jnz MINUS ; 条件跳转指令, 转到 MINUS 12.codetest al, 00001001H ; 检查 al 操作数第 0 位和第 3 位是否同时为 0 控制转移指令 转移指令概述 实质: 改变 IP(或 CS) 的内容 所有转移指令不会影响标志位 无条件转移指令 JMP JMP disp (段内直接转移) CS 保持不变, 指令中 $8/16$ 位偏移量加到 IP JMP SHORT OPRD $8$ 位偏移地址: $-128\\sim +127$ JMP NEAR PTR BUF $16$ 位偏移地址: $-32768\\sim +32767$ Example: 1234.codeJMP 0120H ; 直接转向JMP SHORT LR ; 8 位偏移量JMP NEAR PTR BUF ; 16 位偏移量 JMP reg/mem (段内间接转移) CS 保持不变, reg/mem 中的 $16$ 位偏移地址送到 IP $16$ 位偏移地址指的是段内偏移地址，而不是相对于 IP 的偏移量 123.codeJMP [BX + DI] ; (DS) = 3000H, (BX) = 1300H, (DI) = 1200H, (32500H) = 2350H; (IP) = 2350H JMP segment:offset (段间直接转移) 指令中的 $16$ 位段地址和 $16$ 位偏移地址送到 CS 和 IP (立即数) 123.codeJMP 2000H:1000H; (CS) = 2000H, (IP) = 1000H 注：直接地址为符号地址时，段间直接转移指令中的符号地址前应加操作符 FAR PTR JMP mem$32$ (段间间接转移) mem$32$ 中的 $16$ 位段地址和 $16$ 位偏移地址送到 CS 和 IP (两个相邻字) 1234.codeJMP DWORD PTR[SI] ; 表示转移地址为一个双字; (DS) = 4000H, (SI) = 1212H, (41212H) = 1000H, (41214H) = 4A00H; (IP) = 1000H, (CS) = 4A00H 条件跳转指令 声明全局变量 (变量后面紧跟 “::”) 基于特定 CPU 标志值的跳转指令 助记符 标志位 标志值/跳转条件 JZ ZF(零标志位) 1 JNZ ZF(零标志位) 0 JC CF(进位标志位) 1 JNC CF(进位标志位) 0 JO OF(溢出标志位) 1 JNO OF(溢出标志位) 0 JS SF(符号标志位) 1 JNS SF(符号标志位) 0 JP PF(奇偶标志位) 1 JNP PF(奇偶标志位) 0 依据相等比较的跳转指令 指令格式: CMP LeftOp, RightOp Jxx Label 助记符 跳转条件 JE LeftOp = RightOp JNE LeftOp$\\neq$ RightOp JCXZ CX=0 JECXZ ECX=0 基于无符号整数比较结果的跳转指令 指令格式: CMP LeftOp, RightOp Jxx Label 指令助记: Z:zero, E:equal, A:above, B:below 助记符 跳转条件 JA LeftOp &gt; RightOp JAE LeftOp &gt;= RightOp JB LeftOp &lt; RightOp JBE LeftOp &lt;= RightOp JNA LeftOp &lt;= RightOp JNAE LeftOp &lt;= RightOp JNB LeftOp &gt;= RightOp JNBE LeftOp &gt;= RightOp 基于有符号整数比较结果的跳转指令 指令格式: CMP LeftOp, RightOp Jxx Label 指令助记: Z:zero, E:equal, G:greater, L:less 助记符 跳转条件 JG LeftOp &gt; RightOp JGE LeftOp &gt;= RightOp JL LeftOp &lt; RightOp JLE LeftOp &lt;= RightOp JNG LeftOp &lt;= RightOp JNGE LeftOp &lt;= RightOp JNL LeftOp &gt;= RightOp JNLE LeftOp &gt;= RightOp 123MOV al, statusTEST al, 00100000b ; 测试 bit5=1jnz OK 123MOV al, statusTEST al, 00010011b ; 测试 bit0, bit1, bit4至少一个1jnz OK 1234MOV al, statusAND al, 10001100b ; 取出 bit2, bit3, bit7CMP al, 10001100b ; 测试 bit2, bit3, bit7不全为 1jnz OK 循环指令 LOOP LOOP Label 执行操作: (CX)$-1$ $\\rightarrow$ CX 循环条件: (CX) $\\neq0$ 转至 Label 处循环执行 等价指令: DEC CX, JNZ Label 循环目的地址与当前地址相距范围：$-128\\sim+127$字节，机器指令平均 $3$ 字节, 单词循环平均最多包含约 $42$ 条指令 1234567891011.datacount DW ?.code mov cx, 100L1: mov count, cx mov cx, 20L2: . . loop L2 mov cx, count loop L1 LOOPZ (Loop if zero, Loop if equal) 指令等价：LOOPE 指令格式: LOOPZ Label 执行操作: (CX) $-1\\rightarrow$ CX 循环条件: (CX) $\\neq0 \\wedge$ ZF $=1$ LOOPNZ (Loop if not zero, Loop if not equal) 指令等价：LOOPNE 指令格式: LOOPNZ Label 执行操作: (CX) $-1\\rightarrow$ CX 循环条件: (CX) $\\neq0 \\wedge$ ZF $=0$ 移位和循环移位指令 助记符 指令含义 影响标志位 助记符 指令含义 影响标志位 助记符 指令含义 影响标志位 SHL 逻辑左移 CF,OF,PF,SF,ZF ROL 循环左移 CF,OF SHLD 双精度左移 CF,OF SHR 逻辑右移 CF,OF,PF,SF,ZF ROR 循环右移 CF,OF SHRD 双精度右移 CF,OF SAL 算术左移 CF,OF,PF,SF,ZF RCL 带进位的循环左移 CF,OF SAR 算术右移 CF,OF,PF,SF,ZF RCR 带进位的循环右移 CF,OF 算术移位——把操作数看做是有符号数 逻辑移位——把操作数看做无符号数 $8086$/$8088$: imm8=1, $80286$ 以上: imm8=任意整数 SHL/SAL 指令格式: SHL/SAL mem/reg, imm8/CL 指令功能: 逻辑左移/算术左移 Example 12345SAL al, 1 ; 2xMOV ah, alSAL al, 1 ; 4xSAL al, 1 ; 8xADD al, ah ROL 指令格式: ROL mem/reg, imm8/CL 指令功能: 循环左移 指令特点: 循环左移出的最高位同时给 CF Example 123MOV al, 10000000bROL al, 1 ; 10000000b -&gt; 00000001b, CF = 1ROL al, 1 ; 00000001b -&gt; 00000010b, CF = 0 123MOV al, 26HMOV cl, 4ROL al, cl ; AL=62H ROR 指令格式: ROR mem/reg, imm8/CL 指令功能: 循环右移 指令特点: 循环右移出的最低位同时给 CF Example 123MOV al, 00000001bROR al, 1 ; 00000001b -&gt; 10000000b, CF = 1ROR al, 1 ; 10000000b -&gt; 01000000b, CF = 0 123MOV al, 26HMOV cl, 4ROL al, cl ; AL=62H 12345678.data ArraySize = 3 array DWORD ArraySize DUP(99999999H).code MOV esi, 0 SHR array[esi+8], 1 ; 高位的最低位移进 CF RCR array[esi+4], 1 ; 低位移位必须带 CF RCR array[esi], 1 SHLD 至少是Intel $386$处理器 指令格式: SHLD DEST, SRC, CL/imm8 功能: 将目的操作数左移指定的位数，低位空出来的位用源操作数的高位填充 影响标志: SF, ZF, AF, PF, CF SHRD 至少是Intel $386$处理器 指令格式: SHRD DEST, SRC, CL/imm8 功能: 将目的操作数右移指定的位数，高位空出来的位用源操作数的低位填充 影响标志: SF, ZF, AF, PF, CF 字符串操作指令 寻址方式 源操作数指针 DS:SI 目的操作数指针 ES:DI SI是DS段中的偏移 DI是ES段中的偏移 ES ES通常开始时设为同样的段值 SI DI的值会自动修改（方向标志位DF=0 增；DF=1 减；CLD 清除方向标志位，STD 设置方向标志位） 基本字符串指令 MOVSB(/SW/SD)移动 拷贝DS:(E)SI寻址的内存操作数至ES:(E)DI 例题 CMPSB(/SW/SD)比较 SCASB(/SW/SD)扫描比较内存中由DS:(E)SI寻址和ES:(E)DI寻址的字符串。源﹣目的 例题 SCASB(/SW/SD)扫描 扫描ES:(E)DI指向的内存字符串查找与累加器匹配的值 例题 STOSB(/SW/SD)存储 将累加器内容存储到由ES:(E)DI寻址的内存中 例题 LODSB(/SW/SD)装入 将由DS:(E)SI寻址的内存单元装入累加器中 例题 使用重复前缀 REP 当CX&gt;0时重复 REPZ, REPE 当ZF=1且CX&gt;0时重复 REONZ, REPNE 当ZF=0且CX&gt;0时重复 实现用一条指令处理整个数组 端口、过程与逻辑运算指令 使用I/O端口控制硬件 端口范围：0~FFFFh 端口作用：传送数据，返回状态，控制 指令 IN 累加器，端口地址 累加器：AL\\AX\\EAX 端口地址 0~FFh之间的常量 包含0~FFFFh 之间值的DX寄存器 OUT 端口地址，累加器 例题 过程的定义和使用 PROC伪指令 CALL与RET指令 CALL指令执行时，处理器自动完成压栈；RET指令执行时，处理器自动完成出栈 过程可以嵌套调用 局部标号(L1:)和全局标号(L1::) 例题 逻辑运算指令 设置和清除单个CPU标志 12stc ;设置进位标志clc ;清除进位标志 12and al，0 ;设置零标志or al,1 ;清除零标志 12or al,80h ;设置符号标志and al,7Fh ;清除符号标志 123mov al,7Fh ;AL=+127inc al ;AL=-128, OF=1or eax,0 ;清除溢出标志 程序设计举例 顺序程序 例题 分支程序 例题1 例题2 循环程序 两种结构两种结构循环次数CX的设置会不同 例题 子程序 编写时应注意 如何调用和返回 入口条件和出口条件 寄存器、保护、影响哪些标志位、出错如何处理 参数传递 利用寄存器 利用内存单元 利用堆栈 例题 功能调用 高级功能调用（DOS功能调用） 123MOV AH,功能号对各寄存器调用参数INT 21H 低级功能调用（BIOS功能调用) 123MOV AH,功能类型对各寄存器调用参数INT 中断类型 例题 例1 例2 例3 例4 例5 Examples123456789101112131415TITLE Summing an Array; This program sums an array of 16-bit integers..dataintarray DW 100H, 200H, 300H, 400H.codemain PROC MOV di, OFFSET intarray MOV cx, LENGTHOF intarray MOV ax, 0 ; clear the accumulatorL1: ADD ax, [di] ADD di, TYPE intarray LOOP L1main ENDPEND main 123456789101112131415TITLE Copying a String; This program copies a string..datasource DB &quot;This is the source string.&quot;, 0 ; 字符串末尾加上结束符便于输出，'\\0'的 ASICC 码值为 0target DB SIZEOF source DUP(0), 0.codemain PROC MOV si, 0 MOV cx, SIZEOF sourceL1: MOV al, source[si] MOV target[si], al LOOP L1main ENDPEND main 123456789101112131415161718192021222324252627TITLE Displaying Register Contents; This program displays the contents of the general-purpose registers..codemain PROC MOV bx, 1234H MOV ch, 4 ; 循环计数器ROT: MOV cl, 4 ; 移位计数器 ROL bx, cl ; 循环移位，将高4位移到低4位 MOV al, bl AND al, 0FH ; 取低4位 ADD al, 30H ; 将数字转换为ASCII码 CMP al, 39H JBE DISP ; 如果不大于 9 就显示 ADD al, 7 ; 如果大于 9 则转 A-FDISP: MOV dl, al MOV ah, 2 ; 显示 INT 21H DEC CH ; 计数4个十六进制数 JNZ ROT MOV dl, 48H ; 显示 H MOV ah, 2 INT 21Hmain ENDPEND main 123456789101112131415161718192021222324252627TITLE Scanning an Array for Non-Zero Values; This program scans an array for non-zero values..data intArray SWORD 0, 0, 0, 0, 1, 20, 35 ; single word nonMsg DB &quot;A non-zero value was not found.&quot;, 0.codemain PROC MOV ebx, OFFSET intArray MOV ecx, SIZEOF intArray ; Loop counterL1: CMP WORD PTR[ebx], 0 JNZ Found ; Found a value ADD ebx, 2 Loop L1 JMP NotFoundFound: MOVSX eax, WORD PTR[ebx] call Writeint ; Display the value in EAX JMP QuitNotFound: MOV edx, OFFSET nonMsg call WriteStringQuit: call crlf ; Carriage Return and linefeed exitmain ENDPEND main 123456789101112131415161718192021222324TITLE Scanning an Array; This program scans an array until it finds a positive value..data intArray SWORD -3, -6, -1, 0, 1, 20, 35 ; single word sentinel SWORD 0.codemain PROC MOV esi, OFFSET intArray MOV ecx, LENGTHOF intArray ; Loop counterNext: TEST WORD PTR[esi], 80H ; Testing the highest bit PUSHFD ; Pushing flags on stack ADD esi, TPYE intArray POPFD ; Poping flags from stack LOOPNZ Next ; if not found JNZ Quit ; finished scanning and not zero that is not found SUB esi, TYPE intArray ; moving to the former elementQuit: call crlf ; Carriage Return and linefeed exitmain ENDPEND main 1234567891011121314151617181920212223242526TITLE Compress BCD to ASCII; This program converts a BCD number to ASCII..codemain PROC MOV si, 1000H ; SI &lt;- BCD 首地址 MOV di, 2000H ; DI &lt;- ASCII 首地址 MOV BX, 4 ; 4 个 BCD 码L1: MOV al, [si] ; 取 BCD 码 AND al, 0FH ; 屏蔽高 4 位 OR al, 30H ; 转换为 ASCII STOSB ; 将AL寄存器中的值存储到DI地址指向的内存单元 LODSB ; SI指向的存储单元读入读入AL MOV cl, 4 SHR al, cl ; 逻辑右移 4 位 OR al, 30H ; 得到高 4 位 ASCII 码 STOSB INC si DEC bx JNZ L1 Quit: call crlf ; Carriage Return and linefeed exitmain ENDPEND main 第四章 总线技术第一讲 总线概述 定义: 连接两个以上数字系统元件的公共的信息通路 总线分类 按连接的层次 片内总线：连接CPU内部各功能部件的总线，例如内部的运算器、寄存器等元件级总线：连接CPU、内存以及总线控制逻辑的板内总线系统总线(内总线)：主机内用于连接主板、网卡、显卡等高速功能部件的总线通信总线(外总线)：连接主机与主机、主机与外设之间的总线 按数据传输的位数 I. 并行总线 多条数据线对数据各位进行同时传输 仅适宜计算机内部高速部件近距离传输 有时钟偏移和串扰 II. 串行总线 采用一条数据线逐位传输各位数据 常用于长距离通信及计算机网络，在短距离应用中性能也超过并行总线 无时钟偏移和串扰 内总线 PC机的内总线 ISA总线(Industry Standard Architecture) I. 特点 16位数据总线，支持 8 位、16 位数据操作 地址、数据非多路复用 多主控设备总线 II. 信号定义 数据总线(System Data Bus) 16位 $SD_0$ - $SD_{15}$, 8位 $SD_0$ - $SD_7$ 提速: 同步准备就绪信号 $\\overline{SRDY}$(Synchronous Ready)又零等待状态信号 $\\overline{NOWS}$(No Wait State)，表示无需额外等待即可完成一个总线周期 升位: 片选信号$\\overline{MEMCS16}$(Memory Chip Select 16), $\\overline{IOCS16}$(I/O Chip Select 16)，指示进行16位数据操作 位数可选: 系统高字节允许信号 $\\overline{SBHE}$(System Byte High Enable) 注: 当 $\\overline{SBHE}$ 被主控设备置为低电平，ISA插卡必须及时将 $\\overline{MEMCS16}$ 和 $\\overline{IOCS16}$ 置为有效作为回应(操作16位数据) 地址总线(System Address Bus) 主存地址空间: $SA_0\\sim SA_{19}$ 寻址 $1$MB，配合 $LA_{17}\\sim LA_{23}$ 寻址能力达到16M = $2^{24}$ I/O地址空间: $SA_0\\sim SA_{15}$ 寻址 $64$K，实际寻址 $1$K 未锁定地址信号 $LA_{17}\\sim LA_{23}$(Unlatched Address) 不锁存时: $LA_{17}\\sim LA_{19}$ (不锁存)与 $SA_{17}$ - $SA_{19}$ (锁存)重复 索存时: $LA_{17}\\sim LA_{23}$ 扩展地址总线 中断请求 11个：$IRQ_3$ - $IRQ_7$、$IRQ_9$ - $IRQ_{12}$、$IRQ_{14}$ - $IRQ_{15}$ $IRQ_0$ 定时器，$IRQ_1$ 键盘，$IRQ_2$ 级联，$IRQ_8$ 定时器8254，$IRQ_{13}$ 协处理器 DMA请求 7个 $DRQ_0$ - $DRQ_3$ 、 $DRQ_5$ - $DRQ_7$、 $\\overline{DACK_0}$ - $\\overline{DACK_3}$ 、 $\\overline{DACK_5}$ - $\\overline{DACK_7}$ 优先级：$DRQ_0$ - $DRQ_7$递减 $DRQ_0$ - $DRQ_3$ （8位传输）， $DRQ_5$ - $DRQ_7$（16位传输） 多主控制总线 $\\overline{MASTER}$ 系统控制权信号 速度 CLK PCI总线(Peripheral Component Interconnect Local Bus) I. 特点 不依赖处理器（PCI桥） 扩充性好（多PCI总线结构） 自动配置，即插即用 数据、地址奇偶校验功能 数据宽度32位，可扩展为64位 信号复用，支持无限读写突发操作 适应性广 并行总线操作II. 总线命令 总线命令 命令类型 0000 中断应答 0001 特殊周期 0010 I/O读 0011 I/O写 0100 MEM读 0100 MEM写 0100 读配置 0100 写配置 III. 突发成组数据传输：一个分组= 一个地址节拍 + 一个/多个数据节拍 工控机的内总线 STD总线 外总线 RS232C I. 特点 传输信号线少 传输距离较远 采用不归零编码NRZ和负逻辑 单端通信 传输速率较低 II. 电气特性、引脚功能 DB25和DB9，相同功能针号不同 信号 传送信息信号：TXD RXD（逻辑1电压为负） 联络信号：RTS CTSS DTR DSR DCD RI（逻辑1电压为正） 全双工和半双工 与TTL电平转换 应用 使用modem连接 软硬件系统调试 直接连接 交叉连接方式（全双工） 三线连接方式（软件无需检测CTS、DSR的状态） RS423、RS422 RS423：单端输出、差分接收 RS422：差分输出、差分接收 SCSI 使用逻辑地址而非物理地址寻址数据 特点： 适用范围广 传输速率高 提高了CPU效率，CPU占有率低 支持多任务 智能化 SCSI-1和SCSI-2 通用接口，设备无关 主机适配器 + 外设控制器 ≤ 8 两种工作方式 同步数据传输 异步数据传输（速率低于同步） SCSI总线上的设备无主从之分，任何设备可做启动设备也可做目标设备 驱动方式（三种方式不能共存） 单端 差分 LVD 总线信号 $DB_0$ - $DB_7$,DBP:命令、数据、状态、信息、SCSI-ID REQ 、 ACK：握手信号 C/D I/O SEL MGS ATN BSY RST 工作过程 启动设备选择一个目标设备，发送一条命令 目标设备被选中并接受命令（获得总线控制权），命令传到LUN（物理外设）去执行 目标设备释放总线 USB总线 特点 单一接口类型 127个外设 整个USB系统只用一个端口、一个中断，节省系统资源 热插拔 高速、全速、低速 设备供电 控制传输、同步传输、中断传输、批量传输 构成 硬件 USB主机 USB主集线器 根集线器 USB设备 集线器 功能部件 软件 USB设备驱动程序 USB驱动程序 USB主控制器驱动程序 第二讲 总线的驱动与控制总线竞争 同一总线上，同一时刻，有两个或以上的器件输出状态 防止总线竞争：用三态电路，严格控制逻辑 总线负载 直流负载 驱动器的高电平输出电流应不小于所有负载所需高电平输入电流之和 驱动器的低电平输出电流应不小于所有负载所需低电平输入电流之和 扇出数：驱动同门的个数，用 $I_{OH}$ / $I_{IH}$ 和 $I_{OL}$ / $I_{IL}$，取二者的较小值 交流负载 对MOS电路，主要考虑电容负载 扇出数：输出门的负载电容 $C_p$ / $C_{li}$ 总扇出数：$I_{OH}$ / $I_{IH}$ 、 $I_{OL}$ / $I_{IL}$ 、 $C_p$ / $C_{li}$，三者取最小值（理想情况） 总线驱动设计 克服总线负载效应：用驱动器和缓冲器 扇出能力大 延时可忽略 噪声容限较高 几种常用芯片（防止总线竞争） 单向驱动器（三态输出）（224） 双向驱动器（三态输出）（245） DIR = 0，读；DIR = 1，写 锁存器（三态输出）（373） 总线驱动设计 内存板：20位地址（$\\overline{MEMR}$ 、 $\\overline{MEMW}$），接口板：16位地址（$\\overline{IOR}$ 、 $\\overline{IOW}$） 防止总线竞争的原则：只有当CPU读本电路板内的内存地址/接口地址时，才允许双向驱动器指向系统总线的三态门是导通的 步骤 分析板内内存地址，找出地址特征 设置译码电路，用来控制双向数据总线驱动器，使之满足防止总线竞争的原则 译码方式 基本门电路 译码器（74LS138） 译码ROM 比较器（74LS688） PLA CPLD FPGA 第三讲 总线的工程设计问题 设计总线要考虑 不发生总线竞争 总线负载 总线交叉串扰 总线延时 总线信号的反射 总线交叉串扰 产生原因 总线间的寄生电容 总线本身可看做一个小电感 解决：减少总线间的寄生电容 减少总线长度 增加总线间距离 降低总线上的负载 两条信号线间加一条地线 减少总线的平行走向 总线优化器DS36662 采用双绞线 总线延时 解决方法 减少总线长度 选用延时小、输入输出电容小、驱动能力强的元器件 总线信号的反射 产生原因： 信号沿总线传播到达总线终端时，若总线终端负载阻抗与总线特性阻抗不匹配，信号的一部分会被反射 反射回来的信号到达信号源时，若源的内部阻抗与总线的特性阻抗不匹配，又会有一部分被反射回去 此过程有时需要多次才能在负载上建立所需的波形 危害 反射使波形变坏、延时增加 克服方法 降低传输信号的频率 尽量使 信号源内阻、总线的特性阻抗、负载阻抗 相匹配 总线匹配 末端匹配 源端匹配 限制总线长度 来自作者的忠告 从本章开始，默认读者已经掌握大部分微机原理与接口技术的基础内容，后续着重关注于较难的问题或者不易记忆的模块，此部分基于作者本身的直觉认为应当是计算机技术专业学生必须牢记的；由于作者仍在深入学习，知识储存量不能做到非常全面，所以如果您觉得部分内容有冗余，作者建议您可以选择直接略过。 第五章 存储技术第一讲 概述半导体存储器的基本概念 RAM: SRAM [异步 SRAM, 同步 SRAM], DRAM ROM 可一次编程 ROM: PROM(Programmable ROM); 可擦写的 PROM: [EPROM(Erasable Programmable ROM),E2PROM/EEPROM(Electrically Erasable Programmable ROM)[传统 E2PROM, FLASH]] 三级存储结构: 高速缓冲存储器、主存储器、辅助存储器 第二讲 常用存储器芯片及接口设计 来自作者的忠告 本讲重点关注于常用存储器芯片的特性以及接口设计，在主存接口设计中必须牢记常用存储器芯片特点 SRAM 及接口设计 异步 SRAM: 访存独立于时钟，控制信号不需要时钟同步 典型传统异步性SRAM芯片–6264芯片 数据线: $D0\\sim D7$ (8位存储器) 地址线: $A0\\sim A12\\Longrightarrow 2^{13}\\times 8=8K\\times 8$ (存储容量) 片选信号: $\\overline{CS1}, CS2$ 使能信号: $\\overline{OE}$ (输出使能), $\\overline{WE}$ (写使能) 时序分析 写入时序地址 $\\rightarrow$ 片选 $\\rightarrow$ 数据 $\\rightarrow$ 写信号 $\\rightarrow\\cdots\\rightarrow$ 撤写信号 $\\rightarrow$ 撤其他信号 读出时序地址 $\\rightarrow$ 片选 $\\rightarrow$ 读信号 $\\rightarrow$ 数据有效 $\\rightarrow$ 撤读信号 $\\rightarrow$ 撤其他信号 逻辑分析传送地址、加载片选信号以及加载读写信号顺序保持一定，主要是使得存储器读写信号的充分有效性 译码电路 译码方式 全地址译码: 全部的高位地址信号(除了存储单元地址以及片内地址)作为译码信号，编码存储器芯片的所有存储单元 部分地址译码/部分高位地址: 部分高位地址信号进行译码，存储器芯片占据几组不同的地址范围 译码电路的选择 利用译码芯片(74LS139(2-4译码器), 74LS138(3-8 译码器), 74LS154(4-16 译码器))、门电路 利用数字比较器芯片 74LS688 利用 PROM 译码器 芯片结构 同步 SRAM: 访存依赖于时钟，控制信号需要时钟同步 第三讲 Intel16/32/64 位微机系统的主存设计 8088 系统存储器: 8 位数据总线，单体存储器 8086/186/286 系统: 16 位数据总线，双体存储器 80386/80486 系统: 32 位数据总线，四体存储器 Intel 16位微机系统的主存设计 存储器的字、位扩展 芯片数量计算 存储容量 = (尾地址 - 首地址 + 1)$\\times$ 位宽 芯片数量 = 存储容量/芯片容量 Intel 32位微机系统的主存设计 $M/\\overline{IO}$ $D/\\overline{C}$ $W/\\overline{R}$ 总线周期 0 0 0 中断响应 0 0 1 停机 0 1 0 I/O读 0 1 1 I/O写 1 0 0 取指令操作码 1 0 1 保留 1 1 0 存储器读 1 1 1 存储器写 Intel 64位微机系统的主存设计 体选择信号: $\\overline{BE0}$ ~ $\\overline{BE7}$ 内存由 8 个体构成，每个体对应一个体选择信号 第四讲 只读存储器 (ROM) 及接口设计 外存平均访问时间 ms 级; 内存平均访问时间 ns 级 EPROM–2764芯片 地址总线: $A12\\sim A0$ (8K$\\times$ 8bit) 数据总线: $D7\\sim D0$ 片选信号: $\\overline{CE}$ 输出使能信号: $\\overline{OE}$ PGM: 编程时脉冲输入，读时为 “1” 芯片结构 EEPROM–98C64A芯片 地址总线: $A12\\sim A0$ (8K$\\times$ 8bit 并行) 数据总线: $D7\\sim D0$ 片选信号: $\\overline{CE}$ 输出使能信号: $\\overline{OE}$ 写入使能信号: $\\overline{WE}$ $Ready/\\overline{Busy}$: 漏极开路 芯片结构 EPROM 需要进行擦除 EEPROM 可单字节随机读写 (不需擦除，直接改写数据) 存储密度小，单位成本高 第六章 输入/输出技术第一讲 I/O概述主机和外设I/O 方式 程序控制方式 无条件传送方式 查询方式 不要求CPU效率 外设慢速 中断方式 要求CPU效率 外设中慢速 DMA 外设高速从无条件传送方式到DMA，控制越来越复杂，效率越来越高 I/O 接口 作用 信息传递（利用端口——接口里的寄存器） 注意区分“接口”“端口” 数据格式转换 CPU与外设速度匹配 负载匹配、时序匹配 总线隔离 提供中断、DMA功能 信息传递 编址方式 统一编制 独立编制（有IN OUT） I/O 端口地址译码 全地址译码 部分地址译码 基本的并行输入/输出接口 输入：三态门（防止总线冲突） 输出：锁存器（CPU和外设速度匹配） 第二讲 程序查询 I/O 方式 无条件传送方式（查询方式的特例） 外设时刻处于就绪状态 硬件：数据端口，软件：输入输出指令 查询方式 外设准备就绪之后才能与微机系统进行信息交换 硬件：数据端口、状态端口，软件：不断查询 ；硬件简单，软件开销大 时序 多外设的查询控制 一定要服务优先级高的——用于优先级差别很大的 服务完高优先级的再从头查询——用于优先级有一定差距的 机会均等——用于优先级差别很小的 第三讲 中断方式中断概述 中断源 内部：内中断（软件中断） 外部：外中断（硬件中断） NMI（不可屏蔽） INTR（可屏蔽） 中断过程 中断源发出中断请求 满足中断条件，进行中断响应 断点保护（硬件完成） PSW压栈，关中断，CS压栈，IP压栈 中断判优 硬件判优 软件判优 中断源识别 软件查询 中断矢量法 获得中断服务子程序首地址 固定入口法 中断向量法 中断处理——中断服务子程序 FAR类型，用IRET返回 保护现场 → 开中断STI → 中断处理 → 关中断CLI → 恢复现场 → 中断返回IRET RISC寄存器分页，中断服务程序无需PUSH POP 中断返回 IRET IRET指令使CPU把堆栈内保存的断电信息弹出到IP、CS、FLAG中 中断优先级嵌套 优先级原则 速度快＞速度慢 输入设备＞输出设备 解决办法 软件查询 硬件链式优先级排队电路 硬件优先级编码比较电路 利用可编中断控制器PIC 实现中需注意 中断处理程序：STI开中断指令 堆栈足够大 正确使用堆栈（关中断之后恢复现场） Intel 16位中断系统8086/8088中断系统 中断源类型 中断向量表IVT 存放中断服务程序的入口地址 00000H ~ 003FFH，1KB = 4B/入口 × 256个入口 中断向量在IVT中的存放地址 = 4 × 中断类型号n 4n : IP 4n+2 : CS 中断的响应过程 注意，外部中断INTA有两次 优先级从高到低：内部中断、NMI 、INTR、单步中断 可编程中断控制器（PIC）8259 内部结构 IRR 请求（=1表示有请求） ISR 服务（=1表示正被服务） IMR 屏蔽（=1表示被屏蔽） 中断优先权判别电路 引脚 工作方式 级联 单片8259A可支持8个中断源，多片级联最多支持64个中断源，n片可支持7n+1个中断源（n≤9） $\\overline{\\text{SP}}$ / $\\overline{\\text{EN}}$ :低-从片，高-主片 从片中断结束，中断服务程序需发送两个EOI命令 编程使用 内部寄存器的寻址方法 命令字 中断方式实现方法 8259连接（硬件） 编写初始化程序 8259初始化（初始化命令字） 设置中断向量表 直接写IVT 利用都是功能调用：功能号25H是写IVT 编写中断处理程序 第四讲 直接存取方式DMA工作过程 特点 高速外设，纯硬件控制，外设直接与存储器进行数据交换，无需CPU，传输速率高 内存/外设的地址和读写控制均由DMACA提供 时序 AEN=0 : CPU AEN=1 : DMA 工作过程 外设准备好，向DMA发出DRQ DMA收到请求，向CPU发出HOLD CPU完成当前总线周期且非总线封锁，响应HOLD信号 将数据总线、地址总线、控制信号线置高阻态，放弃总线控制权 向DMA发出HLDA DMA收到HLDA，开始控制总线，向外设发出DACK 外设与内存 或 内存与内存 直接数据传送 DMA自动修改地址和字节计数器，传完后，撤HOLD CPU撤HLDA，下一时钟周期控制总线 DMA控制器8237（DMAC） 特点 4个独立DMA通道，级联扩展为最多16个 引脚及功能 工作时序 Si：空闲状态 S0请求状态 S1 ~ S4传送状态 S1只在A15 ~ A18更新时才执行 可在S3 S4之间插入Sw 正常时序S2、S3、S4 压缩时序S2、S4 8237工作方式 工作方式 空闲周期 工作周期 传输方式 单字节传送（传完一个字节后，DREQ无效，总线控制权还给CPU） 数据块传送 （传完块数据后才释放总线，期间无论DREQ是否有效都传送） 请求传送（猝发传送）（只要DREQ有效或I/O接口的数据缓冲可用，DMA一直传送数据） 连接方式 级联方式 在级联方式下，当第二层8237的请求得到响应时，第一层8237仅向微处理器发出HRQ信号、对第二层的HRQ作出响应DACK而不能输出地址及控制信号，第二层的8237才是真正的主控制器 传送类型：存储器 → 接口，接口 → 存储器，存储器 → 存储器 优先级 固定优先级 循环优先级 传输速率 正常时序（1个DMA总线周期需4个时钟周期） 压缩时序（1个DMA总线周期需2个时钟周期） 内部寄存器 第七章 常用接口器件第一讲 8255: 8位通用可编程并行接口计算机与外设之间通过接口传送数据 无条件输入(三态门: 74LS244) 无条件输出(锁存器: 74LS273) 中断方式，单向输入/输出 中断方式，双向传输(I/O) 端口地址信号 $A_1$ $A_0$ 选择 0 0 A口($PA_0\\sim PA_7$) 0 1 B口($PB_0\\sim PB_7$) 1 0 C口($PC_0\\sim PC_7$) 1 1 控制寄存器 A口、B口的输入和输出具有锁存能力，C口的输出有锁存能力，输入没有锁存能力 A组 B组 $PA_0\\sim PA_7, PC_4\\sim PC_7$ $PB_0\\sim PB_7, PC_0\\sim PC_3$ 控制字 控制字的部分独立性 A口($PA_0\\sim PA_7$)、B口($PB_0\\sim PB_7$)、C口低四位($PC_0\\sim PC_3$)、C口高四位($PC_4\\sim PC_7$)可单独定义 状态字当8255的A口、B口工作在方式1或A口工作在方式2时，通过读C口的状态，可以检测A口和B口的状态 工作方式 工作方式 0(基本输入/输出方式)A口($PA_0\\sim PA_7$)、B口($PB_0\\sim PB_7$)、C口低四位($PC_0\\sim PC_3$)、C口高四位($PC_4\\sim PC_7$)独立定义，均可做为输入或输出接口 工作方式 1(选通输入/输出方式) A、B口均输出 固定 C 口线A 口使用 $PC_3(INTR_A),PC_6(\\overline{ACK_A}),PC_7(\\overline{OBF_A})$, B 口使用 $PC_0(INTR_B),PC_1(\\overline{OBF_B}),PC_2(\\overline{ACK_B})$ $\\overline{OBF}$(Ouput Buffer): (8255端口$\\rightarrow$ 外设) 输出缓冲器满信号，通知外设在规定端口上取数据: $CPU\\overset{data}{\\rightarrow}Buffer\\overset{\\overline{OBF}}{\\rightarrow}Device\\overset{Fetch}{\\rightarrow}Data$ $\\overline{ACK}$: (外设$\\rightarrow$ 8255端口) 外设响应信号：$Device\\overset{Fetch}{\\rightarrow}Data\\rightarrow \\overline{OBF}=1$ $INTR$: (8255端口$\\rightarrow$ CPU) 中断请求信号，$CPU\\overset{data}{\\rightarrow}Buffer\\rightarrow INTR\\rightarrow Newdata$ $INTE$: 中断允许状态，A口由$PC_6$控制，B口由$PC_2$控制 A、B口均输入 固定 C 口线A 口使用 $PC_3(INTR_A),PC_5(IBF_A),PC_4(\\overline{STB_A})$, B 口使用 $PC_0(INTR_B),PC_1(IBF_B),PC_2(\\overline{STB_B})$ $\\overline{STB}$: (外设$\\rightarrow$ 8255端口) 输入选通信号，将外设数据锁存于输入锁存器中 $\\overline{IBF}$: (8255端口$\\rightarrow$ 外设) 输入缓冲器满信号 $INTR$: (8255端口$\\rightarrow$ CPU) 中断请求信号 $INTE$: 中断允许状态，A口由$PC_4$控制，B口由$PC_2$控制 工作方式 2(双向输入/输出方式，仅A口) A口控制线: $PC_0\\sim PC_7$ 芯片结构连接图 初始化程序 8255端口地址：380H$\\sim$383H 方式0——手动设置外设选通信号1234567891011121314151617181920212223242526272829303132333435INIT_8255: MOV DX, 0383H ; 控制寄存器 MOV AL, 10000011B ; 方式选择 OUT DX, AL MOV AL, 00001101B ; C口使得STROBE=1, 初始化控制信号 OUT DX, ALPRINT: MOV AL, BLAK MOV Cl, AL ; 字符串长度 MOV SI, OFFSET DATAGOOD: MOV DX, 0382H ; C口 PWAIT: IN AL, DX ; Test busy signal AND AL, 02H JNZ PWAIT ; Wait until ready MOV AL, [SI] ; load char data MOV DX, 0380H ; A口 OUT DX， AL ; CPU -&gt; A口 MOV DX, 0382H ; C口 MOV AL, 00H OUT DX, AL ; PC6=0 -&gt; STROBE=0 CALL Delay_1us ; A 口 -&gt; 外设 MOV AL, 40H OUT DX, AL ; PC6=1 -&gt; STROBE=1 Restore high level INC SI DEC CL JNZ GOOD RET 方式1——自动握手12345678910111213141516171819202122232425262728INIT_8255: MOV DX, 0383H ; 控制寄存器 MOV AL, 10100000B ; 方式选择 OUT DX, AL MOV AL, 00001101B ; C口 PC6=1 初始无握手信号 OUT DX, ALPOLLPRINT: MOV AL, BLAK MOV Cl, AL ; 字符串长度 MOV SI, OFFSET DATAGOOD: MOV DX, 0382H ; C口PWAIT: IN AL, DX ; Test busy signal AND AL, 80H ; Test PC7 = 1 首先测试 PC7 表示 CPU 已经响应中断 JZ PWAIT ; Wait until ready MOV AL, [SI] ; load char data MOV DX, 0380H ; A口 OUT DX， AL ; CPU -&gt; A口 ; Make a short summary ; A 口自动传送给外设: CPU响应中断 -&gt; data -&gt; A口 -&gt; 有效的OBF -&gt; 选通外设接受数据 ; 外设接受数据 -&gt; 有效 ACK 握手信号 -&gt; OBF 无效 INC SI DEC CL JNZ GOOD RET 第二讲 8253: 可编程定时器端口地址信号 $A_1$ $A_0$ 选择 0 0 计数器0 0 1 计数器1 1 0 计数器2 1 1 控制寄存器 芯片结构 计数方式 8253的计数模式 计数初值寄存器与减一计数器的关系: 计数初值装入初值寄存器，减一计数器每次都加载初值寄存器中的初值，启动计数。这种关系适用于所有计数模式，主要便于循环计数，启动新一轮计数.减一计数器与计数锁存器的关系：CPU发锁存命令，使得减一计数器中的当前计数值会锁存到计数锁存器中, 可用于在计数过程中读取当前计数值. 减1计数器 二进制计数：0000H$\\sim$ FFFFH(65535) 初值0000H为最大计数值，FFFFH为计数最小值 减一运算采用补码加法： FFFFH-1H = FFFFH + 0001H=0000H 0000H-1H = 0000H + 0001H=0001H 0001H-1H = 0001H + 0001H=0010H 方式0：计数结束产生中断 Condition: GATE 高电平，允许计数 OUT: 输出低电平 First CLK: 计数初值 N -&gt; 初值寄存器 N CLKs: 减一计数 N+1 CLKs: 事件计数 方式1：可编程单稳 Condition: GATE 上升沿触发计数 OUT: 输出低电平 N CLKs: 利用 GATE 编程计数 方式2：频率发生器 Condition: GATE 高电平，允许计数 OUT: 周期输出负脉冲 N CLKs: 减到1时送出负脉冲 方式3：方波发生器 Condition: GATE 高电平，对称方波 OUT: 前 N/2 | (N+1)/2 CLKs 高电平，后 N/2 | (N-1)/2 CLKs 低电平 方式4：软件触发选通 Condition: GATE 高电平，允许计数 OUT: 计数结束输出负脉冲 N CLKs: 技术结束下一个 CLK, 送出负脉冲 方式5：硬件触发选通 Condition: GATE 上升沿触发计数 OUT: 计数结束输出负脉冲 N CLKs: 技术结束下一个 CLK, 送出负脉冲 Summary 所有 GATE 上升沿触发计数均在下一个 CLK 启动计数 0为计数最大值，1为计数最小值，计数为减一计数器 从初值寄存器装入新的计数值，除了可编程单稳，频率发生器都需要重新开始计数 所有 GATE 上升沿触发计数(可编程单稳，频率发生器)在新的上升沿到来时，均会重新开始计数 控制字 芯片结构连接图 初始化程序及其应用 利用计数器模式设计电路，输出指定频率的信号 12345678910MOV AL, 36H ; 控制字，计数器0，双字节，方式3，二进制计数OUT 43H, AL ; 送入控制寄存器MOV AL, 0OUT 40H, AL ; 先写低字节OUT 40H, AL ; 后高字节MOV AL, 54H ; 计数器1，低字节，方式2，二进制计数OUT 43H, ALMOV AL, 18OUT 41H, AL 计数模式1：GATE周期信号频率: $F_1$Hz, CLK输入频率: $F_2$Hz，GATE上升沿刷新计数的最大计数值为:$$N = \\frac{F_2}{F_1}$$ 题型分析 仅适用于重点范围的题型分析，是个人觉得出题意义或概率相对较大的一类题目或知识模块; 设定的 Todo List 仅是基于我个人的情况，不提供参考； 第二章 8086/8088 CPU 8086/8088 最小/最大模式下系统总线形成 第三章 8086汇编语言程序设计 常用汇编指令 基本汇编程序编写 基本表达式计算 数据段中数组数据进行排序 第四章 总线与驱动控制 常用数据总线特点(ISA, PCI, USB) 总线驱动控制电路设计与分析 单向驱动器: 74LS224 双向驱动器: 74LS245 数据锁存器: 74LS373 总线驱动与控制参数计算 第五章 存储器设计 SRAM, DRAM, EPROM, EEPROM 特点 数字比较器、PROM 作为译码电路的实现机制 基于 SRAM 芯片的8086/88系统主存电路设计与分析 位扩展+字扩展设计方法(8086系统16位存储设计) 8086系统8位读写以及16位读写 总线驱动设计: 单向驱动与双向驱动 基于 EEPROM 芯片的 IO 接口设计(Busy的处理) 存储器设计中总线驱动器件使能端设计 第六章 输入/输出技术 中断处理响应过程 8259工作方式(状态字) 级联: 特殊全嵌套与一般嵌套 中断结束: 自动EOI, 特殊/指定EOI, 一般/非指定EOI 优先级: 固定优先级, 自动循环优先级, 指定循环优先级 微机原理与系统课程实验 微机原理与系统课程设计 本章节主要是课程设计部分，以《交通信号灯自动控制模拟指示系统设计》为课设项目完成的实验报告。 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 张剑贤. 2023年秋, 微机原理与系统设计, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/236212950.html 微型计算机原理及接口技术(第三版) https://www.xduph.com/Pages/BookDetail.aspx?doi=09a5a856-0f2e-4260-b9c4-17b78c1e7701","link":"/collaboration/Microcomputer/"},{"title":"大学物理之电磁场学","text":"第一章 静电场第一讲 库仑定律库仑定理——（真空静止点电荷）$$F = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q_1q_2}{r^2}\\boldsymbol{r}^0\\tag 1$$ 其中真空介电常数 $\\varepsilon_0 \\approx 8.85\\times10^{-12} C^2N^{-1}m^{-2}$，令 $k=\\frac{1}{4\\pi\\varepsilon_0}$ 则 $k\\approx 9\\times 10^9Nm^2/C^2$，矢量 $\\boldsymbol{r}^0$ 由施力电荷指向受力电荷 第二讲 电场强度$E$2.1 电场强度$$E = \\frac{F}{q_0}=\\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r^2}\\boldsymbol{r}^0\\tag 2$$ 2.2 均匀带电细圆环圆环轴线上一点 $P$ 的电场强度： $$E = \\frac{1}{4\\pi\\varepsilon_0}\\frac{qx}{(R^2+x^2)^\\frac{3}{2}}\\tag 3$$ 其中，$x$ 表示 $P$ 点到圆环中心 $O$ 的距离，$R$ 表示圆环半径，$q$ 表示圆环带电量； 2.3 有限长直线段直线外一点 $P$ 电场强度： $$E_x=\\frac{\\lambda}{4\\pi\\varepsilon_0 a}(cos\\theta_1-cos\\theta_2), E_y=\\frac{\\lambda}{4\\pi\\varepsilon_0 a}(sin\\theta_2-sin\\theta_1)\\tag 4$$ 注：在建立坐标系的情况下，上式均带有方向，其中沿 $y$ 轴正向：$\\theta_1\\rightarrow \\theta_2$，$\\theta$ 为与 $y$ 轴正向夹角；其中，$a$ 表示 $P$ 点到直线的垂直距离； 2.4 均匀带电无限长直线由 $2.4$ 推得：令$\\theta_1=0,\\theta_2=\\pi$ $$E_x = \\frac{\\lambda}{2\\pi\\varepsilon_0 a}, E_y = 0\\tag 5$$ 2.5 均匀带电无限大平面$$E=\\frac{\\sigma}{2\\varepsilon_0} \\tag 6$$ 2.6 无限大均匀带异号电荷平板间$$E=\\frac{\\sigma}{\\varepsilon_0}\\tag 7$$ 其中，$\\sigma$ 表示每个平板的电荷面密度； 2.7 电偶极子电偶极矩：$\\boldsymbol{p}=q\\boldsymbol{l}$中垂线上一点$P$场强： $$E = -\\frac{\\boldsymbol{p}}{4\\pi\\varepsilon_0y^3} (y\\gg l)\\tag 8$$ 共线上一点 $P$ 场强： $$E=\\frac{2\\boldsymbol{p}}{4\\pi\\varepsilon_0x^3}(x\\gg l)\\tag 9$$ 其中 $\\boldsymbol{l}$ 方向由负电荷指向正电荷； 2.8 力偶矩电偶极子在匀强电场中得力偶矩： $\\boldsymbol{F}_+=q\\boldsymbol{E},\\boldsymbol{F}_-=-q\\boldsymbol{E}$ $$M = F_+\\cdot\\frac{1}{2}lsin\\theta+F_-\\cdot\\frac{1}{2}lsin\\theta=qlEsin\\theta\\tag{10} $$ $\\Rightarrow\\boldsymbol{M}=q\\boldsymbol{l}\\times\\boldsymbol{E}=\\boldsymbol{p}\\times\\boldsymbol{E}$ 注：电偶极子在电场的作用下总要使 $\\boldsymbol{p}$ 转向 $\\boldsymbol{E}$ 的方向； 第三讲 电通量 $\\bigstar$高斯定理3.1 电通量$$\\Phi_e=\\oint_S\\boldsymbol{E}\\cdot d\\boldsymbol{S}\\tag{11}$$ 3.2 高斯定理选定高斯面后，电通量： $$\\Phi_e=\\oint_S\\boldsymbol{E}\\cdot d\\boldsymbol{S}=\\frac{1}{\\varepsilon_0}\\sum_{(内)}q_i\\tag{12}$$ 3.3 轴对称性电场无限长均匀带电直线外一点 $P$ 场强： $$\\Phi_e=\\boldsymbol{E}\\oint_侧d\\boldsymbol{S}=2\\pi rEl=\\frac{1}{\\varepsilon_0}\\lambda l\\Rightarrow E = \\frac{\\lambda}{2\\pi\\varepsilon_0r}\\tag{13}$$ 其中，$r$表示 $P$ 距离导线垂直距离； 3.4 球面对称性电场均匀带电球面电场分布： $$\\Phi_e=\\boldsymbol{E}\\oint_S\\boldsymbol{S}=E\\cdot 4\\pi r^2=\\sum_{(内)}q_i=q$$ $$\\Rightarrow E=\\frac{1}{4\\pi \\varepsilon_0}\\frac{q}{r^2}\\boldsymbol{r}^0(r&gt;R)\\tag{14}$$ $$\\Rightarrow E=0(r&lt;R)$$ 3.5 无限大均匀带电平面选定圆柱面作为高斯面： $$\\Phi_e=\\oint_{左端面}\\boldsymbol{E}\\cdot d\\boldsymbol{S}+\\oint_{右端面}\\boldsymbol{E}\\cdot d\\boldsymbol{S}=2ES=\\frac{1}{\\varepsilon_0}\\sigma S\\tag{15}$$ $\\Rightarrow E=\\frac{\\sigma}{2\\varepsilon_0}$ 3.6 均匀带电圆盘$$E = \\frac{\\sigma}{2\\varepsilon_0}(1-\\frac{x}{\\sqrt{R^2+x^2}})\\tag{16}$$ 3.7 均匀带电球体$$E=\\frac{Q}{4\\pi\\varepsilon_0r^2}\\boldsymbol{r_0}(r&gt;R)$$ $$E=\\frac{\\rho}{3\\varepsilon_0}\\boldsymbol{r}(r&lt;R)$$ 第四讲 静电场的环路定理 电势能4.1 电场强度环流$$\\oint\\boldsymbol{E}\\cdot d\\boldsymbol{l}=0\\tag{17}$$ 环路定理表明静电场是无旋有源场； 4.2 电势能选定电势能零参考点，则点 $A$ 处的电势能： $$w_a=A_{a’0’}=\\int_a^{‘0’}q_0\\boldsymbol{E}\\cdot d\\boldsymbol{l}\\tag{18}$$ 注：电势能是标量，相对于电势能零参考点有负值； 第五讲 电势 电势差5.1 电势与电势差$A$点电势： $$u_a=\\frac{W_a}{q_0}=\\int_a^{‘0’}\\boldsymbol{E}\\cdot d\\boldsymbol{l}\\tag{19}$$ 注：电势为标量； $$U_{ab}=u_a-u_b=\\int_a^b\\boldsymbol{E}\\cdot d\\boldsymbol{l}\\tag{20}$$ 电荷$q$$a\\rightarrow b$时，静电力做功： $$A_{ab}=q(u_a-u_b)\\tag{21}$$ 5.2 电偶极子电势能在电场 $\\boldsymbol{E}$ 中： $$W=-\\boldsymbol{p}\\cdot\\boldsymbol{E}\\tag{22}$$ 当$\\boldsymbol{E}$为非均匀电场时，上式应改为积分形式；在电场中做功： 方法一 $$W_{\\theta_1\\theta_2}=-\\boldsymbol{p}\\cdot\\boldsymbol{E}(\\theta_1)-(-\\boldsymbol{p}\\cdot\\boldsymbol{E}(\\theta_2))$$ 方法二 $$W_{\\theta_1\\theta_2}=\\int_{\\theta_1}^{\\theta_2}-\\boldsymbol{p}\\times\\boldsymbol{E}d\\theta$$ 5.3 电势叠加原理对于点电荷选取无穷远处作为零电势点： $$u_a=\\int_a^{\\infty}\\boldsymbol{E}\\cdot d\\boldsymbol{l}=\\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r}\\W_a = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q^2}{r}\\tag{23}$$ 叠加原理——标量叠加 $$u_a=\\sum u_i\\\\Rightarrow u_a=\\int_Q\\frac{1}{4\\pi\\varepsilon_0}\\frac{dq}{r}\\tag{24}$$ 5.4 电荷分布求电势积分形式： $$u_a=\\int_Q\\frac{1}{4\\pi\\varepsilon_0}\\frac{dq}{r}\\tag{25}$$ 电偶极子外任一点$C$的电势： $$U_C = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r_+}-\\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r_-}=\\frac{q}{4\\pi\\varepsilon_0}\\frac{r_–r_+}{r_-r_+}$$ $$r\\gg l\\Rightarrow r_+r_-\\approx r^2,r_–r_+\\approx lcos\\theta\\tag{26}$$ $$\\Rightarrow u_C = \\frac{1}{4\\pi\\varepsilon_0}\\frac{\\boldsymbol{p}\\cdot\\boldsymbol{r}}{r^3}$$ 5.5 电场强度求电势场强与电势关系： $$u_a=\\int_a^{\\infty}\\boldsymbol{E}\\cdot d\\boldsymbol{l}\\tag{27}$$ 带电体电荷分布具有对称性时，利用高斯定理求出场强分布进而求电势；【无限长均匀带电圆柱面】由高斯定理求得电场分布： $E = 0 (r\\leq R)$ $E=\\frac{\\lambda}{2\\pi\\varepsilon_0r}(r>R)$ 一般而言，当电荷分布延伸到无穷远时，是不能选取无穷远处为电势零参考点的； $$u_P=\\int_P^{P_0}\\boldsymbol{E}\\cdot d\\boldsymbol{l}=\\int_P^{P’}\\boldsymbol{E}\\cdot d\\boldsymbol{l}+\\int_{P’}^{P_0}\\boldsymbol{E}\\cdot d\\boldsymbol{l}$$ $$=0+\\int_r^{r_0}\\frac{\\lambda}{2\\pi\\varepsilon_0r}dr=-\\frac{\\lambda}{2\\pi\\varepsilon_0}\\ln r+\\frac{\\lambda}{2\\pi\\varepsilon_0}\\ln r_0\\tag{29}$$ $$=-\\frac{\\lambda}{2\\pi\\varepsilon_0}\\ln r+C(r&gt;R)$$ $$u_P=\\int_P^{P_0}\\boldsymbol{E}\\cdot d\\boldsymbol{l}=\\int_r^R\\boldsymbol{E}\\cdot d\\boldsymbol{l}+\\int_R^{r_0}\\boldsymbol{E}\\cdot d\\boldsymbol{l}$$ $$=0+\\int_R^{r_0}\\frac{\\lambda}{2\\pi\\varepsilon_0r}dr\\tag{30}$$ $$=-\\frac{\\lambda}{2\\pi\\varepsilon_0}\\ln R + C(r&lt;R)$$ 其中，$C=\\frac{\\lambda}{2\\pi\\varepsilon_0}\\ln r_0$ 5.6 均匀带电球面电势$V(r) = \\frac{1}{4\\pi\\varepsilon_0} \\frac{q}{R}(r \\leq R)$ $V(r) = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r}(r>R)$ 5.7 均匀带电球体电势球内距离球心$r$处一点$P$电势： $$u = u_1+u_2=\\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{R^3}r^2+\\int_r^R\\frac{1}{4\\pi\\varepsilon_0}\\frac{dq_2}{r’}$$ $$=\\frac{1}{4\\pi\\varepsilon_0}\\frac{Q}{R^3}r^2+\\int_r^R\\frac{3Qr’}{4\\pi\\varepsilon_0R^3}dr’\\tag{32}$$ $$=\\frac{Q(3R^2-r^2)}{8\\pi\\varepsilon_0R^3}(r&lt;R)$$ 球外距离球心 $r$ 处一点 $P$ 电势： $$u = \\frac{Q}{4\\pi\\varepsilon_0r}(r\\ge R)\\tag{33}$$ 注：在 $P$ 点的电场强度犹如电荷集中在球心处的点电荷在 $P$ 点产生的电场强度一样，故电势同理； 第六讲 电势与场强微分关系$$E = -\\frac{du}{dn}, E_l=-\\frac{du}{dl}$$ $$\\boldsymbol{E}=-(\\frac{\\partial u}{\\partial x}\\boldsymbol{i}+\\frac{\\partial u}{\\partial y}\\boldsymbol{j}+\\frac{\\partial u}{\\partial z}\\boldsymbol{k}), u(x,y,z)\\Rightarrow E(x,y,z)\\tag{34}$$ 第七讲 静电场中的导体 电容7.1 静电平衡导体表面电场强度： $$\\boldsymbol{E}=\\frac{\\sigma}{\\varepsilon_0}\\boldsymbol{n}\\tag{35}$$ 区别于无限大带电平面产生的电场(缺少静电平衡的条件)： $$\\boldsymbol{E}=\\frac{\\sigma}{2\\varepsilon_0}\\boldsymbol{n}\\tag{36}$$ 7.2 孤立导体电容$$C = \\frac{q}{u}\\tag{37}$$ 7.3 平行板电容器电容$$C = \\frac{q}{u_1-u_2}\\=\\frac{q}{Ed}=\\frac{q}{\\frac{\\sigma}{\\varepsilon_0}d}\\=\\frac{q}{\\frac{qd}{\\varepsilon_0S}}=\\frac{\\varepsilon_0S}{d}\\tag{38}$$ 7.4 球形电容器电容两球面间电场强度： $$E=\\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r^2}\\tag{39}$$ $$u_1-u_2=\\int_{R_1}^{R_2}\\boldsymbol{E}\\cdot d\\boldsymbol{l} = \\int_{R_1}^{R_2}\\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r^2}dr$$ $$=\\frac{q}{4\\pi\\varepsilon_0}\\frac{R_2-R_1}{R_1R_2}\\tag{40}$$ $$\\Rightarrow C = \\frac{q}{u_1-u_2}=\\frac{4\\pi\\varepsilon_0R_1R_2}{R_2-R_1}$$ 7.5 电容器串并联 串联 $$\\frac{1}{C}=\\frac{1}{C_1}+\\frac{1}{C_2}+\\cdot\\cdot\\cdot+\\frac{1}{C_n}$$ 并联 $$C = C_1+C_2+\\cdot\\cdot\\cdot+C_n\\tag{41}$$ 第八讲 静电能8.1 静电能公式推导$$U(t) = \\frac{q(t)}{C}, dA = U(t)dq = \\frac{q(t)}{C}dq$$ $$A = \\int dA = \\int_0^Q\\frac{q(t)}{C}dq=\\frac{Q^2}{2C}Q=CU\\tag{42}$$ $$\\Longrightarrow A = \\frac{1}{2}CU^2=\\frac{1}{2}QU\\Rightarrow W=A=\\frac{Q^2}{2C}=\\frac{1}{2}CU^2=\\frac{1}{2}QU$$ 8.2 电场能量密度推导$$U=Ed, C = \\frac{\\varepsilon_0S}{d}$$ $$\\Rightarrow W = \\frac{1}{2}\\varepsilon_0E^2Sd = \\frac{1}{2}\\varepsilon_0E^2V\\tag{43}$$ $$\\Rightarrow \\omega = \\frac{W}{V}=\\frac{1}{2}\\varepsilon_0E^2$$ 第九讲 电介质的极化 束缚电荷9.1 电介质$$C = \\varepsilon_r C_0\\tag{44}$$ 其中，$\\varepsilon_r$ 称为介质的相对介电常数（相对电容率），$C_0$ 表示真空中对应的电容；因此，除真空中 $\\varepsilon_r=1$ 外，其余 $\\varepsilon_r&gt;1$； 9.2 介质极化 有极分子 $\\Rightarrow$ 取向极化无极分子 $\\Rightarrow$ 位移极化 第十讲 电介质内的电场强度根据电介质极化原理推导： $$\\boldsymbol{E} = \\boldsymbol{E}_0+\\boldsymbol{E}’,\\ E_0=\\frac{\\sigma_0}{\\varepsilon_0},E’=\\frac{\\sigma’}{\\varepsilon_0}$$ $$\\Rightarrow E = \\frac{\\sigma_0}{\\varepsilon_0}-\\frac{\\sigma’}{\\varepsilon_0},\\ E = \\frac{E_0}{\\varepsilon_r}\\tag{45}$$ $$\\Rightarrow \\sigma’=(1-\\frac{1}{\\varepsilon_r})\\sigma_0$$ 第十一讲 $\\bigstar$电介质中的高斯定理11.1 电位移矢量推导： $$\\iint_S\\boldsymbol{E}\\cdot d\\boldsymbol{S}=\\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma’)S$$ 由式(45)得: $$\\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma’)=\\frac{\\sigma_0}{\\varepsilon_0\\varepsilon_r}$$ $$\\iint_S\\varepsilon_0\\varepsilon_r\\boldsymbol{E}\\cdot d\\boldsymbol{S}=\\varepsilon_0S=q_0$$ 令 $\\boldsymbol{D} = \\varepsilon\\boldsymbol{E} = \\varepsilon_0\\varepsilon_r\\boldsymbol{E}$ 得: $$\\iint_S\\boldsymbol{D}\\cdot d\\boldsymbol{S} = q_0\\tag{46}$$ 其中，$D$ 称为电位移矢量或电通密度，$\\varepsilon = \\varepsilon_0\\varepsilon_r$ 称为电介质的介电常数； 11.2 电介质中的能量密度$$\\omega = \\frac{1}{2}\\boldsymbol{D}\\cdot\\boldsymbol{E}\\\\varepsilon_r = 1\\Rightarrow \\omega = \\frac{1}{2}\\varepsilon_0E^2\\tag{47}$$ 第十二讲 经典习题 第二章 恒定电流的磁场第一讲 磁感应强度$B$电流元 $Idl$ 所受磁场力： $$d\\boldsymbol{F} = Id\\boldsymbol{l}\\times\\boldsymbol{B}\\tag{1}$$ 第二讲 毕奥-萨伐尔定律2.1 电流元的磁场$$d\\boldsymbol{B} = \\frac{\\mu_0}{4\\pi}\\frac{Id\\boldsymbol{l}\\times\\boldsymbol{r}^0}{r^2}\\tag{2}$$ 其中，$\\mu_0=4\\pi\\times10^{-7}N/A^2$称为真空磁导率，$\\boldsymbol{r}_0$ 表示到 $P$ 点的单位矢量，$r$ 表示到 $P$ 点的距离； 2.2 运动电荷的磁场$$\\boldsymbol{B} = \\frac{d\\boldsymbol{B}}{dN}=\\frac{\\mu_0}{4\\pi}\\frac{q\\boldsymbol{v}\\times\\boldsymbol{r}^0}{r^2}\\tag{3}$$ 2.3 载流直导线的磁场$$dB = \\frac{\\mu_0}{4\\pi}\\frac{Idlsin\\theta}{r^2}$$ $$\\Rightarrow B = \\frac{\\mu_0I}{4\\pi r}\\int_{\\theta_1}^{\\theta_2}sin\\theta d\\theta=\\frac{\\mu_0I}{4\\pi r}(cos\\theta_1-cos\\theta_2)\\tag{4}$$ $$\\theta_1\\approx 0,\\theta_2\\approx\\pi\\Rightarrow B = \\frac{\\mu_0I}{2\\pi r}$$ 式中，$r$ 表示到载流导线的距离； 2.4 载流圆环的磁场$$B = \\int dB_x = \\int dBcos\\theta = \\frac{\\mu_0}{4\\pi}\\int \\frac{Idl}{r^2}cos\\theta$$ $$cos\\theta = \\frac{R}{r}=\\frac{R}{(R^2+x^2)^{1/2}}\\tag{5}$$ $$\\Rightarrow B = \\frac{\\mu_0IR^2}{2(R^2+x^2)^{3/2}}$$ 【$N$匝线圈】 $$B = \\frac{\\mu_0IR^2N}{2(R^2+x^2)^{3/2}}\\tag{6}$$ 【圆弧磁场】由式 (5) 令 $x=0$ 得圆心处磁感应强度: $B = \\frac{\\mu_0I}{2R}$ $$B = \\frac{\\mu_0I}{2R}\\cdot\\frac{\\varphi}{2\\pi}=\\frac{\\mu_0I\\varphi}{4\\pi R}\\tag{7}$$ 2.5 载流线圈的磁矩由式 (5) 令 $x\\gg R$ 则得: $(x^2+R^2)\\approx x^2$ $$\\Rightarrow B\\approx \\frac{\\mu_0IR^2}{2x^3} = \\frac{\\mu_0I\\pi R^2}{2\\pi x^3}=\\frac{\\mu_0 IS}{2\\pi x^3}$$ $$\\Rightarrow Define:\\ \\ \\ \\ \\boldsymbol{p}_m = IS\\boldsymbol{n}\\tag{8}$$ $$\\boldsymbol{B} = \\frac{\\mu_0}{2\\pi}\\frac{\\boldsymbol{p}_m}{x^3}$$ 其中，$\\boldsymbol{n}$表示线圈平面正法线方向上的单位矢量；圆心处的磁感应强度： $$\\boldsymbol{B} = \\frac{\\mu_0}{2\\pi}\\frac{\\boldsymbol{p}_m}{R^3}\\tag{9}$$ 2.6 无限大均匀载流平面$$dB = \\frac{\\mu_0\\alpha dx}{2\\pi\\sqrt{r^2+x^2}}$$ 由对称性得：$B_x = \\int dB_x, \\ \\ \\ B_y = \\int dB_y = 0$ $$B = B_x = \\int \\frac{r}{\\sqrt{r^2+x^2}}\\cdot \\frac{\\mu_0 \\alpha dx}{2\\pi\\sqrt{r^2+x^2}} =\\int \\frac{\\mu_0 \\alpha r dx}{2\\pi (r^2+x^2)}$$ $$=\\frac{\\mu_0 \\alpha r}{2\\pi}\\int_{-\\infty}^{+\\infty}\\frac{1}{r^2+x^2}dx=\\frac{\\mu_0 \\alpha}{2}\\tag{10}$$ $$\\Longrightarrow B = \\frac{1}{2}\\mu_0\\alpha$$ 式中，$r$ 表示$P$点距到无限大载流平面的距离，$\\alpha$ 表示流过单位长度的电流； 2.7 均匀密绕直螺线管$$dB = \\frac{\\mu_0R^2dI’}{2(R^2+l^2)^{3/2}} = \\frac{\\mu_0R^2Indl}{2(R^2+l^2)^{3/2}}$$ $$l = Rcot\\beta\\ ,\\ \\ \\ dl = -Rcsc^2\\beta d\\beta\\ , \\ \\ \\ R^2+l^2 = R^2csc^2\\beta$$ $$\\Rightarrow dB= -\\frac{\\mu_0}{2}nIsin\\beta d\\beta\\tag{11}$$ $$\\Rightarrow B =\\int_{\\beta_1}^{\\beta_2}-\\frac{\\mu_0}{2}nIsin\\beta d\\beta = \\frac{\\mu_0nI}{2}(cos\\beta_2-cos\\beta_1)$$ 【无限长】 $$L\\gg R,\\ \\ \\beta_1\\rightarrow\\pi, \\ \\ \\beta_2\\rightarrow 0 \\Rightarrow B = \\mu_0nI\\tag{12}$$ 【半无限长】端点处： $$\\beta_1 = \\frac{\\pi}{2}, \\ \\ \\beta_2\\rightarrow 0\\ , or \\ \\ \\beta_1\\rightarrow \\pi, \\ \\ \\beta_2=\\frac{\\pi}{2}\\Rightarrow B = \\frac{\\mu_0nI}{2}\\tag{13}$$ 式中，$n$ 表示单位长度上的线圈匝数； 2.8 均匀密绕圆环螺线管$$B = n\\mu I$$ 第三讲 磁通量 磁场的高斯定理3.1 磁通量$$\\Phi_m = \\int_S \\boldsymbol{B}\\cdot d\\boldsymbol{S}\\tag{14}$$ 3.2 高斯定理$$\\oint_S \\boldsymbol{B}\\cdot d\\boldsymbol{S}=0\\tag{15}$$ 第四讲 $\\bigstar$安培环路定理$$\\oint_L\\boldsymbol{B}\\cdot d\\boldsymbol{l}=\\mu_0\\sum_{(内)}I_i\\tag{16}$$ 式中，$I_i$ 的正（负）取决于电流方向与闭合路径 $L$ 绕行方向满足（不满足）右螺旋法则；$B$ 表示闭合路径 $L$ 内外所有电流产生的总磁感应强度；【无限大载流平面】 $$\\oint_L\\boldsymbol{B}\\cdot d\\boldsymbol{l} = \\int_{PQ}\\boldsymbol{B}\\cdot d\\boldsymbol{l}+\\int_{QR}\\boldsymbol{B}\\cdot d\\boldsymbol{l}+\\int_{RS}\\boldsymbol{B}\\cdot d\\boldsymbol{l}+\\int_{SP}\\boldsymbol{B}\\cdot d\\boldsymbol{l}$$ $$=Bx+0+Bx+0 = 2Bx = \\mu_0 \\alpha x\\tag{17}$$ $$\\Rightarrow B = \\frac{1}{2}\\mu_0\\alpha$$ 第五讲 磁场对电流作用5.1 载流导线所受安培力： $$\\boldsymbol{F} = \\int_LId\\boldsymbol{l}\\times\\boldsymbol{B}\\tag{18}$$ 5.2 载流线圈所受磁力矩： $$M = F_{ab}l_1sin\\varphi=BIl_1l_2sin\\varphi=BISsin\\varphi$$ $$\\boldsymbol{p}_m = IS\\boldsymbol{n}\\tag{19}$$ $$\\Rightarrow \\boldsymbol{M}=\\boldsymbol{p}_m\\times\\boldsymbol{B}$$ 式中，$\\boldsymbol{n}$ 的方向按电流方向用右螺旋法则确定； 5.3 磁力的功$$A = F\\overline{aa’} = BIl\\overline{aa’}=BI\\vartriangle S = I\\vartriangle\\Phi$$ $$\\Rightarrow A = \\int_{\\Phi_1}^{\\Phi_2}Id\\Phi = I(\\Phi_2-\\Phi_1)=I\\vartriangle\\Phi\\tag{20}$$ 5.4 磁偶极子势能载流线圈相当于磁偶极子，因此载流线圈同理；当 $\\varphi = \\frac{\\pi}{2}$ 时, $W = 0$ (零势能点) $$W = -A = -\\int_\\varphi^{\\pi/2}Md\\varphi = -p_mB\\int_\\varphi^{\\pi/2}sin\\varphi d\\varphi = -p_mBcos\\varphi$$ $$\\Rightarrow W = -\\boldsymbol{p}_m\\cdot \\boldsymbol{B}\\tag{21}$$ 第六讲 带电粒子在电场和磁场中的运动6.1 洛伦兹力$$\\boldsymbol{F} = q\\boldsymbol{v}\\times\\boldsymbol{B}\\tag{22}$$ 式中，$q$ 包含电荷正负特性符号； 6.2 霍尔效应$$q\\overline{v}B=qE\\Rightarrow E = \\overline{v}B\\Rightarrow U = El = vBl$$ $$I = nqS\\overline{v}\\Rightarrow U = \\frac{IB}{nqd} = K\\frac{IB}{d}\\tag{23}$$ $$K = \\frac{1}{nq}$$ 式中，$d$ 和 $l$ 分别表示沿电流方向上导体截面的宽度和高度；$n$ 表示单位体积的载流子数；【载流子种类】 p(positive)型半导体 $\\Rightarrow$ 空穴 $\\Rightarrow$ 空穴导电n(negative)型半导体 $\\Rightarrow$ 电子 $\\Rightarrow$ 电子导电金属导体(大多数) $\\Rightarrow$ 电子 $\\Rightarrow$ 电子导电 第七讲 磁介质7.1 相对磁导率$$\\mu_r = \\frac{B}{B_0}\\tag{24}$$ 式中，$B_0$ 表示真空磁感应强度，$\\mu_r$ 表示磁介质的相对磁导率，$B$ 表示磁介质的磁感应强度； $\\mu_r &gt; 1\\Rightarrow$ 顺磁质(弱/非磁性物质)$\\mu_r&lt;1\\Rightarrow$ 抗磁质(弱/非磁性物质)$\\mu_r\\gg 1 \\Rightarrow$ 铁磁质(强磁性物质) 7.2 $\\bigstar$ 磁介质的安培环路定理$$\\oint_L\\boldsymbol{B}\\cdot d\\boldsymbol{l} = \\mu_0\\mu_r\\sum_{(内)}I$$ 令 $\\mu = \\mu_0\\mu_r$ 得: $$\\oint_L \\frac{\\boldsymbol{B}}{\\mu}\\cdot d\\boldsymbol{l}=\\sum_{(内)}I$$ 令 $\\boldsymbol{H} = \\frac{\\boldsymbol{B}}{\\mu}$ 得: $$\\oint_L\\boldsymbol{H}\\cdot d\\boldsymbol{l}=\\sum_{(内)}I\\tag{25}$$ 式中，$\\mu$ 表示磁介质的磁导率，$\\boldsymbol{H}$ 表示磁场强度，对有介质存在的环路定理的处理可以参考电位移矢量 $\\boldsymbol{D}$； 第八讲 经典习题 第三章 电磁感应与电磁场第一讲 电磁感应的基本规律1.1 电动势闭合回路上： $$\\xi = \\oint\\boldsymbol{E}_k\\cdot d\\boldsymbol{l}\\tag{1}$$ 对于一段电路$ab$： $$\\xi = \\int_a^b\\boldsymbol{E}_k\\cdot d\\boldsymbol{l}\\tag{2}$$ 其中，$\\boldsymbol{E}_k$表示非静电性电场强度； 1.2 法拉第电磁感应定律$$\\xi_i=-\\frac{d\\Phi}{dt}\\tag{3}$$ 由楞次定律确定方向$\\Rightarrow$方向相反； 1.3 多匝串联线圈$$\\xi_i=-\\frac{d}{dt}(\\sum_{k=1}^N\\Phi_k)=-\\frac{d\\Psi}{dt}\\tag{4}$$ $$\\xi_i=-\\frac{d\\Psi}{dt}=-N\\frac{d\\Phi}{dt}(\\Phi_i=\\Phi_j, 1 \\leq i,j \\leq N)\\tag{5}$$ 其中，$\\Psi=\\sum_{k=1}^N\\Phi_k$表示穿过各线圈的总磁通量，称为磁通链数； 1.4 长直螺线管在长直螺线管外套一 $N$ 匝，总内阻为 $R$ 的圆线圈，$S$ 表示螺线管截面积： $$B=\\mu_0nI\\Rightarrow \\Phi = \\boldsymbol{B}\\cdot\\boldsymbol{S}=\\mu_0nIS$$ 当通电电流均匀变化时，螺线管内的感应电动势: $$\\xi_i=-\\frac{d\\Psi}{dt}=-N\\frac{d\\Phi}{dt}=-\\mu_0nNS\\frac{dI}{dt}$$ 【螺线管内磁感应强度】感应电流 $I_i=\\frac{\\xi_i}{R}=-\\frac{N}{R}\\frac{d\\Phi}{dt}$ $$\\Delta_{q_i}=\\int_{t_1}^{t_2}I_idt=-\\frac{N}{R}\\int_{\\Phi_1}^{\\Phi_2}d\\Phi=-\\frac{N}{R}(\\Phi_2-\\Phi_1)$$ $$\\Longrightarrow \\Phi_1-\\Phi_2=\\frac{\\Delta_{q_i}R}{N}$$ 当 $\\Phi_1=0\\vert_{t=t_1},\\Phi_2=BS\\vert_{t=t_2\\rightarrow+\\infty}$ 时，推出 $B=\\frac{\\Delta_{q_i}R}{NS}$ 第二讲 动生电动势 感生电动势2.1 动生电动势导体棒 $ab$ 产生的动生电动势： $$\\xi_i=\\int_a^b\\boldsymbol{E}_k\\cdot d\\boldsymbol{l}=\\int_a^b(\\boldsymbol{v}\\times\\boldsymbol{B})\\cdot d\\boldsymbol{l}\\tag{6}$$ 闭合回路产生的动生电动势： $$\\xi_i=\\oint_Ld\\xi_i=\\oint_L(\\boldsymbol{v}\\times\\boldsymbol{B})\\cdot d\\boldsymbol{l}\\tag{7}$$ 动生电动势方向由 $\\boldsymbol{v}\\times\\boldsymbol{B}\\cdot d\\boldsymbol{l}$ 判定： $\\xi_i>0\\Rightarrow u_a\\leq u_b$ $\\xi_iu_b$ 注：积分路径：$a\\rightarrow b$，在电源内部非静电性电场强度从负极指向正极， $\\boldsymbol{E}_k$ 与积分方向一致时积分值为正，否则为负； 2.2 感生电动势 感生电场假说$\\Longrightarrow$ 有旋电场 【回路固定不动】 $$\\xi_i=\\oint_L\\boldsymbol{E}_V\\cdot d\\boldsymbol{l}=-\\iint_S\\frac{\\partial \\boldsymbol{B}}{\\partial t}\\cdot d\\boldsymbol{S}\\tag{9}$$ 感生电动势方向由楞次定律判定；有旋电场度 $E_V$ 的方向判定：闭合回路由右螺旋法则指向磁场方向选定回路绕行正方向，由式 $(9)$ 代入符号计算，$E_V$ 正负与回路绕行方向保持一致；当 $E_V$ 相等，磁场均匀变化时， $$\\xi_i=E_V\\oint_Ldl=-\\frac{\\partial{B}}{\\partial{t}}\\iint_SdS=-\\frac{\\partial{B}}{\\partial{t}}S\\tag{10}$$ $\\Longrightarrow$ 计算某一闭合回路上的有旋电场强度($S$ 表示磁场面积) 第三讲 自感与互感3.1 自感电动势$$\\Psi=LI\\Rightarrow \\xi_L=-\\frac{d\\Psi}{dt}=-L\\frac{dI}{dt}\\tag{11}$$ 式中 $L$ 表示自感系数为常量，与 $I$ 无关(存在铁磁质时与 $I$ 有关)，仅有回路的匝数、几何形状、大小以及周围介质磁导率决定； 3.2 长直螺线管自感系数【空心自感线圈】 $$B = \\mu_0nI=\\mu_0\\frac{N}{l}I\\Rightarrow \\Psi=NBS=\\mu_0\\frac{N^2}{l}\\pi R^2I$$ $$\\Longrightarrow L=\\frac{\\Psi}{I}=\\frac{\\mu_0N^2\\pi R^2}{l}=\\mu_0n^2V\\ (V=\\pi R^2l)\\tag{12}$$ 3.3 传输线的分布电感两长直平行导线电流 $I$，半径 $r_0$，轴线间距 $d$，且 $r_0\\leq d$；导线微元: $d\\Phi_1=BdS=\\frac{\\mu_0I}{2\\pi r}ldr$ $$\\Rightarrow \\Phi_1=\\int_{r_0}^{d-r_0}\\frac{\\mu_0Il}{2\\pi}\\frac{dr}{r}=\\frac{\\mu_0Il}{2\\pi}\\ln(\\frac{d-r_0}{r_0})$$ $\\Phi=\\Phi_1+\\Phi_2=2\\Phi_1$(电流反向) $\\Phi=\\Phi_1+\\Phi_2=0$(电流同向) $$ L=\\frac{\\Phi}{I}=\\frac{\\mu_0}{\\pi}l\\ln(\\frac{d-r_0}{r_0})\\approx \\frac{\\mu_0}{\\pi}l\\ln\\frac{d}{r_0}\\tag{13} $$ 3.4 互感电动势 回路 $1$ 对回路 $2$: $\\Psi_{21}=M_{21}I_1$ 回路 $2$ 对回路 $1$: $\\Psi_{12}=M_{12}I_2$ $$M_{21}=M_{12}=M\\Longrightarrow \\xi_M=-M\\frac{dI}{dt}\\tag{14}$$ 式中 $M_{21}$ 表示回路 $1$ 对回路 $2$ 的互感系数，$M_{12}$ 表示回路 $2$ 对回路 $1$ 的互感系数；$M$ 表示两个回路间的互感系数，与 $I$ 无关(存在铁磁质时与 $I$ 有关)，由回路的匝数、几何形状、尺寸、周围介质磁导率以及回路的相对位置决定； $M_{12}=M_{21}=M\\Rightarrow$ 转换研究对象简化计算互感系数$\\Rightarrow$ 互感电动势 第四讲 磁能4.1 自感磁能$$dA=-\\xi_Lidt,\\ \\xi_L=-L\\frac{di}{dt}$$ $$\\Longrightarrow dA=Lidi$$ $$\\Longrightarrow A=\\int_0^ILidi=\\frac{1}{2}LI^2\\tag{15}$$ 即$W_m=\\frac{1}{2}LI^2$ (自感磁能) 当有磁场能量时可以利用$L=\\frac{2W_m}{I^2}$ 计算自感系数 式中，$L$ 表示线圈自感，$I$ 表示线圈所通电流； 4.2 长直螺线管磁能$$由式(12)\\Rightarrow L=\\mu n^2V\\Rightarrow W_m=\\frac{1}{2}LI^2=\\frac{1}{2}\\mu n^2I^2V$$ $$B=\\mu nI\\Longrightarrow H=\\frac{B}{\\mu}=nI\\tag{16}$$ $W_m=\\frac{1}{2}BHV$ 磁能密度$\\omega_m=\\frac{W_m}{V}=\\frac{1}{2}BH=\\frac{1}{2}\\frac{B^2}{\\mu_0\\mu_r}$ 4.3 有限体积内的磁能$$W_m=\\int_VdW_m=\\frac{1}{2}\\int_VBHdV\\tag{17}$$ 第五讲 麦克斯韦电磁场理论5.1 位移电流 传导电流 $\\Leftarrow$ 电荷定向移动形成的电流位移电流 $\\Leftarrow$ 电位移通量的变化率(变化的电场) $$\\Phi_D=DS=\\varepsilon ES=\\varepsilon\\cdot\\frac{\\sigma}{\\varepsilon}S=\\sigma S$$ 传导电流 $$\\Longrightarrow \\frac{d\\Phi}{dt}=\\frac{d}{dt}(\\sigma S)=\\frac{dq}{dt}=I\\tag{18}$$ 位移电流 $$\\Longrightarrow I_D = \\frac{d\\Phi_D}{dt}=\\frac{dD}{dt}S=\\varepsilon\\frac{dE}{dt}S$$ 全电流 $\\Longrightarrow$ 全电流 = $I+I_D$ 非恒定电路中传导电流不连续但全电流保持连续 5.2 全电流安培环路定理$$\\oint_L\\boldsymbol{H}\\cdot d\\boldsymbol{l}=I+I_D,\\ I_D =\\frac{d\\Phi_D}{dt}= \\int_S\\frac{d\\boldsymbol{D}}{dt}\\cdot\\boldsymbol{S}\\tag{19}$$ 5.3 麦克斯韦方程组 电场 $\\boldsymbol{E}, \\boldsymbol{D}$ 自由电荷产生的静电场 $\\boldsymbol{E_1}$、$\\boldsymbol{D_1}$ $\\Rightarrow\\boldsymbol{E}=\\boldsymbol{E_1}+\\boldsymbol{E_2}$ 变化磁场产生的有旋电场 $\\boldsymbol{E_2}$、$\\boldsymbol{D_2}$ $\\Rightarrow\\boldsymbol{D}=\\boldsymbol{D_1}+\\boldsymbol{D_2}$ 磁场 $\\boldsymbol{B}, \\boldsymbol{H}$ 传导电流产生的磁场 $\\boldsymbol{B_1}$、$\\boldsymbol{H_1}$ $\\Rightarrow\\boldsymbol{B}=\\boldsymbol{B_1}+\\boldsymbol{B_2}$ 位移电流产生的磁场 $\\boldsymbol{B_2}$、$\\boldsymbol{H_2}$ $\\Rightarrow\\boldsymbol{H}=\\boldsymbol{H_1}+\\boldsymbol{H_2}$ 电场的高斯定理 $\\oint_S\\boldsymbol{D}\\cdot d\\boldsymbol{S}=\\sum_iq_i$ 电场是有源场 法拉第电磁感应定律 $\\oint_L\\boldsymbol{E}\\cdot d\\boldsymbol{l}=-\\iint_S\\frac{\\partial{\\boldsymbol{B}}}{\\partial{t}}\\cdot d\\boldsymbol{S}$ 静电场是保守(无旋、有势)场 磁场的高斯定理 $\\oint_S\\boldsymbol{B}\\cdot d\\boldsymbol{S}=0$ 磁场是无源场 全电流安培环路定理 $\\oint_L\\boldsymbol{H}\\cdot d\\boldsymbol{l}=\\sum(I_D+I)$ 磁场是有旋(非保守)场 位移电流 $I_d$ $$\\Phi_D = \\iint\\boldsymbol{D}\\cdot d\\boldsymbol{S}\\I_d = \\frac{d\\Phi_D}{dt}$$ $\\Rightarrow$ 位移电流密度 $j_d = \\frac{I_d}{S}$ 位移电流激发的磁场 $B$$$\\oint_L\\boldsymbol{H}\\cdot d\\boldsymbol{l}=j_dS$$ 第四章 狭义相对论力学基础第一讲 力学相对性原理1.1 经典力学相对性原理 力学相对性原理 对于描述力学现象的规律而言，所有惯性系都是等价的 力学规律的数学表达式应具有伽利略坐标变换的不变性(协变性) 1.2 伽利略坐标变化式根据 $\\lambda_{PS’}+\\lambda_{S’S}=\\lambda_{PS}$ 推出: $$\\lambda’ = \\lambda-\\mu t\\ \\ (\\lambda=x,y,z,\\boldsymbol{v},\\boldsymbol{a},\\mu=u),\\ t’=t\\tag{1}$$ 第二讲 狭义相对论基本假设 狭义相对论的相对性原理 在所有惯性系中，一切物理学定理都相同，即具有相同的数学表达式 对于描述一切物理现象的规律而言，所有惯性系都是等价的 光速不变原理 在所有惯性系中，真空中光沿各个方向传播的速率都等于同一个恒量 $c$，与光源和观察者的运动状态无关 第三讲 狭义相对论的时空观3.1 同时性的相对性 异地发生的两个同时事件，同时性具有相对性(对任意参考系)同地发生的两个同时事件，同时性具有绝对性(对任意参考系) 3.2 时间延缓 时间间隔具有相对性 $$\\tau=\\frac{\\tau_0}{\\sqrt{1-(\\frac{u}{c})^2}}=\\gamma\\tau_0\\tag{2}$$ 式中，$\\gamma = \\frac{1}{\\sqrt{1-(\\frac{u}{c})^2}}$，$\\tau_0$ 表示同地不同时的两事件的时间间隔称为原时，且在不同参考系中测得的时间间隔以原时最短； 3.3 长度收缩 长度测量具有相对性 $$L’=L\\sqrt{1-(\\frac{u}{c})^2}\\tag{3}$$ 式中，$L$ 表示观测者静止时测得的长度(原长)，$L’$ 表示在沿尺长度方向运动速度为 $u$ 时测得的长度，且在不同参考系中测得的长度以原长最长； 第四讲 洛伦兹变换4.1 时空坐标变换$P$ 在 $S$ 中的时空坐标 $(x,y,z,t)$,在 $S'$ 中的时空坐标 $(x',y',z',t')$ $S$ 系中测得 $S'$ 中坐标 $x''= x'\\sqrt{1-(\\frac{u}{c})^2}$ (长度收缩) $\\Longrightarrow$ 在 $S$ 系中 $P$ 坐标 $x = ut + x''=ut+x'\\sqrt{1-(\\frac{u}{c})^2}$ $S'$ 系中测得 $S$ 中坐标 $x_1= x\\sqrt{1-(\\frac{u}{c})^2}$ (长度收缩) $\\Longrightarrow$ 在 $S'$ 系中 $P$ 坐标 $x' = x_1 -ut' = x\\sqrt{1-(\\frac{u}{c})^2} - ut'$ $$ \\Longrightarrow x' = \\frac{x-ut}{\\sqrt{1-(\\frac{u}{c})^2}},t' = \\frac{t-\\frac{u}{c^2}x}{\\sqrt{1-(\\frac{u}{c})^2}}\\tag{4} $$ 式中，$u$ 表示 $S’$ 相对于 $S$ 的速度(相对速度)，$x’$ 表示待求坐标系中参量； 推导时间变换式: 由 $x’ = \\frac{x-ut}{\\sqrt{1-(\\frac{u}{c})^2}}$ 及逆变换 $x = \\frac{x’+ut’}{\\sqrt{1-(\\frac{u}{c})^2}}$ 联立消去 $x’$ 解 $t’$ 4.2 时空间隔变换$P_1,P_2$ 在 $S$ 中的时空坐标 $(x_1,y_1,z_1,t_1),(x_2,y_2,z_2,t_2)$,在 $S'$ 中的时空坐标 $(x_1',y_1',z_1',t_1'),(x_2',y_2',z_2',t_2')$ 由 $S\\rightarrow S'$ 得: $$ \\Delta t'=\\frac{\\Delta t-\\frac{u}{c^2}\\Delta x}{\\sqrt{1-\\beta^2}},\\Delta x'=\\frac{\\Delta x-u\\Delta t}{\\sqrt{1-\\beta^2}}\\ (\\beta = \\frac{u}{c}) $$ 由 $S'\\rightarrow S$ 得: $$ \\Delta t=\\frac{\\Delta t'+\\frac{u}{c^2}\\Delta x'}{\\sqrt{1-\\beta^2}},\\Delta x=\\frac{\\Delta x'+u\\Delta t'}{\\sqrt{1-\\beta^2}}\\ (\\beta = \\frac{u}{c})\\tag{5} $$ 式中，$u$ 关联于坐标轴选取的正方向，一般选定 $S$ 系运动方向为坐标轴正方向； 4.3 爱因斯坦速度相加定律由式 $(4)$ 求微分得: $$dx’=\\frac{(v_x-u)}{\\sqrt{1-\\beta^2}}dt,\\ dy’= dy,\\ dz’= dz,\\ dt’ = \\frac{(1-\\frac{u}{c^2}v_x)}{\\sqrt{1-\\beta^2}}dt$$ $$\\Rightarrow v_x’=\\frac{dx’}{dt’}=\\frac{v_x-u}{1-\\frac{u}{c^2}v_x},\\ v_y’=\\frac{dy’}{dt’}=\\frac{v_y\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x},\\ v_z’=\\frac{dz’}{dt’}=\\frac{v_z\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x}\\tag{6}$$ 第五讲 狭义相对论质点动力学5.1 相对论动量和质量 质速关系式 $$m(v) = \\frac{m_0}{\\sqrt{1-(\\frac{u}{c})^2}}$$ $$\\Longrightarrow \\boldsymbol{p}=m\\boldsymbol{v}=\\frac{m_0}{\\sqrt{1-(\\frac{u}{c})^2}}\\boldsymbol{v},\\ \\boldsymbol{F}=\\frac{d\\boldsymbol{p}}{dt}=\\frac{d}{dt}(\\frac{m_0}{\\sqrt{1-(\\frac{u}{c})^2}}\\boldsymbol{v})\\tag{7}$$ 式中，$m_0$ 表示物体静止质量； 5.2 相对论动能$$E_k = \\int \\boldsymbol{F}\\cdot d\\boldsymbol{r}=\\int \\frac{d(m\\boldsymbol{v})}{dt}\\cdot d\\boldsymbol{r}=\\int d(m\\boldsymbol{v})\\cdot \\frac{d\\boldsymbol{r}}{dt}=\\int d(m\\boldsymbol{v})\\cdot\\boldsymbol{v}$$ $m\\propto\\boldsymbol{v}\\Longrightarrow d(m\\boldsymbol{v})\\cdot\\boldsymbol{v}=(\\boldsymbol{v}dm+md\\boldsymbol{v})\\cdot \\boldsymbol{v}=v^2dm+mvdv$ 由式 $(7)$ 得: $m^2v^2=m^2c^2-m_0^2c^2\\Rightarrow v^2dm+mvdv=c^2dm$ $$ E_k=\\int_{m_0}^mc^2dm=mc^2-m_0c^2\\tag{8} $$ 5.3 质能方程 运动能量: $E=mc^2$静止能量: $E_0=m_0c^2$ 5.4 光子质量 爱因斯坦光子假说 光子能量: $E= h\\nu$ $$\\Longrightarrow m_\\varphi=\\frac{E}{c^2}=\\frac{h\\nu}{c^2}=\\frac{h}{c\\lambda}\\tag{10}$$ 光子、中微子在真空中速率为$c$，不可能静止因此静止能量等于零 5.5 相对论能量与动量关系由式 $(7)$ 得: $m^2(1-\\frac{v^2}{c^2})=m_0^2$ $\\Longrightarrow m^2c^4=m^2v^2c^2+m_0^2c^4$ $p=mv\\Rightarrow E^2=p^2c^2+E_0^2$ 由于光子 $m_0=0$ 故得: $E_0=0\\Rightarrow E^2=p^2c^2$ $$ \\Longrightarrow p=\\frac{h\\nu}{c}=\\frac{h}{\\lambda}\\tag{11} $$ 第五章 量子物理基础第一讲 普朗克量子假设1.1 基本概念 热辐射 物体由其温度所决定的电磁辐射(温度越高，单位时间内辐射的能量越高) 平衡热辐射 当辐射和吸收达到平衡时，物体的温度不再发生变化而处于热平衡状态时的热辐射 单色辐射出射度(单色辐出度) 物体单位表面积在单位时间内发射的，波长在$\\lambda\\rightarrow\\lambda+d\\lambda$ 范围内的辐射能 $dM_\\lambda$与波长间隔 $d\\lambda$ 的比值 绝对黑体(黑体) 能够全部吸收各种波长的辐射能而不发生发射和透射的物体 1.2 单色辐出度$$M_\\lambda(T)=\\frac{dM_\\lambda}{d\\lambda}\\tag{1}$$ 【单色辐出度图】 温度越高 单色辐出度越大，峰值波长越短 1.3 普朗克量子假设$$\\varepsilon=nh\\nu\\tag{2}$$ 式中，$\\varepsilon$ 表示腔壁中带电谐振子离散变化的能量，振子的频率为 $\\nu$，$n$ 表示量子数，$h\\nu$ 表示能量子——谐振子能量的最小单位(不是物质而是能量单位)； 第二讲 爱因斯坦光子理论2.1 光电效应 金属及其化合物在光的照射下发射电子的现象 【光电效应伏安特性曲线】 照射光光强越大，饱和光电流越大 光电子最大初动能与照射光强度无关，而与频率成线性关系 2.2 光电效应方程 遏止电压: $\\frac{1}{2}mv_m^2=eU_a$光电效应方程: $h\\nu = A + \\frac{1}{2}mv_m^2$截止频率: $\\nu_0=\\frac{A}{h}$ $$\\Longrightarrow U_a = \\frac{h}{e}\\nu-\\frac{A}{e}\\tag{3}$$ 第三讲 康普顿效应及光子理论解释3.1 康普顿效应 单色$X$ 射线被物质散射时，散射光两种波长中有一种波长比入射线长的散射现象 3.2 光子理论解释【微观机制】——等价于微观粒子的弹性碰撞入射光子频率 $\\nu_0$,散射角为 $\\theta$ 的光子频率为 $\\nu$,电子沿着与入射线成 $\\varphi$ 角的方向运动,静质量 $m_0$,动质量 $m$由动量守恒定律得到: $\\frac{h\\nu_0}{c}=\\frac{h\\nu}{c}\\cos\\theta+mv\\cos\\varphi$ $\\frac{h\\nu}{c}\\sin\\theta=mv\\sin\\varphi$ $\\Longrightarrow m^2v^2c^2=h^2(\\nu_0^2-\\nu^2-2\\nu_0\\nu\\cos\\theta)\\tag{4}$ 由能量守恒定律得到: $hv_0+m_0c^2=hv+mc^2\\tag{5}$ 进一步式 $(5)$ 平方 $-$ 式 $(4)$ 且 $m^2(1-\\frac{v^2}{c^2})=m_0^2$ 得到: $$ m_0c^2(\\nu_0-\\nu)=h\\nu_0\\nu(1-\\cos\\theta) $$ $$ \\Longrightarrow \\Delta\\lambda = \\lambda - \\lambda_0=\\frac{c}{\\nu}-\\frac{c}{\\nu_0}=\\frac{h}{m_0c}(1-\\cos\\theta) =\\frac{2h}{m_0c}\\sin^2\\frac{\\theta}{2}=2\\lambda_C\\sin^2\\frac{\\theta}{2}>0\\tag{6} $$ 式中，$\\lambda_C=\\frac{h}{m_0c}$ 称为电子的康普顿波长； 第四讲 氢原子光谱 玻尔氢原子理论4.1 氢原子光谱实验规律 氢原子光谱——线状光谱【里德伯-里兹合并原则】 光谱线波数 $\\widetilde{\\nu}=\\frac{1}{\\lambda}=T(k)-T(n)=R_H(\\frac{1}{k^2}-\\frac{1}{n^2})$ ($k、n\\in Z$ 且 $n&gt;k$) $k = 1\\ (n=2,3,4,\\cdots)$ ——赖曼系 $k = 2\\ (n=3,4,5,\\cdots)$——巴耳末系 4.2 玻尔氢原子理论——氢原子或类氢原子【辐射频率公式】——辐射或吸收一个频率为 $\\nu_{kn}$ 的光子 $$\\nu_{kn} = \\frac{|E_k-E_n|}{h}\\tag{7}$$ 【角动量量子化条件】——轨道角动量不能连续变化 $$L=mvr=n\\frac{h}{2\\pi}=n\\overline{h},\\ \\ n = 1,2,3,\\cdots\\tag{8}$$ 式中，$\\overline{h}=\\frac{h}{2\\pi}$ 表示约化普朗克常数；【电子轨道半径】——电子轨道半径不能连续变化 $$m\\frac{v^2}{r}=\\frac{1}{4\\pi\\varepsilon_0}\\frac{e^2}{r^2}$$ 又由式 $(8)$ 得: $$\\Rightarrow r_n=n^2(\\frac{\\varepsilon_0h^2}{\\pi me^2})=n^2r_1\\ (n=1,2,3,\\cdots)\\tag{9}$$ 式中 $r_1$ 表示氢原子中电子的最小轨道半径，称为玻尔半径； $n=1$ 的定态——基态$n=2,3,4,\\cdots$ 各态——受激态 氢原子能量=电子动能+电子电势能 量子数为 $n$ 的定态时氢原子能量： $$E=\\frac{1}{2}mv^2-\\frac{1}{4\\pi\\varepsilon_0}\\frac{e^2}{r}=-\\frac{1}{8\\pi\\varepsilon_0}\\frac{e^2}{r}$$ $$\\Longrightarrow E_n=-\\frac{1}{8\\pi\\varepsilon_0}\\frac{e^2}{r_n}=-\\frac{1}{n^2}(\\frac{me^4}{8\\varepsilon_0^2h^2})\\ \\ \\ (n=1,2,3,\\cdots)\\tag{10}$$ 当 $n\\rightarrow \\infty$ 时,$r_n\\rightarrow \\infty$，$\\ E_n\\rightarrow0$，能级趋于连续，原子趋于电离；$E&gt;0$ 时，原子处于电离状态，能量可连续变化。 电离能: 使原子或分子电离所需要的能量原子电离电势:电子使原子刚好电离所需的加速电势差 【氢原子跃迁】高能态跃迁到低能态发射一个光子其频率和波数： $$\\nu_{nk}=\\frac{E_n-E_k}{h}\\ \\ \\ (n&gt;k)$$ $$\\widetilde{\\nu_{nk}}=\\frac{1}{\\lambda_{nk}}=\\frac{\\nu_{nk}}{c}=\\frac{1}{hc}(E_n-E_k)\\tag{11}$$ 常用物理常数 物理常数 物理符号 取值 普朗克常数 $h$ $6.62607015\\times 10^{-34} \\ \\ J\\cdot s$ 电子电量 $e$ $1.6\\times 10^{-19}\\ \\ C$ 光速 $c$ $3\\times 10^8\\ \\ m/s$ 真空电容率/真空介电常量 $\\varepsilon_0$ $8.85\\times 10^{-12}\\ \\ C^2\\cdot N^{-1}\\cdot m^{-2}$ Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 郭恒. 2022年秋, 大学物理(II), 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/227063073.html","link":"/collaboration/Physics/"},{"title":"概率论与数理统计","text":"前言 课程复习、期末试题资源详见阿里云盘链接 概率论与数理统计笔记总结文档 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 郭杏莉. 2022年秋, 概率论与数理统计, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/227062626.html","link":"/collaboration/ProbabilityTheory/"},{"title":"SOC(System on Chip) 微体系结构设计","text":"前言 课程实验、复习、期末试题资源详见阿里云盘链接 期末复习笔记 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 张剑贤, 刘锦辉. 2024年春, SOC微体系结构设计, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/240785527.html","link":"/collaboration/SOCMicroarchitecture/"},{"title":"软件工程","text":"前言 课程复习、期末试题资源详见阿里云盘链接 期末复习笔记 Contributors Zhihao Li, Computer Science and Technology, Xidian University https://zhihaoli.top References 赵辉. 2024年秋, 软件工程, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/240785498.html","link":"/collaboration/SoftwareEngineering/"},{"title":"关于生命与健康的一些思考","text":"致敬人民好总理今天早上刚起来，就被一则重大的消息所震惊——我们的好总理李克强不幸逝世；我真的不敢相信，深深为之震惊：“他还那么年轻，这些年还一直在全心全意服务国家和人民，怎么会呢”。可叹人生苦短、世事无常，但总觉得总理音容犹在、笑貌宛存，中国又失去了一位人民的好总理······ 李克强总理的一生，是革命的一生、奋斗的一生、光辉的一生，是全心全意为人民服务的一生，是献身于共产主义事业的一生。向总理致敬，愿您一路走好！ 关于国务院总理的记忆我的人生榜样——周恩来总理我小时候便读过一些清正廉洁的书籍，对于政府官员为政作风，工作态度都有着很深的感触。我尤为记得国务院总理一直以来都是为国为民，无私奉献最好的榜样。特别是周恩来总理，一直到现在都是我的人生榜样。我也有幸找到了当时小学五年级读过的书籍中的那篇文章，上面写道，“死不留灰，生而无后，官而不显，党而不私，劳而无怨，去不留言”。 达到这样六大惊人之“无”的境地，只有伟大的人民父母官才能够做的到，也只有真正深入了解人民疾苦、与人民同患难才能感受到伟大的责任。 关于生命意义的思考李克强总理，享年68岁，前段时间才刚退休正应有机会安享晚年，却遭遇此劫难。在我的认知里，40-60岁正当中流砥柱之际，60-70岁正是老骥伏枥，志在千里之时，总理一生为人民鞠躬尽瘁却没得机会安详晚年······这让我想起保尔曾说，“人最宝贵的是生命，但生命只有一次，人的一生应该这样度过：当回忆往事的时候，他不会因为虚度年华而悔恨，也不会因为碌碌无为而羞愧；在临死的时候，他能够说，我的生命和全部的精力，都全部献给了世界上最壮丽的事业——为人类的解放事业而斗争”。我们的总理虽然走了，但是他的精神却永远留在了我们的心中。 为祖国健康工作50年让我深深触动地还有对生命健康的追求，从中可以看到我国医学事业仍需要努力，如果医学技术能够再先进一些，是不是就有很大可能挽回我们的好总理？我高中时也想过从事医学，为健康中国贡献自己的力量，但是阴差阳错选择了计算机科学与技术，中国医学的路途就交给其他有志青年，各自艰苦奋斗，任重而道远。 人生着实短暂，作为刚满20岁的我，在这个时间节点上已经开始为祖国事业贡献自己的力量，我会谨记保尔的忠告，会传承总理的精神，珍惜生命，为祖国健康工作50年。","link":"/essay/HealthAndLife/"},{"title":"我的科研理解——读《研究生的早期之路》有感","text":"学术研究的专业性之前对科研这项工作的了解，主要是来自一名国外研究者的个人陈述，“研究是一份非常正式、值得尊重的工作”，再后来阅读赵鑫老师的博文，即研究者所从事的学术研究当是从各方面都是非常专业的。这是我作为初学者第一次了解的原则，从宏观上定性的认识。这里引用赵鑫老师的原话： 专业的论文从写作、理论以及代码等多个维度都是专业的； 研究基本功作为初学者，当然也略微接触了一些科研内容，但是我始终不能够理解或探索到什么是真正有意义的科研。 一方面，我的研究能力还没有达到应有的水平，另一方面，我期待的研究模式应该是发现问题、机理分析、动机分析、提出 idea、公式推导、设计模型、开展实验、结果分析，而在此之前的研究模式却是发现问题、动机分析、提出idea、设计模型、开展实验、结果分析。主要的区别在于，后者是没有太多依据地提出idea或者说不断挖掘可用部分，至于有没有理论支撑全依赖于实验验证，这就给我了一种错觉？似乎想 idea 就是天马行空地想，然后直接验证测试。回想起上次面试，一位老师的提问，现在才悟到：应该不断追问，为什么采用这个模块，有什么作用和不足之处。也即，要深入地思索每个模块有什么特点，实现效果怎样，有没有其他改进的地方。 那么，回到赵鑫老师的博文，讲到“熟读论文百篇、白纸推公式、vim写代码”，这个理想状态确实很难，但也对此很是感触。 熟读论文百篇 白纸推公式 vim写代码 确实，这是至少包括我在内的本科生所欠缺的一部分内容。 回想我阅读论文的习惯，如果与我开展实验无关但是研究思路相关的论文，那就阅读论文摘要、相关工作、研究理论、模型设计、实验结果；如果与我开展实验相关而且研究思路相关的论文，那就阅读论文摘要、相关工作、研究理论、模型设计、实验设置、实验结果、实验代码。但不论哪一种习惯，我都没有认真亲手推导其中的公式，一方面因为有的确实很难，另一方面则是现在才意识到这一点。 持之以恒我一直很担心这样一个问题，当所从事的研究工作给予的正反馈或激励比较少时，我是否真的能够继续坚持下去。 这个问题真的很难，我不可避免地要在意科研以外的其他事情，顾虑因素始终存在，而且我觉得这个问题真的很普遍，不只是我所具有的。然后又想到了最近报名夏令营所要叙述的个人研究兴趣，大部分都要求要对该方向有强烈的研究动机或动力。那么，其实我是不太认同的，研究兴趣只是支撑力量的一小部分，就像我来说，似乎没有特别大的偏好，只要该方向有很好的研究前景，有进一步改变世界的潜力，我觉得都是我感兴趣的方向，都愿意为之持续投入研究。 科研动机进一步地，我思索自己即将走向这条道路的支撑力量来源，首先是对世界的认知，研究其实是发现这个世界新的科学规律，从而改变人类生产生活方式。我从小对科学家都有一种向往，一直坚信“万物皆可研究”，这是对世界的认知，就好像在不断追问，为什么我来到这个世界，为什么这个世界是这样，为什么我不能改变这个世界。在这个特殊的时代，我特别希望能够根植一个领域，然后通过自己的研究改变世界的一部分，完成我作为一个微小个体来到这个世界的使命。 其次是对研究者非常专业严谨风格的向往，现下的学术研究内容广泛、规模庞大，自己难免接触到非常多的研究成果，看到他们规范的论文写作、精美的数据图表、亮丽的个人名片，心中总是一阵澎湃。虽然相比于工业界的工程师，研究学者的成果往往是停留在理论上的研究，但是却往往有一种特别的风采，那便是一生二，二生万物的魅力。随着近年来，不断有基础模型投入应用，也逐渐改变着停留理论研究的局限性，开始真正走向改变生产生活的方向。 再者是我的生活理念和习惯，我喜欢不断思索一个问题，一有空闲就会思考，有一部分观点认为，似乎这是一种工作狂（Workaholic），是彻底的 Live for work。但是从笨拙简单的角度讲，这何尝不是一种热爱。在某一个时刻突然想出的时刻，是多么令人惊喜。反而，我喜欢这样纯粹简单的生活氛围，不用受到诸多的干扰。可能常见到一个人沉默不言，但实际上早已碰撞出思想的火花。记得大二期间完成一道算法题目，我确实一直思索它，不论赶路、吃饭，还是其他空闲时间，这是一种疯狂，但是确实是珍惜时间的最好方式。 最后是我个人的做事风格与责任感，也记得之前有说法，人生一直忙于规划，却从没有自由的时间。我是一直为个人的发展不断做出并调整规划，并基于这份规划指导生活、完成事情。从个人的观点来看，虽然有时候或者是事情忘记规划，或者是没有按照规划执行，但是总体将这是非常有用的，至少大部分工作都不会遗忘、执行效率也会提高。责任感是我觉得一个人为人处世中最重要的特质，在前三年的学习期间，经常遇到一些人，自己的事情都完成不好，同时也对团队的工作造成影响。常讲，“做一个靠谱的人”，不论是同学、朋友，还是导师、同事，与他人相处，做好分内之事，也尽量对整体工作上心，才是实现团队合作的最佳状态。比较科研工作中的事情，反倒是我这种特点还比较适合走向这条道路的，交流讨论的各种 Plans、以及合作研究的责任。 借用赵鑫老师的一条建议，“坚持读完若干经典书籍、坚持复现若干经典模型的代码、坚持每天不断阅读新的论文、坚持写作、坚持跑不同的实验、坚持去做错误分析”，在找到自己的科研动机后，就持之以恒地形成坚持的习惯吧。 参考文章 研究生的早期科研之路","link":"/essay/MyViewsOnResearch/"},{"title":"征服秦岭第一峰——朱雀森林公园游记","text":"出行准备计划下午爬山，中午直接在上面吃饭。前天晚上就提前买好各种速食，尤其我们每个人准备了一份自热米饭。考虑到没人的负重，具体物品清单如下： 三份自热米饭； 三个腌制鸡腿； 三个超大火腿肠； 三个卤蛋； 一包薄荷糖； 一包口香糖； 五瓶500ml矿泉水； 一瓶1.5L矿泉水； 我们水源准备的很充分，但实际上还是刚刚好。准备的薄荷糖本来是想爬山中途可以加快通气，但后来发现反而有些加速口腔变冷。每个人备了些厚重的衣服，因为山上风很大，而且海拔较高，添置了羽绒服以及较厚的保暖外套（唯一缺陷是下身没做额外加暖，结果后续真的有些扛不住）。 路线规划由于朱雀森林公园距离南校区有将近 70 公里，沿途也没有地铁以及公交，基本属于给自驾游的游客准备的，因此我们选择直接打车过去。 百度地图上打车预计需要160元左右，打车的第一个师傅直接让加到200元，不然不接了。这么临时涨价的，还不走打车平台的，实在是无法接受。遇到的第二个师傅倒是非常热心，直接就接送我们。后面属于是，去时走打车平台，然后师傅在景区门口等我们爬完山下来，再接我们返程，收费200元。我觉得等我们四五个小时也是非常不易的，索脆就答应了。那么返程的利润呢，属于私下交易，不走平台，我觉得他也赚了好多。 爬山过程刚下车，迎面就来强劲的冷分，我们三个人在山脚立刻换上了厚装备。虽然是国庆，但是这里爬上的人也不是特别多，可能由于天气比较冷的缘故。简单在爬山开始处吃了点东西，便开始动身攀爬。 爬山体验 总体上行程是，爬一座山后再下山一段路程，然后再爬上另外一座上，比较累的。但是沿途风景确实很美，尤其是远处的秦岭，让人心旷神怡。 爬山过程，逆风而行，山上的风很大也比较凉，尤其是到山顶穿着羽绒服感觉都顶不住。期间，一开始吃薄荷糖来舒畅呼吸，后面发现口腔越来越冷，喝水直接感觉像喝冰水，所以一定不要在冷风爬山时吃薄荷糖。 最高的山峰——冰晶顶，由于山顶确实十分寒冷，可能只有几摄氏度的情况，我们便止步在草甸上面，没有继续前行那一两百米。 总体爬上体验感还是十分不错的，朱雀森林公园有缆车的，下山可以乘坐缆车，避免膝盖受伤。","link":"/essay/ZhuqueForestPark/"},{"title":"计算机图形学入门","text":"Learning Notes References 罗楠. 2024秋, 计算机图形学, 西安电子科技大学. https://mooc1.chaoxing.com/mooc-ans/course/245352860.html Lingqi Yan, GAMES101, UC Santa Barbara. https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html","link":"/knowledge/ComputerGraphics/"},{"title":"Mathematic Principles about Cosine Similarity of High-dimensional Vectors","text":"IntroductionIn machine learning, we often need to measure the distance between the high-dimensional vectors and using the distance to cluster, do re-labeling, or evaluate samples. Although there are many other alternative methods, the cosine similarity is the most used and more efficient. Two-dimensional VectorsWhen I encountered this theory, it’s so fantastic because it is just extended from one conclusion that I derived in the high school. Let’s firstly take the original conclusion as an example.In the following figure, there are three points $A$, $B$, $P$ in the two-dimensional space which form two vectors $\\overrightarrow{PA}$, $\\overrightarrow{PB}$. We know, the vector $\\overrightarrow{AB}$ could be represented as $\\overrightarrow{PB} - \\overrightarrow{PA}$. In the high school, we use this characteristic to calculate the cosine value between the two vectors. That is,$$\\cos \\theta = \\frac{\\overrightarrow{PA}^2 + \\overrightarrow{PB}^2 - \\overrightarrow{AB}^2}{2|\\overrightarrow{PA}||\\overrightarrow{PB}|}$$$$\\overrightarrow{AB}^2 = \\overrightarrow{PA}^2 + \\overrightarrow{PB}^2 - 2\\overrightarrow{PA} \\cdot \\overrightarrow{PB}$$$$\\cos \\theta = \\frac{\\overrightarrow{PA} \\cdot \\overrightarrow{PB}}{|\\overrightarrow{PA}||\\overrightarrow{PB}|}$$If we denote the $\\overrightarrow{PA}=(x_1, y_1)$, $\\overrightarrow{PB}=(x_2, y_2)$, then we can get the more concrete formula.$$\\cos \\theta = \\frac{x_1x_2 + y_1y_2}{\\sqrt{(x_1^2 + y_1^2)}\\sqrt{(x_2^2 + y_2^2)}}$$ Similarity AnalysisBut why is it suitable for evaluating the similarity between two vectors?This method using the cosine value of $\\theta$ to measure the similarity between the two vectors. If the cosine value is close to 1, it means that the two vectors are parallel to each other. If the cosine value is close to 0, it means that the two vectors are perpendicular to each other.If the cosine value is close to -1, it means that the two vectors are opposite to each other.This method just balance the angle or direction of vectors. The more closer the direction is, the more similar the two vectors are. Do you put forward another question? If we have two vectors with the same direction and different modulus and we have another two vectors with the same direction and same modulus, the two situations will both get the cosine value of 1. But actually, the latter is more similar in our opinion so this is a little drawback. High-dimensional VectorsNow, let’s extend this conclusion to the high-dimensional vectors. The only difference is just the dimensionalities which are very very large but the principles are still consistent.If $x\\in R^n$, $y\\in R^n$, then we can get the cosine similarity.$$\\cos \\theta = \\frac{x^T\\cdot y}{|x||y|}=\\frac{\\sum_{i=1}^n x_iy_i}{\\sqrt{\\sum_{i=1}^n x_i^2}\\sqrt{\\sum_{i=1}^n y_i^2}}$$ ConclusionThe cosine similarity is a very useful method to measure the similarity between the high-dimensional vectors. But it has its application limitations. For some situations, it doesn’t work well or the principles are not desired. Just taking my exploration, I want the similarity between samples to be higher when they have more overlapping features. So this situation is not suitable for the cosine similarity. In a nutshell, using the cosine similarity need to consider your application scenarios.","link":"/knowledge/CosineSimilarity/"},{"title":"The Basic Principles and Some Further Discussion of GANs","text":"Maximum Likelihood Estimation Given a data distribution $P_{data}(x)$ We have a distribution $P_G(x;\\theta)$ parameterized by $\\theta$ E.g. $P_G(x:\\theta)$ is a Gaussian Mixture Model, $\\theta$ are means and variances of the Gaussians We want to find $\\theta$ such that $P_G(x;\\theta)$ close to $P_{data}(x)$ Sample ${x^1, x^2,…,x^m}$ from $P_{data}(x)$ We can compute $P_G(x^i;\\theta)$ Likelihood of generating the samples$$L = \\prod_{i=1}^m P_G(x^i;\\theta)\\tag{1}$$ So we can just solve the optimal $\\theta$:$$\\theta^* = arg \\max_{\\theta}\\prod_{i=1}^m P_G(x^i;\\theta)\\tag{2}$$$$= arg \\max_{\\theta} \\log\\prod_{i=1}^m P_G(x^i;\\theta)\\tag{3}$$$$=arg \\max_{\\theta}\\sum_{i=1}^m \\log P_G(x^i;\\theta)\\tag{4}$$$$\\approx \\max_{\\theta} E_{x\\sim P_{data}}[\\log P_G(x;\\theta)]\\tag{5}$$$$=arg \\max_{\\theta}\\int_x P_{data}(x)\\log P_G(x;\\theta)dx - \\int_x P_{data}(x)\\log P_{data}(x)dx\\tag{6}$$$$=arg \\min_{\\theta} KL(P_{data}(x)||P_G(x;\\theta))\\tag{7}$$ In the equation (2), $\\theta$ means the parameters of G(Generate) model and $x^i$ means the $i$-th sample from $P_{data}(x)$. So this equation expresses the probability of $P_G$ generating the samples from $P_{data}$. In the equation (3) and (4), we use the logarithm to make the equation easier to calculate and it doesn’t influence the optimal $\\theta$. Equation (5) is the approximate of summation results and it only has the difference with $\\frac{1}{m}$. Int te euqation (6), there is a extra term $\\int_x P_{data}(x)\\log P_{data}(x)dx$ which is the constant for $G$ network so it also doesn’t influence the optimal $\\theta$. Basic Idea of GANBut the Generator $G$ is hard to be learned by maximum likelihood. Min-max GANDefine a value function $V(G, D)$:$$G^* = arg \\min_G \\max_D V(G, D)\\tag{8}$$ Given G, the optimal $D^*$ maximizing:$$V = E_{x\\sim P_{data}}[\\log D(x)] + E_{x\\sim P_G(x)}[\\log (1-D(x))]\\tag{9}$$$$=\\int_xP_{data}(x)\\log D(x)dx + \\int_xP_G(x)\\log (1-D(x))dx\\tag{10}$$$$=\\int_x[P_{data}(x)\\log D(x) + P_G(x)\\log (1-D(x))]dx\\tag{11}$$ Given $D$, the optimal $G^*$ minimizing:$$P_{data}(x)\\log D(x) + P_G(x)\\log (1-D(x))\\tag{12}$$ Optimal $D^*$If we maximum each $P_{data}(x)\\log D(x) + P_G(x)\\log (1-D(x))$ for any input $x$, there will be the optimal $D$. Given $x$, the optimal $D^*$ maximizing:$$P_{data}(x)\\log D(x) + P_G(x)\\log (1-D(x))\\tag{13}$$There we can view $P_{data}(x)$ as a constant value of $a$, and $P_G(x)$ as a constant value of $b$.$D^*$ maximizing: $f(D) = a\\log D + b\\log (1-D)$. Solving it, $D^* = \\frac{1}{a+b}$, that is$$D^* = \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}\\tag{14}$$ Conduct Result$$V(G, D^*) = E_{x\\sim P_{data}}[\\log \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] +E_{x\\sim P_G(x)}[\\log \\frac{P_{G}(x)}{P_{data}(x)+P_G(x)}]\\tag{15}$$$$=\\int_x P_{data}(x)\\log \\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}dx + \\int_x P_G(x)\\log \\frac{P_{G}(x)}{P_{data}(x)+P_G(x)}dx\\tag{16}$$$$=\\int_x P_{data}(x)\\log \\frac{\\frac{P_{data}(x)}{2}}{\\frac{P_{data}(x)+P_G(x)}{2}}dx + \\int_x P_G(x)\\log \\frac{\\frac{P_{G}(x)}{2}}{\\frac{P_{data}(x)+P_G(x)}{2}}dx\\tag{17}$$$$=-2\\log2+\\int_x P_{data}(x)\\log \\frac{P_{data}(x)}{\\frac{P_{data}(x)+P_G(x)}{2}}dx + \\int_x P_G(x)\\log \\frac{P_{G}(x)}{\\frac{P_{data}(x)+P_G(x)}{2}}dx\\tag{18}$$$$=-2\\log2+KL(P_{data}(x)||\\frac{P_{data}(x)+P_G(x)}{2}) + KL(P_G(x)||\\frac{P_{data}(x)+P_G(x)}{2})\\tag{19}$$$$=-2\\log2+2JSD(P_{data}(x)||P_G(x))\\tag{20}$$ Optimal $G^*$$$G^* = arg \\min_G \\max_D V(G, D)$$When got the optimal $D^*$,$$\\max_D V(G, D) = -2\\log 2+2JSD(P_{data}(x)||P_G(x))\\tag{21}$$So to minimize above equation, we just get the optimal G:$$P_G(x) = P_{data}(x)\\tag{22}$$ Further DiscussionThe adversarial idea is very innovative which seems there two bodies, one for making decisions and the other for checking the quality, will enhance each other alternately. In some robust research domain, this idea will provide a new way to improve, like learning with noisy labels. Reference Generative Adversarial Network","link":"/knowledge/GANs/"},{"title":"Knowledge Introduction","text":"科学研究定义 国家教育部对科学研究的定义：科学研究是指为了增进知识包括关于人类文化和社会的知识以及利用这些知识去发明新的技术而进行的系统的创造性工作; 美国资源委员会对科学研究的定义：科学研究工作是科学领域中的检索和应用，包括对已有知识的整理、统计以及对数据的搜集、编辑和分析研究工作; 《科研项目完全指南：从课题选择到报告撰写》：剑桥在线词典将“研究”定义为“对某一主题的详细探究，特别是为了发现（新）信息或达成（新）理解”; 研究包括三个步骤：提出问题；收集用以回答问题的数据；给出问题的答案。 IntroductionThese days I have been sentimental about the fact that I had learned so much knowledge but what’s the really helpful to my current learning or research is not so directly accessible. Until now, I have learned for at least fifteen years covering basic subjects from chinese, mathematics, english, physics, chemistry, biology, geography, history to politics and engineering subject of computer science. However, to be honest, I have forgotten a lot of them which is not so necessary or neccessay for my current learning. In other words, I cann’t rethink them immediately when I engage in the related work. In my views, the sense of immediate recall is very important for research innovation which allows us to know what kind of knowledge there exists and how to reform the existed knowledge in new environment. So I have decided to develop this habit of recording learned knowledge which has the potential in motivating my future learning or research. Knowledge ListMathematical Principles仿射变换(Affine Transformation)线性模型:$$price = w_{area}\\cdot area + w_{age} \\cdot age + b$$仿射变换的特点是通过加权和对特征进行线性变换，并通过偏置项进行平移。 非线性频率压缩在滤波器设计中将整个模拟频率轴压缩到 $\\pi/T$ 之间，使得 $H_a(s), s=j\\Omega$ 压缩为 $\\widehat{H_a}(s_1),s_1=j\\Omega_1$, 可以利用正切变换实现频率压缩模型：$$\\Omega = \\frac{2}{T}\\tan(\\frac{1}{2}\\Omega_1T)$$这个设计思想实质上利用了正切函数定义域有限、值域无限以及奇函数的性质；推而广之，这种设计可以实现特定的单值压缩方法，也可以实现值域的延展。 一些类似的函数特性，对数函数，指数函数分别适合于定义域、值域取值 $0 \\sim 1$ 之间的情况，但是对目标域都有所限制，因此这些函数往往没有正切函数具有优良的特性。 Research InnovationLearning With Noisy Labels Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels Innovation: DNN的相互指导学习机制，两个模型分别动态地选取一些干净样本相互提供给对方进行学习，目的是过滤不同类型的噪声； Learning Points: 直觉是同辈相互纠错的学习机制，而且训练中其样本选取的动态性值得一提； DivideMix: Learning with Noisy Labels as Semi-supervised Learning Innovation: 对噪声数据集进行划分，并同时学习两个模型进行相互指导、标签集成，以克服不同类型的噪声； Learning Points: Mutual Learning 和 交互学习一定程度上可以增强模型鲁棒性； Project HabitsPackage ManagementMiniconda Configuration1234567891011121314151617############ Conda Environment Installation ############# Fetch the miniconda scriptexport HOME=$PWDwget -q https://repo.anaconda.com/miniconda/Miniconda3-py37_4.12.0-Linux-x86_64.sh -O miniconda.shsh miniconda.sh -b -p $HOME/miniconda3rm miniconda.shexport PATH=$HOME/miniconda3/bin:$PATH# Initialize condasource $HOME/miniconda3/etc/profile.d/conda.shhash -rconda config --set always_yes yes --set changeps1 yes# Create new environmentconda create -n my_env python=3.8conda activate my_env","link":"/knowledge/Introduction/"},{"title":"My Practical Experience On Linux","text":"Linux 内核相关僵尸进程原因 父进程没有回收子进程的资源 子进程的进程描述符仍然存在，因此子进程成为僵尸进程 解决方法 父进程调用 wait() 函数，回收子进程的资源 或者父进程调用 waitpid() 函数，回收子进程的资源 或者父进程调用 signal(SIGCHLD,SIG_IGN) 函数，忽略 SIGCHLD 信号，让内核自动回收子进程的资源 实际开发当我们在 Linux 主机上遇到占用显存但是找不到对应的进程时（如下图案例所示），往往就是子进程所占用的资源没有被回收，而父进程已经结束。这种情况一般会在多线程并行当中出现，比如在多线程并行训练模型时，如果主线程在子线程结束之前就已经结束，那么子线程就会变成僵尸进程，占用显存。 对应的解决方法，一般可以通过检测僵尸进程，然后再寻找僵尸进程对应的父进程，安全地终止父进程后，操作系统就会自动清理对应的子进程。 检测僵尸进程 1ps aux | grep Z 在输出中，状态列（STAT）会显示为 Z，表示这是一个僵尸进程. 查找僵尸进程对应的父进程 1ps -o ppid= -p 2721429 可以通过以上命令，查找僵尸进程对应的父进程的 PID，然后进行终止. 终止父进程 1kill -9 2721429 当父进程被杀死后，操作系统会自动将这些僵尸进程的父进程设置为 init 进程（PID 1），相当于讲这些僵尸进程转移给了 init 进程作为接管的父进程。init 是系统的主进程，它会自动调用 wait() 来回收所有孤立的僵尸进程，从而清除它们。 nohup 后台运行原理nohup 是 no hang up 的缩写，它的作用是让进程在后台运行，即使终端关闭也不会影响进程的运行。 使用方法1nohup command &gt; output.log 2&gt;&amp;1 &amp; 其中，command 是要执行的命令，output.log 是输出日志文件，2&gt;&amp;1 表示将标准错误输出重定向到标准输出，&amp; 表示将命令放到后台运行。 实际开发1nohup sh test.sh &gt; output.log 2&gt;&amp;1 &amp; 以上一条命令，基本能够解决大多数情况下的后台运行。","link":"/knowledge/PracticeOnLinux/"},{"title":"3D Gaussian Splatting 真实场景的光场图像渲染","text":"一、基本原理实现​ 3DGS 将稀疏的点云变成 3D 空间中的椭球体，每个椭球体拥有位置、颜色、不透明度、协方差（大小），当混合在一起时，可以产生从任何角度渲染的完整模型的可视化效果； 整体框架 通过 SfM 获取初始化稀疏点云（采样点）； 基于初始化点云生成 3D 高斯椭球集； 利用投影矩阵将 3D 高斯椭球投影的 2D 平面； 进行场景渲染（分 tile 16*16）； 计算 Loss 以及梯度回传； 基于梯度自适应改变点云的分布方式； 二、构建场景数据​ 针对实际场景重建需要获取场景各个角度的图片，并且每张照片尽量保持一致的曝光。由于也可以录制视频提取单帧来获取图片，因此构建场景数据集主要通过以下两种方式： 获取重建场景各个角度图片，尽量保持一致曝光，推荐100-1000张； 利用 FFMPEG工具构建真实场景数据集 ​ 使用的基本命令如下，video_addr 指的是实际视频文件地址，FPS 主要影响每秒采多少帧的图像： 1ffmpeg -i {video_addr} -qscale:v 1 -qmin 1 -vf fps={FPS} %04d.jpg 构建的场景数据集 数据集目录结构 12345&lt;dataset_name&gt;|---input| |---&lt;image 0&gt;| |---&lt;image 1&gt;| |---... 三、获取相机位姿​ 3DGS 需要利用稀疏点云作为输入进行建模，因此我们需要针对场景数据集建立点云。本项目中我们可以利用 COLMAP 获取相机位姿建立点云，安装完成后在终端执行以下命令，完成相机位姿和点云的建立： 1python convert.py -s data/dataset_name 可视化相机位姿与点云 借助 COLMAP 工具我们可以对真实场景建立稀疏点云以及对应的相机位姿。 数据集目录结构 1234567891011&lt;dataset_name&gt;|---input|---distorted|---images|---sparse| |---0| | |---cameras.bin| | |---images.bin| | |---points3D.bin|---stereo|---... 四、3DGS训练模型​ 针对构建好的真实场景数据以及 COLMAP 估计出的相机位姿，利用 3DGS 训练场景数据集对应的模型： 1python train.py -s data/playroom 模型训练损失 场景渲染对比 ​ 训练完成后，会得到如下目录结构，其中 point_cloud.ply 就是训练好的点云模型文件。 1234567891011output|---&lt;Env_ID&gt;| |---point_cloud| | |---iteration_7000| | | |---point_cloud.ply| | |---iteration_30000| | | |---point_cloud.ply| |---cameras.json| |---cfg_args| |---events.out...| |---input.ply 五、渲染真实场景​ 利用 SIBR Viewers 可以利用训练好的模型文件渲染实际场景，具体在终端执行以下命令： 1./viewers/bin/SIBR_gaussianViewer_app -m &lt;path to trained model&gt; 整体渲染效果 不同缩放系数的影响直观地感受到，从最开始的稀疏点云建立的椭球形模型不断优化，逐渐的渲染出整个实际场景。 六、其他真实场景的渲染从构建的数据集以及渲染结果得出，场景视角越多，渲染出的场景图像质量越高，对于最后一个教学楼数据集，仅从单个视角构建图像时，渲染的3D场景效果就非常差。因此，如果想要得到质量更高的渲染场景，可以从多个视角拍摄一段连续的视频，再从中提取帧构造场景数据集。","link":"/projects/3DGS/"},{"title":"Design of A Basic Computer Model With Stack Function","text":"IntroductionLast weekend I undertook a project to design a basic computer model from clock generator design to microinstruction encoding. And I preferably chose to design a basic model with common stack functions. My Report Contributors Zhihao Li","link":"/projects/ComputerModel/"},{"title":"基于YOLO模型的目标检测与识别实现在ESP32-S3上全流程部署","text":"项目环境安装ESP-IDF安装ESP-IDF 5.0+ 的版本有较大改动，在部署过程中会出现一些问题，建议使用 4.4 版本的进行安装。基于 Windows 平台的软件安装，可以参考 https://dl.espressif.com/dl/esp-idf/. 按照流程完成安装即可。 开发环境本项目整体开发环境主要基于训练框架，以及对应esp32的模型部署框架，具体如下： 训练、转换模型: Model Assistant 模型部署: sscma-example-esp32(1.0.0) 运行环境123456789101112131415161718192021222324python3.10 + CUDA11.7 + esp-idf 4.4# 主要按照 ModelAssistant/requirements_cuda.txt 进行安装torch 2.0.0+cu117torchaudio 2.0.1+cu117torchvision 0.15.1+cu117yapf 0.40.2typing_extensions 4.5.0tensorboard 2.13.0tensorboard-data-server 0.7.2tensorflow 2.13.0keras 2.13.1tensorflow-estimator 2.13.0tensorflow-intel 2.13.0tensorflow-io-gcs-filesystem 0.31.0sscma 2.0.0rc3setuptools 60.2.0rich 13.4.2Pillow 9.4.0mmcls 1.0.0rc6mmcv 2.0.0mmdet 3.0.0mmengine 0.10.1mmpose 1.2.0mmyolo 0.5.0 conda 的环境依赖主要见上面各种库的版本，其中 mmcv 库安装mmcv 库的安装需要对应 cuda 版本、torch 版本以及 python 版本，具体说明：cu117，torch2.0.0，python3.10可以参考https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html，对应其中主要根据操作系统选择性安装，./mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl 和 ./mmcv-2.0.1-cp310-cp310-win_amd64.whl 文件，具体如下， 训练数据集准备开源 VOC 数据集从官网下载 VOC2007数据集，并解压到指定目录 data中，利用下面代码将 VOC 格式的标注文件转换为对应 COCO 格式的 json 文件。 训练选取的类别主要有，[&quot;person&quot;, &quot;cellphone&quot;, &quot;cup&quot;, &quot;table&quot;, &quot;chair&quot;]，其中对于 person 类别主要采用 VOC2007数据集训练，而 &quot;cellphone&quot;, &quot;cup&quot;, &quot;table&quot;, &quot;chair&quot; 类别均额外收集了对应的数据集进行汇总，具体汇总方法见下文。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import osimport jsonimport pandas as pdfrom xml.etree import ElementTree as ETfrom PIL import Imageimport shutilimport randomfrom tqdm import tqdm# Set pathsvoc_path = 'data/VOCdevkit/VOC2007'train_path = 'datasets/collection/train'valid_path = 'datasets/collection/valid'# Create directories if not existif not os.path.exists(train_path): os.makedirs(train_path)if not os.path.exists(valid_path): os.makedirs(valid_path)# training classesclasses = [&quot;person&quot;, &quot;cellphone&quot;, &quot;cup&quot;, &quot;table&quot;, &quot;chair&quot;]# Get list of image filesimage_files = os.listdir(os.path.join(voc_path, 'JPEGImages'))random.seed(0)random.shuffle(image_files)# Split data into train and validtrain_files = image_files[:int(len(image_files)*0.8)]valid_files = image_files[int(len(image_files)*0.8):]# Convert train data to COCO formattrain_data = {'categories': [], 'images': [], 'annotations': []}train_ann_id = 0train_cat_id = 0img_id = 0train_categories = {}for file in tqdm(train_files): # Add annotations xml_file = os.path.join(voc_path, 'Annotations', file[:-4] + '.xml') tree = ET.parse(xml_file) root = tree.getroot() for obj in root.findall('object'): category = obj.find('name').text if category not in classes: continue if category not in train_categories: train_categories[category] = train_cat_id train_cat_id += 1 category_id = train_categories[category] bbox = obj.find('bndbox') x1 = int(bbox.find('xmin').text) y1 = int(bbox.find('ymin').text) x2 = int(bbox.find('xmax').text) y2 = int(bbox.find('ymax').text) width = x2 - x1 height = y2 - y1 ann_info = {'id': train_ann_id, 'image_id': img_id, 'category_id': category_id, 'bbox': [x1, y1, width, height], 'area': width*height, 'iscrowd': 0} train_data['annotations'].append(ann_info) train_ann_id += 1 if len(root.findall('object')): image_id = img_id img_id += 1 image_file = os.path.join(voc_path, 'JPEGImages', file) shutil.copy(image_file, os.path.join(train_path, file)) img = Image.open(image_file) image_info = {'id': image_id, 'file_name': file, 'width': img.size[0], 'height': img.size[1]} train_data['images'].append(image_info)# Add categoriesfor category, category_id in train_categories.items(): train_data['categories'].append({'id': category_id, 'name': category}) 添加自定义数据集主要的数据集可以从开源的 Roboflow Universe 搜集，比如我们需要识别某些类别，可以在该网站上下载对应的数据集，下载格式选择 COCO 格式，如下图所示： 挑选多个类别数据集后，需要对其进行合并，在上面 VOC2007 数据集处理的基础上，利用下述代码进行合并（主要合并 json 文件，各类别数据集的图像文件直接移动即可）： 12345678910111213141516171819202122232425262728293031323334353637383940414243# Add class datadef add_coco_class_data(dataset_path, classname, img_id, train_ann_id, category_id): with open(os.path.join(dataset_path, '_annotations.coco.json'), 'r') as file: class_data = json.load(file) class_exist, class_id = False, None for item in train_data['categories']: if item['name'] == classname: class_exist, class_id = True, item['id'] if class_exist is False: category_id += 1 class_id = category_id train_data['categories'].append({'id': category_id, 'name': classname}) print(train_data['categories']) # add the class images for the train data image_id = img_id for image in class_data['images']: image_info = {'id': img_id, 'file_name': image['file_name'], 'width': image['width'], 'height': image['height']} train_data['images'].append(image_info) img_id += 1 # add the class annotations for the train data for ann in class_data['annotations']: ann_info = {'id': train_ann_id, 'image_id': image_id+ann['image_id'], 'category_id': class_id, 'bbox': ann['bbox'], 'area': ann['area'], 'iscrowd': ann['iscrowd']} train_data['annotations'].append(ann_info) train_ann_id += 1 return img_id, train_ann_id, category_id# process the extra datasetchair_path = './Dataset/Collection/deteksi kursi.v1i.coco/train'phone_path = './Dataset/Collection/cellphone.v1i.coco/train'cup_path = './Dataset/Collection/cups detection.v1i.coco/train'table_path_1 = './Dataset/Collection/Detect Tables.v1i.coco/train'table_path_2 = './Dataset/Collection/T4bl3.v1i.coco/train'img_id, train_ann_id, category_id = add_coco_class_data(chair_path, &quot;chair&quot;, img_id, train_ann_id, category_id)img_id, train_ann_id, category_id = add_coco_class_data(phone_path, &quot;cellphone&quot;, img_id, train_ann_id, category_id)img_id, train_ann_id, category_id = add_coco_class_data(cup_path, &quot;cup&quot;, img_id, train_ann_id, category_id)img_id, train_ann_id, category_id = add_coco_class_data(table_path_1, &quot;table&quot;, img_id, train_ann_id, category_id)img_id, train_ann_id, category_id = add_coco_class_data(table_path_2, &quot;table&quot;, img_id, train_ann_id, category_id) 随后保存训练数据文件， 123# Save train data to filewith open(os.path.join(train_path, '_annotations.coco.json'), 'w') as f: json.dump(train_data, f, indent=4) 对于测试数据集，处理方式与训练数据集类似，汇总如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Convert valid data to COCO formatvalid_data = {'categories': [], 'images': [], 'annotations': []}valid_ann_id = 0img_id = 0for file in tqdm(valid_files): # Add annotations xml_file = os.path.join(voc_path, 'Annotations', file[:-4] + '.xml') tree = ET.parse(xml_file) root = tree.getroot() for obj in root.findall('object'): category = obj.find('name').text if category not in classes: continue category_id = train_categories[category] bbox = obj.find('bndbox') x1 = int(bbox.find('xmin').text) y1 = int(bbox.find('ymin').text) x2 = int(bbox.find('xmax').text) y2 = int(bbox.find('ymax').text) width = x2 - x1 height = y2 - y1 ann_info = {'id': valid_ann_id, 'image_id': img_id, 'category_id': category_id, 'bbox': [x1, y1, width, height], 'area': width*height, 'iscrowd': 0} valid_data['annotations'].append(ann_info) valid_ann_id += 1 if len(root.findall('object')): # Add image image_id = img_id img_id += 1 image_file = os.path.join(voc_path, 'JPEGImages', file) shutil.copy(image_file, os.path.join(valid_path, file)) img = Image.open(image_file) image_info = {'id': image_id, 'file_name': file, 'width': img.size[0], 'height': img.size[1]} valid_data['images'].append(image_info)# Add categoriesvalid_data['categories'] = train_data['categories']def add_coco_class_data_val(dataset_path, classname, img_id, train_ann_id, category_id): with open(os.path.join(dataset_path, '_annotations.coco.json'), 'r') as file: class_data = json.load(file) class_exist, class_id = False, None for item in valid_data['categories']: if item['name'] == classname: class_exist, class_id = True, item['id'] if class_exist is False: category_id += 1 class_id = category_id valid_data['categories'].append({'id': category_id, 'name': classname}) print(valid_data['categories']) # add the class images for the train data image_id = img_id for image in class_data['images']: image_info = {'id': img_id, 'file_name': image['file_name'], 'width': image['width'], 'height': image['height']} valid_data['images'].append(image_info) img_id += 1 # add the class annotations for the train data for ann in class_data['annotations']: ann_info = {'id': train_ann_id, 'image_id': image_id+ann['image_id'], 'category_id': class_id, 'bbox': ann['bbox'], 'area': ann['area'], 'iscrowd': ann['iscrowd']} valid_data['annotations'].append(ann_info) train_ann_id += 1 return img_id, train_ann_id, category_id# process the extra datasetchair_path = './Dataset/Collection/deteksi kursi.v1i.coco/valid'phone_path = './Dataset/Collection/cellphone.v1i.coco/valid'cup_path = './Dataset/Collection/cups detection.v1i.coco/valid'table_path_1 = './Dataset/Collection/Detect Tables.v1i.coco/valid'table_path_2 = './Dataset/Collection/T4bl3.v1i.coco/valid'img_id, valid_ann_id, category_id = add_coco_class_data_val(chair_path, &quot;chair&quot;, img_id, valid_ann_id, category_id)img_id, valid_ann_id, category_id = add_coco_class_data_val(phone_path, &quot;cellphone&quot;, img_id, valid_ann_id, category_id)img_id, valid_ann_id, category_id = add_coco_class_data_val(cup_path, &quot;cup&quot;, img_id, valid_ann_id, category_id)img_id, valid_ann_id, category_id = add_coco_class_data_val(table_path_1, &quot;table&quot;, img_id, valid_ann_id, category_id)img_id, valid_ann_id, category_id = add_coco_class_data_val(table_path_2, &quot;table&quot;, img_id, valid_ann_id, category_id)# Save valid data to filewith open(os.path.join(valid_path, '_annotations.coco.json'), 'w') as f: json.dump(valid_data, f, indent=4) 下载预训练模型参考 Face Detection - Swift-YOLO 下载预训练模型权重文件 pretrain.pth，然后保存在 ModelAssistant/checkpoints 文件夹下。 训练 YOLO 模型在 ModelAssistant 项目下，采用 yolov5_tiny 的配置文件进行训练，训练命令如下： 12345678910# training the yolo modelpython tools/train.py configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\--cfg-options \\ work_dir=work_dirs/collection_tiny_ep300 \\ num_classes=5 \\ epochs=300 \\ height=96 \\ width=96 \\ data_root=datasets/collection/ \\ load_from=checkpoints/pretrain.pth 导出模型训练完毕后，采用以下命令导出模型： 123456789# export the modelpython tools/export.py configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ./work_dirs/collection_tiny_ep300/best_coco_bbox_mAP_epoch_300.pth --cfg-options \\ work_dir=work_dirs/collection_tiny_ep300 \\ num_classes=5 \\ epochs=300 \\ height=96 \\ width=96 \\ data_root=datasets/collection/ \\ load_from=checkpoints/pretrain.pth 导出的模型会保存在 work_dirs/collection_tiny_ep300 文件夹下，生成 best_coco_bbox_mAP_epoch_300_int8.tflite 文件，这是量化到 Int8 格式的tflite 文件，可以用于后续模型的部署。 References esp32-s3训练自己的数据进行目标检测、图像分类","link":"/projects/DeployYOLOModel/"},{"title":"Double Prompt Learners: Classifier and Discriminator Mechanisms for Noisy Label Learning","text":"研究背景预训练-微调范式 (Pre-Training and Fine-Tuning(PT-FT)) 已经成为自然语言处理和多模态领域中的主流，针对视觉语言模型，通过提示学习微调预训练模型适配下游数据集已经被广泛地证明有非常好的泛化性能。然而对于大量各异的下游任务场景 (图像分类、识别、分割等任务)，精细地筛选数据集以及采用大量样本学习将会是模型迁移应用的局限之处，因此我们旨在探索一种**借助少样本学习适应下游噪声数据集并且能够通过不断学习增强模型性能的鲁棒性提示学习机制**，甚至可以应用到通过模型与环境不断的交互作用，既不用采集大量样本学习，也无需精细挑选数据集，这对模型泛化和迁移性能提供了极大便利。 研究领域 Noisy Label Learning Few-shots Learning Prompt Learning Visual Language Models(VLMs) 研究基础 数据：下游任务数据集存在噪声（标注错误）; 模型：Visual Language Models (VLMs); 目标：在有噪音的下游任务上学习一个 Robust 的模型; 方式：fine-tune pre-trained model，few-shots learning; 相关工作PTNL, Robust To Noisy LabelsVisual-Language Models Findings 固定的类 Tokens 对模型优化能够提供强有力的约束作用； 提示学习能够抑制噪声样本的梯度更新； 预训练的图像文本嵌入为图像分类提供了强有力的先验知识； Conclusions CLIP 本身具有一定的噪声鲁棒性； CLIP 对下游任务具有强有力的先验知识； VLM-CPL, Vision-Language Models-Consensus Pseudo LabelsFramework 利用VLM的零样本推理获得基于提示的伪标签； 在特征空间中对样本进行聚类获得基于特征的伪标签； 构造提示-特征共识伪标签划分噪声数据集进行训练； Strength 通过数据增强获取单个样本的多个预测标签； 引入标签共识增强噪声样本划分的置信度； Problems 数据增强不会解决预训练模型对某些类别的偏好作用; 数据增强的样本数以及可信样本过滤的比例需要手动设置; Hungarian Matching 会引入额外的误差，使得伪标签不够准确; 激励分析 如何构造多个决策体，使得集成决策的策略能够缓解或避免单个模型的偏好作用； 如何利用 VLMs 的预训练知识筛选噪声样本以及伪标签增强； Double Prompt LearnersCLIP 利用类别提示特征与图像特征之间的余弦相似度进行分类，最大的潜力在于 CLIP 预训练在通用大规模数据集上，能够表现出较好的泛化性能，由于其庞大的学习参数以及多样的通用知识，CLIP 被证明本身便具有一定的噪声鲁棒性。我们设想扩展 CLIP 的文本提示空间以能够引导对噪声样本和干净样本的筛选，即基于CLIP构建分类器与判别器，通过相互学习来不断增强模型性能。 CLIP 分类器根据之前的探究，我们发现对每个类别设定多个提示词能够进一步缓解由于上下游数据集领域不同带来的偏差作用，典型的有类别偏置。这种提示集成策略有利于对样本分类提供更加可信的特征相似度，对样本噪声的鲁棒性也会更强。 Prompts 设置 对每一个 class 设置多个提示词，即 PT1: [&lt; a photo of &gt; &lt; class &gt;] PT2: [&lt; a photo of &gt; &lt; class &gt;] … PTm: [&lt; a photo of &gt; &lt; class &gt;] CLIP 判别器Prompts 设置 对每一个 class 设置噪声样本提示与干净样本提示，即 [&lt; a clean photo of &gt; &lt; class &gt;] [&lt; a noisy photo of &gt; &lt; class &gt;] Framework 特点分析 模型的作用 Prompt Learner A 用于下游任务的分类预测，分类器； Prompt Learner B 用于噪声样本筛选以及标签更正，判别器； 模型学习动力 前提是 A 有一定可信度的预测能力，预训练的 CLIP 足以满足； 通过 A 的预测标签对比原有标签，对 B 提供筛选标签； B 筛选样本后获得的标签更新 A； Learner A 与 Learner B 相互增强 Learner A 学习能力增强，使得分类更准确，提供给 B 的监督作用越强； Leaner B 筛选噪声样本能力更强，提供给 A 的标签就更准确； ExperimentsRequirementsTo accelerate training double prompt learners and abalation experinments, we used two GPUs: RTX 2080-Ti and construct the shell codes template for running only once. Screen 0 123screen -S cuda0cd scriptsbash train_exp0.sh ssdtd Screen 1 123screen -S cuda1cd scriptsbash train_exp1.sh ssdtd Shell CodesWe configure all experiments in a shell script so that it’s very convenient to conduct Validation Experiments and Ablation Experiment. After running experiments, the script immediately did result analysis. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!/bin/bashDATASET=$1# Experiments: Training for DPL# Configuration# --- dataset: Dtd# --- noise rate: 0 | 12.5% | 25% | 50%# --- backbone: Text: ViT-B/32-PT, Visual: RN50-PT CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 8# Experiments: Abalation Study for DPL# Configuration# --- weight parameter beta: 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5# --- dataset: Dtd# --- noise rate: 0 | 12.5% | 25% | 50%# --- backbone: Text: ViT-B/32-PT, Visual: RN50-PT# --- prompt blocks m: 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.0 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.0 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.0 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.0 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.1 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.1 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.1 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.1 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.2 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.2 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.2 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.2 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.3 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.3 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.3 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.3 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.4 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.4 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.4 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.4 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 8# Experiments: Abalation Study for DPL# Configuration# --- prompt blocks m: 2 | 4# --- dataset: Dtd# --- noise rate: 0 | 12.5% | 25% | 50%# --- backbone: Text: ViT-B/32-PT, Visual: RN50-PT# --- weight parameter beta: 0.5CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init 0.5 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init 0.5 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init 0.5 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init 0.5 8CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 0CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 2CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 4CUDA_VISIBLE_DEVICES=0 bash dpl_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5 8# Experiments: Result Analysis for DPL# Configuration# --- Experiments: Training for DPLCUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5# Configuration# --- Experiments: Abalation Study for DPL -- weight parameterCUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.0CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.1CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.2CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.3CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.4CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init 0.5# Configuration# --- Experiments: Abalation Study for DPL -- prompt blocksCUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init 0.5 ResultsAbalation Study for DPL – prompt blocks $m$ dataset: Dtd noise rate: 0 | 12.5% | 25% | 50% backbone: Text: ViT-B/32-PT, Visual: RN50-PT weight parameter $\\beta$: 0.5 Prompt Blocks$m$ Noise Rate Noise Rate Noise Rate Noise Rate 0 12.5% 25% 50% PTNL 62.86% 58.90% 53.62% 46.19% 1 63.10% +- 0.83% 61.58% +- 0.25% 60.40% +- 1.40% 53.65% +- 0.47% 2 63.26% +- 0.60% 60.78% +- 0.56% 60.62% +- 0.89% 54.59% +- 1.28% 4 63.51% +- 0.94% 61.37% +- 0.71% 59.97% +- 0.88% 54.73% +- 0.89% 6 63.06% +- 0.41% 60.93% +- 0.66% 59.91% +- 1.06% 54.43% +- 1.90% dataset: Caltech101 noise rate: 0 | 12.5% | 25% | 50% backbone: Text: ViT-B/32-PT, Visual: RN50-PT weight parameter $\\beta$: 0.5 Prompt Blocks$m$ Noise Rate Noise Rate Noise Rate Noise Rate MeanAcc 0 12.5% 25% 50% PTNL 90.65% 82.51% 78.70% 70.13% 80.50% 1 91.33% +- 0.29% 90.48% +- 0.57% 88.93% +- 0.17% 85.37% +- 1.87% 89.03% 2 91.37% +- 0.17% 90.82% +- 0.17% 89.36% +- 0.47% 84.12% +- 2.33% 88.92% 4 91.25% +- 0.65% 90.68% +- 0.14% 89.16% +- 0.04% 84.41% +- 2.72% 88.88% Abalation Study for DPL – weight parameter $\\beta$ dataset: Dtd noise rate: 0 | 12.5% | 25% | 50% backbone: Text: ViT-B/32-PT, Visual: RN50-PT prompt blocks $m$: 4 $\\beta$ Noise Rate Noise Rate Noise Rate Noise Rate MeanAcc 0 12.5% 25% 50% PTNL 62.86% 58.90% 53.62% 46.19% 55.39% 0.0 62.37% +- 0.36% 61.21% +- 0.49% 59.44% +- 2.08% 53.65% +- 0.98% 59.17% 0.1 62.51% +- 0.41% 60.96% +- 0.91% 59.99% +- 1.19% 53.23% +- 0.93% 59.17% 0.2 63.02% +- 0.27% 61.17% +- 0.97% 60.87% +- 0.68% 53.59% +- 2.33% 59.66% 0.3 62.67% +- 0.41% 61.15% +- 0.93% 59.83% +- 1.12% 55.16% +- 1.40% 59.70% 0.4 63.59% +- 0.77% 61.39% +- 0.85% 60.13% +- 0.39% 55.18% +- 2.15% 60.07% 0.5 63.51% +- 0.94% 61.37% +- 0.71% 59.97% +- 0.88% 54.73% +- 0.89% 59.89% 0.6 62.37% +- 0.75% 61.39% +- 0.98% 59.89% +- 1.64% 53.19% +- 1.94% 59.21% 0.7 62.86% +- 0.65% 61.03% +- 0.77% 59.95% +- 1.43% 53.86% +- 0.27% 59.43% 0.8 62.96% +- 0.33% 60.28% +- 0.90% 59.93% +- 0.89% 53.05% +- 3.58% 59.06% 0.9 62.49% +- 0.31% 61.05% +- 0.33% 59.48% +- 0.96% 53.03% +- 1.61% 59.01% 1.0 63.10% +- 0.39% 60.22% +- 0.48% 59.18% +- 1.12% 51.91% +- 2.52% 58.60% dataset: Caltech101 noise rate: 0 | 12.5% | 25% | 50% backbone: Text: ViT-B/32-PT, Visual: RN50-PT prompt blocks $m$: 4 $\\beta$ Noise Rate Noise Rate Noise Rate Noise Rate MeanAcc 0 12.5% 25% 50% PTNL 90.65% 82.51% 78.70% 70.13% 80.50% 0.0 90.90% +- 0.34% 90.56% +- 0.29% 90.17% +- 0.18% 88.67% +- 0.25% 90.07% 0.1 91.02% +- 0.30% 90.92% +- 0.11% 90.29% +- 0.52% 88.94% +- 0.61% 90.29% 0.2 90.90% +- 0.21% 90.97% +- 0.28% 90.24% +- 0.19% 88.75% +- 0.73% 90.21% 0.3 91.04% +- 0.25% 90.40% +- 0.15% 90.01% +- 0.14% 88.56% +- 0.67% 90.00% 0.4 91.00% +- 0.42% 90.72% +- 0.18% 89.93% +- 0.17% 87.75% +- 0.90% 89.85% 0.5 91.25% +- 0.65% 90.68% +- 0.14% 89.16% +- 0.04% 84.41% +- 2.72% 88.88% 0.6 91.07% +- 0.21% 90.45% +- 0.30% 88.63% +- 0.63% 83.02% +- 2.72% 88.29% 0.7 90.86% +- 0.24% 90.57% +- 0.30% 88.69% +- 0.19% 83.08% +- 3.39% 88.30% 0.8 91.14% +- 0.36% 90.52% +- 0.29% 89.55% +- 0.52% 81.42% +- 1.66% 88.16% 0.9 90.98% +- 0.02% 90.18% +- 0.59% 88.92% +- 0.42% 83.48% +- 1.10% 88.39% 1.0 91.25% +- 0.37% 90.64% +- 0.30% 89.24% +- 0.58% 84.46% +- 0.75% 88.90% Raw MaterialsModel traning logs can be found in the log.txt under each experimental directory. Parsing results can be found in the following files: Dataset: Dtd DPL RN50_EP50_16SHOTS_1BLOCK_0.5BETA ON Dtd DPL RN50_EP50_16SHOTS_2BLOCK_0.5BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.0BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.1BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.2BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.3BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.4BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.5BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.6BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.7BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.8BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_0.9BETA ON Dtd DPL RN50_EP50_16SHOTS_4BLOCK_1.0BETA ON Dtd DPL RN50_EP50_16SHOTS_6BLOCK_0.5BETA ON Dtd Dataset: Caltech101 DPL RN50_EP50_16SHOTS_1BLOCK_0.5BETA ON Caltech101 DPL RN50_EP50_16SHOTS_2BLOCK_0.5BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.0BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.1BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.2BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.3BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.4BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.5BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.6BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.7BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.8BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_0.9BETA ON Caltech101 DPL RN50_EP50_16SHOTS_4BLOCK_1.0BETA ON Caltech101 References C. Wu et al. Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels? In ICCV, 2023 L. Zhong et al. VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Human Annotation-Free Pathological Image Classification. In CVPR, 2024","link":"/projects/DoublePromptLearners/"},{"title":"Robust Similarity from Vision-Language Models for Learning with Noisy Labels","text":"研究背景预训练-微调范式 (Pre-Training and Fine-Tuning(PT-FT)) 已经成为自然语言处理和多模态领域中的主流，针对视觉语言模型，通过提示学习微调预训练模型适配下游数据集已经被广泛地证明有非常好的泛化性能。然而对于许多下游任务场景，获取的数据往往具有很大的噪声，采用的人工标注和校正方法将会耗费大量时间成本，并且针对模型快速迁移应用的需求，我们旨在探索一种对噪声鲁棒性更强并且采用少样本学习的鲁棒性提示学习机制，能够更好地微调视觉语言模型适配到下游数据集。 研究领域 Noisy Label Learning Few-shots Learning Prompt Learning Visual Language Models(VLMs) 研究基础 数据：下游任务数据集存在噪声（标注错误）； 模型：Visual Language Models (VLMs)； 目标：在有噪音的下游任务上学习一个 Robust 的模型； 方式：fine-tune pre-trained model，few-shots learning； 研究激励 如何构造多个决策体，使得集成决策的策略能够缓解或避免单个模型的偏好作用； 如何利用样本特征获取样本的潜在标签，辅助决策； Double Similarities Supervision For Filtering Noisy Samples Prompt Similarities By Matrix Learners Step 1：对每个类别构造 $m$ 个提示块形成一个提示矩阵； Step 2：利用 frozen encoders 在多个决策体指导下获得每个样本的特征矩阵； Step 3：集成所有决策体的决策获得每个样本的 prompt-similarity; Feature Similarities By Mutual Distance Step 1：利用visual encoder 提取所有图像样本的特征； Step 2：依据 noisy labels 对提取的特征进行分组； Step 3：计算每个类别中各样本的相互距离矩阵，得到单个样本的 feature-distance; Step 4：最小化相互距离，即最大化类间相似度，feature-similarity = - feature-distance; Robust Similarity Construction样本提示相似度非常依赖于CLIP的预测能力，在迁移到下游任务初期，模型性能需要进一步提高，其标签预测可信度较低，而样本特征之间的关联性能直接反映噪声样本和干净样本的差别（相对于大多数干净样本的联合特征分布，噪声样本的特征分布显得较为独立，具有差异较大的均值和方差）。因此我们构建基于两者性能平衡的鲁棒性相似度，即在模型学习能力和样本特征潜在结构之间实现 trade-off： $$G_i = \\alpha \\cdot \\tilde{y_i} + (1-\\alpha) \\cdot g_i, \\ \\ \\ \\ \\ \\ (i=1,…,D)\\newline\\alpha=0.2\\cdot e^{epoch/35}\\sim(0.2, 0.8325)$$ 训练初期，模型学习能力较弱，伪标签可信度较低，鲁棒性相似度主要来源于样本潜在结构形成的特征相似度； 训练后期，模型学习能力渐渐提高，伪标签可信度较高，鲁棒性相似度主要来源于模型集成预测的提示相似度； How to runRequirementsOnly for the purpose of verifying the model principles, we just used one GPU: RTX 2080-Ti and trained the prompt learner. The following codes is my constructed shell codes for running only once. Screen 0 123screen -S cuda0cd scriptsbash train_exp0.sh ssdtd Shell CodesWe configure all experiments in a shell script so that it’s very convenient to conduct Validation Experiments and Ablation Experiment. After running experiments, the script immediately did result analysis. 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashDATASET=$1TAG=$2# Experiments: Training for POMA# Configuration# --- dataset: Dtd# --- prompt blocks m: 1 | 2 | 4 | 6# --- noise rate: 0 | 12.5% | 25% | 50%# --- backbone: Text: ViT-B/32-PT, Visual: RN50-PTCUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 1 False True rn50_random_init${TAG} 0CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 1 False True rn50_random_init${TAG} 2CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 1 False True rn50_random_init${TAG} 4CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 1 False True rn50_random_init${TAG} 8CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init${TAG} 0CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init${TAG} 2CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init${TAG} 4CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init${TAG} 8CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init${TAG} 0CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init${TAG} 2CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init${TAG} 4CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init${TAG} 8CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 6 False True rn50_random_init${TAG} 0CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 6 False True rn50_random_init${TAG} 2CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 6 False True rn50_random_init${TAG} 4CUDA_VISIBLE_DEVICES=0 bash poma_train.sh ${DATASET} rn50_ep50 end 16 16 6 False True rn50_random_init${TAG} 8# Experiments: Result Analysis for POMA# Configuration# --- Experiments: Training for POMACUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 1 False True rn50_random_init${TAG}CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 2 False True rn50_random_init${TAG}CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 4 False True rn50_random_init${TAG}CUDA_VISIBLE_DEVICES=0 bash parse_test.sh ${DATASET} rn50_ep50 end 16 16 6 False True rn50_random_init${TAG} ResultsAbalation Study for POMA – prompt blocks dataset: Dtd noise rate: 0 | 12.5% | 25% | 50% backbone: Text: ViT-B/32-PT, Visual: RN50-PT Prompt Blocks Noise Rate Noise Rate Noise Rate Noise Rate MeanAcc 0 12.5% 25% 50% PTNL 62.86% 58.90% 53.62% 46.19% 55.39% 1 61.90% +- 1.29% 59.77% +- 1.02% 57.68% +- 0.76% 49.39% +- 0.31% 57.19% 2 62.73% +- 1.00% 60.92% +- 0.45% 59.65% +- 1.50% 49.84% +- 0.89% 58.28% 4 62.80% +- 0.51% 62.61% +- 0.91% 60.56% +- 0.41% 52.40% +- 1.10% 59.59% 6 63.95% +- 0.54% 62.77% +- 0.59% 61.17% +- 1.02% 53.74% +- 1.67% 60.41% Raw MaterialsModel traning logs can be found in the log.txt under each experiment directory. Parsing results can be found in the following files: Dataset: Dtd POMA RN50_EP50_16SHOTS_1BLOCK ON Dtd POMA RN50_EP50_16SHOTS_2BLOCK ON Dtd POMA RN50_EP50_16SHOTS_4BLOCK ON Dtd POMA RN50_EP50_16SHOTS_6BLOCK ON Dtd Conclusions prompt matrix 能够有效地缓解模型偏好的作用，能够进一步提高CLIP的在下游任务上的表现，并且在高噪声情况下性能提升更为明显； 构建的鲁棒性相似度能够更好地结合模型特性和样本特征结构，实现更好的迁移性能和噪声鲁棒性。 References C. Wu et al. Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels? In ICCV, 2023 K. Zhou et al. Learning to Prompt for Vision-Language Models. In CVPR, 2021","link":"/projects/DoubleSimilarities/"},{"title":"Design of A Micro Computer System","text":"IntroductionThis weekend I undertook a project to design a micro computer system taking the example of traffic signal lights system. My Report Contributors Zhihao Li","link":"/projects/MicroComputerSystem/"},{"title":"Micro Controller Design Based on VHDL","text":"一、实验目的 掌握微控制器功能及工作原理； 掌握微控制器与其他模块信号之间的关联性。 二、实验要求 将指令分解为基本的微命令序列，把操作控制信号编制成微指令，存放到控制存储器 (CM)； 程序运行时，从控存中取出微指令，产生指令运行所需的操作控制信号。 三、实验方案及工作原理微程序控制器基本结构 在该实验中，微程序控制器主要由控制存储器CM、微指令寄存器$\\mu$IR、微地址形成电路、微地址寄存器$\\mu$AR模块组成，其中各模块功能分析如下： 控制存储器CM：存放不同机器指令对应的微程序； 微指令寄存器$\\mu$IR：存放现行微指令； 微地址形成电路：提供下一条微命令对应的微地址； 微地址寄存器$\\mu$AR：存在现在微地址； 控制信号汇总PC 模块（4条） LD_PC: in std_logic; – 装载新地址 M_PC: in std_logic; –PC 加 1 控制信号 nPCH, nPCL: in std_logic; –PC 输出总线控制信号 ROM 模块（2条） M_ROM: in std_logic; –ROM 片选信号 ROM_EN: in std_logic; –ROM 使能信号 IR 模块（4 条） LD_IR1,LD_IR2,LD_IR3: in std_logic; –IR 指令存储控制信号 nARen :in std_logic; –IR 中 RAM 地址控制信号 RN 模块（4 条） Ri_CS: in std_logic; –RN 选择信号 Ri_EN :in std_logic; –RN 寄存器使能 RDRi,WRRi :in std_logic; –RN 读写信号 ALU 模块（13 条） M_A,M_B :in std_logic; –暂存器控制信号 M_F :in std_logic; –程序状态字控制信号 nALU_EN :in std_logic; –ALU 运算结果输出使能 nPSW_EN :in std_logic; –PSW 输出使能 C0 :in std_logic; –进位输入 S:in std_logic_vector(4 downto 0); –运算类型和操作选择 F_in:in std_logic_vector(1 downto 0); –移位功能选择 RAM 模块（3 条） RAM_CS :in std_logic; –RAM 片选信号 nRAM_EN :in std_logic; –RAM 输出使能信号 wr_nRD :in std_logic; – 读写信号 控制信号设计 39条控制信号（39位编码） 27条指令（5位编码） 微指令编码设计 根据实验手册，设计 48 位的微指令各编码段如上图所示，对应所有控制信号和寄存器； 取指公操作：微程序入口地址 00H 该微指令的入口地址为 00H，当指令寄存器加载地址 00H时会将该条取指指令加载出来形成取指操作；同理，可以设计出其他所有的微指令； 微程序设计MOV Ri, #data：微程序入口地址 24H 一条机器指令MOV操作被分解为3条微指令，形成一个微程序； 该段微程序入口地址为 24H，即当执行该条机器指令时，首先由取指共操作取出该条指令，然后根据 IR 寄存器进入到改微程序入口，开始顺序执行每一条微指令； 微程序执行完毕后，再次回到 00H，重新进行取指公操作，得到下一条机器指令对应的微程序； 故此，可以根据指令编码以及机器指令执行特点设计出每一条机器指令对应的微程序，然后根据微程序进行实验验证； 四、实验配置微程序设计在本次实验中，为了进一步验证微控制器工作原理，我设计了3条机器指令：sub Ri, Rj; add Ri，Rj; and Ri, Rj. 其对应的微指令编码如下所示： 1234567891011121314151617000000000011000100011001111100110111100000000000 --003119F378 00(00h)100000000011000100011001111100110111100100000010 --803119F379 02(01h) sub ri, rj 100000000011000100110001111100110111101100000011 --803131F37B 03(02h)100000000011000100010001011100110111011100000100 --8031117377 04(03h)100000000011000100010001011100110111011100000101 --8031117377 05(04h)100000000011000101110001111100110111101100000110 --803171F37B 06(05h)100000000011000100110011111100110111101100000111 --803133F37B 07(06h)100000000011000100110000111100110111101100001000 --803130F37B 08(07h)100000000011000100110001111100110111100000000000 --803131F378 00(08h)100000000011000100011001111100110010000100001010 --803119F321 0A(09h) add ri, rj100000000011000100110001111100110010001000001011 --803131F322 0B(0Ah)100000000011000100010001011100110010001100001100 --8031117323 0C(0Bh)100000000011000100010001011100110010010000000000 --8031117324 00(0Ch)100000000011000101110001111100110011000100001110 --803171F331 0E(0Dh) and ri, rj100000000011000100110011111100110011001000001111 --803133F332 0F(0Eh)100000000011000100110000111100110011001100010000 --803130F333 10(0Fh)100000000011000100110001111100110011010000000000 --803131F334 00(10h) 微控制器功能设计针对微控制器的工作原理，在本次实验中设计的功能如下所示： 复位功能：当复位信号有效时，微控制器进行复位，所有寄存器均不存储数据； 使能信号：只有该信号高电平有效时，微控制器才能够正常工作，否则一直保持刚取得的微指令； 指令跳转：该功能使得微控制器可以根据 IR 寄存器中的地址，获取下一条微指令的地址，这使得微控制器可以跳转到不同机器指令的微程序入口，然后继续顺序执行； 指令执行：该功能保证微控制在进入微程序后获取相应的微指令后，可以根据地址译码电路自动获得下一条微指令的地址； 五、实验源码顶层模块设计12345678910111213141516171819202122232425262728293031323334353637383940414243444546library IEEE;use IEEE.STD_LOGIC_1164.ALL;entity micro isPort (clk, rst : in std_logic; seg_sel : out std_logic_vector(15 downto 0); seg_data : out std_logic_vector(7 downto 0); clk_mc,m_ua,cmrom_cs:in std_logic; ir:in std_logic_vector(7 downto 2) );end micro;architecture Behavioral of micro issignal showw:std_logic_vector(63 downto 0);component state isPort (clk, rst : in std_logic; key_in:in std_logic_vector(15 downto 0); seg_sel : out std_logic_vector(15 downto 0); seg_data : out std_logic_vector(7 downto 0); show:in std_logic_vector(63 downto 0) );end component;component micro_controller isPort (clk_mc,m_ua,cmrom_cs:in std_logic; ir:in std_logic_vector(7 downto 2); arr:out std_logic_vector(7 downto 0); next_arr:out std_logic_vector(7 downto 0); cm:out std_logic_vector(47 downto 8) );end component;begin u1: state port map(clk=&gt;clk, rst=&gt;rst, seg_sel=&gt;seg_sel, seg_data=&gt;seg_data, show=&gt;showw, key_in=&gt;x&quot;ffff&quot;); u2: micro_controller port map(clk_mc=&gt;clk, m_ua=&gt;m_ua, cmrom_cs=&gt;cmrom_cs, ir=&gt;ir, cm=&gt;showw(39 downto 0), next_arr =&gt; showw(47 downto 40), arr=&gt;showw(55 downto 48));end Behavioral; 微控制器模块设计12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061library IEEE;use IEEE.STD_LOGIC_1164.ALL;entity micro_controller isPort (clk_mc,m_ua,cmrom_cs:in std_logic; ir:in std_logic_vector(7 downto 2); arr:out std_logic_vector(7 downto 0); next_arr:out std_logic_vector(7 downto 0); cm:out std_logic_vector(47 downto 8) );end micro_controller;architecture Behavioral of micro_controller is component cmrom is Port (m_rom,nrom_en:in std_logic; addr:in std_logic_vector(7 downto 0); data:out std_logic_vector(47 downto 0) ); end component;signal uar:std_logic_vector(7 downto 0) := (others =&gt; '0');signal uir:std_logic_vector(47 downto 0);signal clkk:std_logic;begin cm1:cmrom port map(m_rom=&gt;cmrom_cs, nrom_en=&gt;'0', addr=&gt;uar, data=&gt;uir); cm &lt;= uir(47 downto 8); -- 控制字段 next_arr &lt;= uir(7 downto 0); -- 下条地址字段 arr &lt;= uar; -- 当前地址 -- clkk 50000000 process(clk_mc) variable count: integer range 0 to 60000000; begin if clk_mc'event and clk_mc='1' then count:=count+1; if count=50000000 then clkk&lt;=not clkk; count:=0; end if; end if;end process;process(m_ua,clkk) begin if rising_edge(clkk) then if cmrom_cs = '1' then if m_ua = '1'then uar(5 downto 0) &lt;= ir; uar(7 downto 6) &lt;= &quot;00&quot;; elsif m_ua='0' then uar&lt;=uir(7 downto 0); end if; end if; end if;end process;end Behavioral; 控制存储器模块设计123456789101112131415161718192021222324252627282930313233library IEEE;use IEEE.STD_LOGIC_1164.ALL;use IEEE.STD_LOGIC_UNSIGNED.ALL;use IEEE.STD_LOGIC_TEXTIO.ALL;use std.textio.all;entity cmrom isPort (m_rom,nrom_en:in std_logic; addr:in std_logic_vector(7 downto 0); data:out std_logic_vector(47 downto 0) );end cmrom;architecture Behavioral of cmrom istype matrix is array(integer range&lt;&gt;) of std_logic_vector(47 downto 0);signal rom:matrix (0 to 2**8-1);procedure load_rom (signal data_word:out matrix) is file romfile:text open read_mode is &quot;D:\\zhli\\project_15\\ucode.txt&quot;; variable lbuf:line; variable i:integer:=0; variable fdata:std_logic_vector(47 downto 0);beginwhile not endfile(romfile) loop readline(romfile,lbuf); read(lbuf,fdata); data_word(i)&lt;=fdata; i:=i+1;end loop;end procedure;begin load_rom(rom); data&lt;=rom(conv_integer(addr));end Behavioral; 数码管显示模块设计1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374library IEEE;use IEEE.STD_LOGIC_1164.ALL;use ieee.std_logic_unsigned.all;entity state isPort (clk, rst : in std_logic; key_in : in std_logic_vector(15 downto 0); seg_sel : out std_logic_vector(15 downto 0); seg_data : out std_logic_vector(7 downto 0); show:in std_logic_vector(63 downto 0) );end state;architecture Behavioral of state istype states is (s0,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15);signal state,next_state:states;signal show1: std_logic_vector(3 downto 0);signal rsts,clks: std_logic;signal cc: std_logic;signal showw:std_logic_vector(63 downto 0);component data2seg isPort (data_in:in std_logic_vector(3 downto 0); seg_data:out std_logic_vector(7 downto 0));end component;beginu: data2seg port map(data_in=&gt;show1, seg_data=&gt;seg_data); process(clk) variable count: integer range 0 to 30000; begin if clk'event and clk='1' then count:=count+1; if count=20000 then cc&lt;=not cc; count:=0; end if; end if; end process; process(cc,clk,rst) --复位和状态转移 begin if rst='1' then state&lt;=s0; showw&lt;=x&quot;0000000000000000&quot;; elsif cc'event and cc='1' then showw&lt;=show; state&lt;=next_state; end if; end process; process(state) begin case state is --数码管输出 when s0=&gt;if key_in(0)='1' then seg_sel&lt;=x&quot;fffe&quot;; show1&lt;=showw(3 downto 0); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s1; when s1=&gt;if key_in(1)='1' then seg_sel&lt;=x&quot;fffd&quot;; show1&lt;=showw(7 downto 4); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s2; when s2=&gt;if key_in(2)='1' then seg_sel&lt;=x&quot;fffb&quot;; show1&lt;=showw(11 downto 8); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s3; when s3=&gt;if key_in(3)='1' then seg_sel&lt;=x&quot;fff7&quot;; show1&lt;=showw(15 downto 12); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s4; when s4=&gt;if key_in(4)='1' then seg_sel&lt;=x&quot;ffef&quot;; show1&lt;=showw(19 downto 16); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s5; when s5=&gt;if key_in(5)='1' then seg_sel&lt;=x&quot;ffdf&quot;; show1&lt;=showw(23 downto 20); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s6; when s6=&gt;if key_in(6)='1' then seg_sel&lt;=x&quot;ffbf&quot;; show1&lt;=showw(27 downto 24); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s7; when s7=&gt;if key_in(7)='1' then seg_sel&lt;=x&quot;ff7f&quot;; show1&lt;=showw(31 downto 28); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s8; when s8=&gt;if key_in(8)='1' then seg_sel&lt;=x&quot;feff&quot;; show1&lt;=showw(35 downto 32); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s9; when s9=&gt;if key_in(9)='1' then seg_sel&lt;=x&quot;fdff&quot;; show1&lt;=showw(39 downto 36); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s10; when s10=&gt;if key_in(10)='1' then seg_sel&lt;=x&quot;fbff&quot;; show1&lt;=showw(43 downto 40); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s11; when s11=&gt;if key_in(11)='1' then seg_sel&lt;=x&quot;f7ff&quot;; show1&lt;=showw(47 downto 44); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s12; when s12=&gt;if key_in(12)='1' then seg_sel&lt;=x&quot;efff&quot;; show1&lt;=showw(51 downto 48); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s13; when s13=&gt;if key_in(13)='1' then seg_sel&lt;=x&quot;dfff&quot;; show1&lt;=showw(55 downto 52); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s14; when s14=&gt;if key_in(14)='1' then seg_sel&lt;=x&quot;bfff&quot;; show1&lt;=showw(59 downto 56); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s15; when s15=&gt;if key_in(15)='1' then seg_sel&lt;=x&quot;7fff&quot;; show1&lt;=showw(63 downto 60); else seg_sel&lt;=x&quot;ffff&quot;; end if; next_state&lt;=s0; end case; end process;end Behavioral; 数码管译码模块设计1234567891011121314151617181920212223242526272829303132333435library IEEE;use IEEE.STD_LOGIC_1164.ALL;entity data2seg isPort (data_in:in std_logic_vector(3 downto 0); seg_data:out std_logic_vector(7 downto 0));end data2seg;architecture Behavioral of data2seg isbegin process(data_in) begin case data_in is when x&quot;0&quot;=&gt;seg_data&lt;=x&quot;c0&quot;; when x&quot;1&quot;=&gt;seg_data&lt;=x&quot;f9&quot;; when x&quot;2&quot;=&gt;seg_data&lt;=x&quot;a4&quot;; when x&quot;3&quot;=&gt;seg_data&lt;=x&quot;b0&quot;; when x&quot;4&quot;=&gt;seg_data&lt;=x&quot;99&quot;; when x&quot;5&quot;=&gt;seg_data&lt;=x&quot;92&quot;; when x&quot;6&quot;=&gt;seg_data&lt;=x&quot;82&quot;; when x&quot;7&quot;=&gt;seg_data&lt;=x&quot;f8&quot;; when x&quot;8&quot;=&gt;seg_data&lt;=x&quot;80&quot;; when x&quot;9&quot;=&gt;seg_data&lt;=x&quot;90&quot;; when x&quot;a&quot;=&gt;seg_data&lt;=x&quot;88&quot;; when x&quot;b&quot;=&gt;seg_data&lt;=x&quot;83&quot;; when x&quot;c&quot;=&gt;seg_data&lt;=x&quot;c6&quot;; when x&quot;d&quot;=&gt;seg_data&lt;=x&quot;a1&quot;; when x&quot;e&quot;=&gt;seg_data&lt;=x&quot;86&quot;; when x&quot;f&quot;=&gt;seg_data&lt;=x&quot;8e&quot;; end case; end process;end Behavioral; 六、仿真配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263library IEEE;use IEEE.STD_LOGIC_1164.ALL;entity micro_sim is -- Port ( clk : in STD_LOGIC);end micro_sim;architecture Behavioral of micro_sim iscomponent micro isPort (clk, rst : in std_logic; seg_sel : out std_logic_vector(15 downto 0); seg_data : out std_logic_vector(7 downto 0); clk_mc,m_ua,cmrom_cs:in std_logic; ir:in std_logic_vector(7 downto 2) );end component;signal clk, rst,clk_mc,m_ua,cmrom_cs: std_logic := '0';signal seg_sel: std_logic_vector(15 downto 0) := (others=&gt;'0');signal seg_data: std_logic_vector(7 downto 0) := (others=&gt;'0');signal ir: std_logic_vector(7 downto 2) := (others=&gt;'0');constant clk_period : time := 10 ns;begin Micro_Instance: micro port map( clk =&gt; clk, rst =&gt; rst, seg_sel =&gt; seg_sel, seg_data =&gt; seg_data, clk_mc =&gt; clk_mc, m_ua =&gt; m_ua, cmrom_cs =&gt; cmrom_cs, ir =&gt; ir); clk &lt;= not clk after clk_period / 2; -- clk production clk_mc &lt;= not clk_mc after clk_period * 8; -- clk production process begin cmrom_cs &lt;= '1'; -- reset firstly rst &lt;= '1'; wait for clk_period * 16; rst &lt;= '0'; -- load the first instruction m_ua &lt;= '0'; wait for clk_period * 16; -- load ir register m_ua &lt;= '1'; ir &lt;= &quot;000001&quot;; wait for clk_period * 16; -- run sequencely m_ua &lt;= '0'; wait for clk_period * 48; cmrom_cs &lt;= '0'; end process; end Behavioral; 七、实验结果仿真结果本次实验中，我通过使用数码管来显示微控制器的功能作用，其中各数码管的功能解释如下： 0-1数码管：未使用，默认显示为00； 2-3数码管：显示当前微指令地址； 4-5数码管：显示下一天微指令地址； 6-15数码管：显示微指令的控制字段； 系统复位状态 当系统复位时，即 rst = 1，系统输出为最低为数码管显示 0 其余关闭； 取指令公操作 根据仿真结果可以看出，其16个数码管的编码值依次为 00 00 00 003119F378，微控制器默认处于取指令操作，所以该条指令下一条微指令仍然回到取指操作； IR实现指令跳转 根据仿真结果可以看出，其16个数码管的编码值依次为 00 01 02 8031717379，m_ua为高电平，将 IR=01H 对应地址的微指令加载到当前控制器中，所以显示正在执行当前地址为 01 的微指令，其下一条微指令的地址为 02H； 指令顺序执行 根据仿真结果可以看出，当一个微程序执行完毕后，微控制器再次返回到取指操作对应的微指令，等待进入下一条机器指令对应的微程序入口。 板级验证根据实验进一步验证，可知功能完全正确，如下图示为 IR 加载地址为 03H 的的微指令然后顺序执行一段微程序的结果。","link":"/projects/MicroController/"},{"title":"Transformer Concept Exploration and Practice in Pytorch","text":"IntroductionTransformer 是一种广泛应用与自然语言处理的神经网络架构，它基于自注意力机制，允许模型在做出预测时为句子中的不同单词赋予不同的重要性。它非常擅长处理序列任务，并且具有并行计算的优势，因此在大规模数据集上训练时非常高效。序列任务是任何将输入序列进行变换得到输出序列的任务，例如 machine translation, text summarization, and question answering. 而这种序列模型往往具有编码-解码的模型架构，Transformer 亦是如此：编码器将输入的符号序列映射为提取的连续特征表示，而解码器负责一次生成一个符号，并在每一步将之前生成的符号再次添加到输入以此生成下一个符号，又称为自回归模型。 这种依赖于过去和当前的输入的任务，也被称为因果语言建模 (causal language modeling)。 在这篇文章中，我将探索对 Transformer 结构的学习以及在机器翻译任务上用Pytorch全流程实现Transformer。 Understanding of TheoriesTokenizer &amp; Embedding我们需要从原点出发理解整个处理过程，给定一个自然语言序列，需要做的工作包括对自然语言序列进行分词以及词嵌入，能够将自然语言的单词转换为Transformer模型需要处理的向量化表示。如下图所示，自然语言单词通过语法规则构造出规范的语句，而自然语句通过分词器将语句分级为 tokens，有时候为了处理方便，也会将自然语言单词进行拆分构成不同的token，这取决于分词器的实现。 分词后的tokens序列主要用来构造模型学习的语料库，而词嵌入 embedding 则是将tokens序列转换为连续的向量表示 embeddings，以便模型能够处理整个语句。经过这种变换后，自然语言单词能够转换为浮点数构成的数值向量，这不仅考虑了token的特异性，而且数值能够表示不同token之前的联系，即语境信息。 这种处理方式使得模型能够处理人类的自然语言，并且能够捕捉到不同单词之间的语义关系。 在数据管理器中，基于 torchtext 实现了用于文本分词的 tokenizer 以及对应的 Vocabulary. 整体的流程是，通过预训练的 tokenizer 将输入的文本进行分词，并将单个 token 输出为 token_id，进一步通过输入的语料库来构建词汇表，在词汇表中可以通过 token_id 查找对应的 embedding，这是作为单词在句子中特殊语义的标记。 一些特殊的 token 标记： PAD_IDX：由于在一个 batch 中不同的语句所转换后的 tokens 长度不一，为了能够统一转换为矩阵，需要对这些语句进行对齐，可以理解为以最长的 tokens 序列为标准，以一个特殊的标记填充其他语句。 EOS_IDX: 有填充就必定要有语句结束标记，指定一个语句在哪个位置已经结束。 BOS_IDX: 标记句子的开始，一般是以该 token 为解码器输入，然后逐渐生成我们想要的其他 tokens，所以可以认为这是解码器的特殊启动标记。 Data Manager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112&quot;&quot;&quot;@author: Zhihao Li@date: 2024-11-11@homepage: https://zhihaoli.top/&quot;&quot;&quot;import iofrom collections import Counterimport torchfrom torch.nn.utils.rnn import pad_sequencefrom torch.utils.data import DataLoaderimport torchtexttorchtext.disable_torchtext_deprecation_warning()from torchtext.data.utils import get_tokenizerfrom torchtext.vocab import vocabfrom torchtext.utils import extract_archiveclass DataManeger: &quot;&quot;&quot; A integrated data manager with builded tokenizer and vocabulary. &quot;&quot;&quot; def __init__(self, src_mode, tgt_mode, data_path): &quot;&quot;&quot; Args: src_mode: source natural language, ('en': English, 'de': Deutsch / German', 'cs': Čeština / Czech, 'fr': Français / French). tgt_mode: target natural language, ('en': English, 'de': Deutsch / German', 'cs': Čeština / Czech, 'fr': Français / French). data_path: the path of dataset. &quot;&quot;&quot; self.src_mode = src_mode self.tgt_mode = tgt_mode self.tokenize_src = get_tokenizer('spacy', language=src_mode) self.tokenize_tgt = get_tokenizer('spacy', language=tgt_mode) train_urls = ('train.'+ src_mode +'.gz', 'train.'+ tgt_mode +'.gz') val_urls = ('val.'+ src_mode +'.gz', 'val.'+ tgt_mode +'.gz') test_urls = ('test_2016_flickr.'+ src_mode +'.gz', 'test_2016_flickr.'+ tgt_mode +'.gz') self.train_filepaths = [extract_archive(data_path + url)[0] for url in train_urls] self.val_filepaths = [extract_archive(data_path + url)[0] for url in val_urls] self.test_filepaths = [extract_archive(data_path + url)[0] for url in test_urls] self.src_vocab = self.build_vocab(self.tokenize_src, self.train_filepaths[0]) self.tgt_vocab = self.build_vocab(self.tokenize_tgt, self.train_filepaths[1]) self.src_vocab.set_default_index(self.src_vocab['&lt;unk&gt;']) self.tgt_vocab.set_default_index(self.tgt_vocab['&lt;unk&gt;']) def make_dataset(self): &quot;&quot;&quot; Process out the data through their zip files. &quot;&quot;&quot; train_data = self.data_process(self.train_filepaths) val_data = self.data_process(self.val_filepaths) test_data = self.data_process(self.test_filepaths) return train_data, val_data, test_data def build_vocab(self, tokenizer, train_filepath): &quot;&quot;&quot; Build the corresponding vocabulary for the two languages. &quot;&quot;&quot; counter = Counter() with io.open(train_filepath, encoding=&quot;utf8&quot;) as f: for string_ in f: counter.update(tokenizer(string_)) return vocab(counter, specials=['&lt;unk&gt;', '&lt;pad&gt;', '&lt;bos&gt;', '&lt;eos&gt;']) def data_process(self, filepaths): &quot;&quot;&quot; Create the input_id tensors using tokenizer and vocabulary. &quot;&quot;&quot; raw_src_iter = iter(io.open(filepaths[0], encoding=&quot;utf8&quot;)) raw_tgt_iter = iter(io.open(filepaths[1], encoding=&quot;utf8&quot;)) data = [] for (raw_src, raw_tgt) in zip(raw_src_iter, raw_tgt_iter): src_tensor = torch.tensor([self.src_vocab[token] for token in self.tokenize_src(raw_src)], dtype=torch.long) tgt_tensor = torch.tensor([self.tgt_vocab[token] for token in self.tokenize_tgt(raw_tgt)], dtype=torch.long) data.append((src_tensor, tgt_tensor)) return data def make_iter(self, train, validate, test, batch_size): &quot;&quot;&quot; Create the iterater for sub-dataset using collection function. &quot;&quot;&quot; train_iter = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=self.generate_batch) valid_iter = DataLoader(validate, batch_size=batch_size, shuffle=False, collate_fn=self.generate_batch) test_iter = DataLoader(test, batch_size=batch_size, shuffle=False, collate_fn=self.generate_batch) return train_iter, valid_iter, test_iter def generate_batch(self, data_batch): &quot;&quot;&quot; Construct the batch input_id tensors, add the bos and eos tokens and padding the sentence. &quot;&quot;&quot; SRC_PAD_IDX, TGT_PAD_IDX = self.src_vocab['&lt;pad&gt;'], self.tgt_vocab['&lt;pad&gt;'] SRC_BOS_IDX, TGT_BOS_IDX = self.src_vocab['&lt;bos&gt;'], self.tgt_vocab['&lt;bos&gt;'] SRC_EOS_IDX, TGT_EOS_IDX = self.src_vocab['&lt;eos&gt;'], self.tgt_vocab['&lt;eos&gt;'] src_batch, tgt_batch = [], [] for (src_item, tgt_item) in data_batch: src_batch.append(torch.cat([torch.tensor([SRC_BOS_IDX]), src_item, torch.tensor([SRC_EOS_IDX])], dim=0)) tgt_batch.append(torch.cat([torch.tensor([TGT_BOS_IDX]), tgt_item, torch.tensor([TGT_EOS_IDX])], dim=0)) # padding the sentence using PAD_IDX src_batch = pad_sequence(src_batch, padding_value=SRC_PAD_IDX) tgt_batch = pad_sequence(tgt_batch, padding_value=TGT_PAD_IDX) return src_batch.t(), tgt_batch.t() Position Embedding 并行处理 其实可以发现，transformer 是并行处理一个语句中的所有 tokens，因为它同时接受这些 tokens 作为输入，接着直接计算注意力分数。 位置信息 不同的 token 在语句的不同位置是语法体现，因此需要明确位置信息。 因此仅仅是单个 token 的嵌入向量，并不能表示在语句中的位置关系，这就需要额外引入能够表示 token 在语句中的位置信息。而位置信息需要满足的要求有如下两点， It should be the same for a position irrespective of the token in that position. So while the sequence might change, the positional embeddings must stay the same. [1] They should not be too large, or otherwise they will dominate semantic similarity. [1] 函数选取Position Embedding 不能够太大以免破坏 token 本身的语义信息。因此对于非周期函数例如线性函数，因为值域是无限的，并不容易控制随着维度增大引起的值域增大。 较好的选择就是正余弦函数，它们的值域都缩放在 [-1, 1] 之间，连续且具有周期性。相比于 sigmoid 函数对较大的数基本已经保持平稳，三角函数能够对较大的数具有较大变换幅度，这对于处理长序列是非常有用的。 为了避免三角函数对于不同位置重复相同的结果，给定三角函数一个较低的频率，即具有较大的周期，这将对于最长的序列长度也不会不断重复。频率低就意味着相邻位置变化幅度比较小，这也不是我们想要的，因此对位置编码的奇数维度叠加低频 sine 函数，而对偶数维度叠加低频 cosine 函数。 对于一个单词的嵌入向量：torch.size([1, 512])，其中 512 嵌入向量的奇数位置采用低频 sine 函数，偶数位置采用低频 cosine 函数，这样能够保证每个单词的嵌入向量都包含位置信息。 $$\\begin{aligned}PE(pos, 2i) &amp;= \\sin(\\frac{pos}{1000^{2i/d_{model}}})\\newlinePE(pos, 2i+1)&amp; = \\cos(\\frac{pos}{1000^{2i/d_{model}}})\\end{aligned}$$ 从上图可以看到，这种交叉位置编码平衡了单独两个余弦函数的特性，能够在相邻位置保持变化性，并且对于长序列的位置编码也不会出现大量重复值。 对比交叉、正弦以及余弦位置编码可以看出，交叉位置编码在不同维度是不断变化的，而单独的正弦和余弦函数都出现了较为平滑的区域，即变换幅度都基本不变。 12345678910111213141516171819202122class PositionalEncoding(nn.Module): # Implement the position encoding (PE) function. def __init__(self, d_model, dropout, max_len=5000): super(PositionalEncoding, self).__init__() self.dropout = nn.Dropout(p=dropout) # Compute the positional encodings once in log space. pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len).unsqueeze(1) div_term = torch.exp( torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model) ) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0) self.register_buffer(&quot;pe&quot;, pe) def forward(self, x): # adds token embedding to its position embedding x = x + self.pe[:, : x.size(1)].requires_grad_(False) return self.dropout(x) Encoder编码器负责从输入的 token 序列中提取出语义特征，其结构如下图所示： Residual Connection 残差连接是将该层的输入向量直接传递到输出而不做任何处理，并将其加到该层处理后得到的输出向量上面。这是一项简单高效的技术用于处理深度神经网络梯度消失的问题，以 ResNet 网络之名提出. Layer Normalization 层归一化是在每层中对所有样本的输出进行规范化，而不是对每个批次进行规范化。如下图中对比，Layer Norm 对于单个样本的所有特征进行规范化，使得层内神经元输出的分布具有稳定的均值和方差。 在 Transformer 中是对每个 token 形成的 embedding 进行规范化，而不是对整个序列进行规范化。 然后使用可学习的参数（如 $\\beta$ 和$\\gamma$）对归一化后的输出进行缩放和平移。这样既可以保持数据的分布稳定性，又可以保留一定的灵活性。形式化的表示为： $$ \\text{LN}(x) = \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta $$ 其中，$x$ 是输入向量，$\\mu$ 和 $\\sigma$ 是输入向量的均值和标准差，$\\epsilon$ 是一个很小的常数，用于防止除以零，$\\gamma$ 和 $\\beta$ 是可学习的参数。 在 Transformer 中，对于层归一化可以放置在 Attention 层和前馈神经网络层之后，也可以放置在它们之后。最初的 Transformer 论文中，层归一化采取的是第一种方法，但被证明很难训练到梯度收敛，而第二种方法训练时变得更加稳定且收敛更快。[1] Layer Normalization12345678910111213class LayerNorm(nn.Module): &quot;Construct a layer norm module &quot; def __init__(self, d_model, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(d_model)) self.b_2 = nn.Parameter(torch.zeros(d_model)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.a_2 * (x - mean) / (std + self.eps) + self.b_2 Multi-Head Attention多头注意力机制实际上是包含多个自注意力头的一种机制，每个头都独立地学习输入序列中的不同模式。多头注意力机制可以捕获更多的信息，并且可以更好地处理长距离依赖关系。多头注意力机制的结构如下图所示： 其中，$d_{model}$ 是设定的每个 embedding 所包含的特征数量，实际上对于该超参数的设定，有时候并不清楚是否特征表示冗余（即浪费了很多特征块），或者是特征表示不足（即特征块不够）。 面对这样的问题，与其单独计算一个有着冗余风险的超大自注意力头，不如将这些所有特征分组成 $h$ 组，每组包含 $d_{model}/h$ 个特征，然后分别对每组进行自注意力计算，最后将所有组的输出拼接起来。这样能够保证每个子注意力头完成一个子任务，即捕获子模式：不同位置和不同特征的信息，从而更好地处理输入序列中的复杂关系。 Self-Head Attention子注意力头主要是关注于序列本身中每个token与序列中其他token的依赖关系以及相似度，计算的注意力也成为：Scaled dot-product attention。 首先，将序列的嵌入特征表示投影成不同的三个向量，记为 query, key and value。然后计算注意力分数，通过测量 query 和 key 的点积来衡量 query 和 key 之间的相似度。这是因为点积可以衡量向量之间的相似性，如果非常接近则点积结果会有一个较大的值。一个有 $n$ 个 token 的序列来计算相互之间的相似度，即 Pairwise Similarity 将会得到 $n\\times n$ 的注意力分数。 在获得注意力分数之后，因为点积结果是两个高维向量相乘并求和的结果，取值范围属于无限大，如果直接参与后续计算，势必会扰乱特征信息。因此，需要对注意力分数进行缩放，即除以 $\\sqrt{d_k}$，其中 $d_k$ 是 key 的维度。然后通过 softmax 将其转换为注意力权重，这样做的目的是为了平衡不同维度之间的差异，使得计算结果更加稳定。 真正表示 token 语义的一直是 value 向量，通过构建的 query 和 key 只是获取 token 之间的注意力权重，然后对 value 向量中的每一个 token 进行加权求和，可以得到依赖于目前学习到的 token 间语义关系的加权平均的嵌入特征表示。这里有两个特定词，希望给出一些个人的理解： 目前学习到的可以看到，对 query, key and value 的投影矩阵都是不断学习的参数，transformer 训练过程中，会不断通过学习调整 query, key 以提取更加准确的 token 间的语义依赖关系，这也会是 value 向量再次更新的关键，等到学习基本完毕时，我们可以任务，value 向量已经集成了之前所探寻得到的语义关系，代表了能够真正理解这句话的真实含义。 加权平均的注意到注意力权重是通过 softmax 归一化的相似度分数，即对于注意力权重形如 $L\\times L$，其中 $L$ 表示序列长度，每一行都表示对应的 token 与序列中其他 token 的语义关系（相似性），这样作用于 value 向量时，都会根据注意力分数提取其他相似的 token 的语义信息，从而得到一个加权平均的语义表示。 因此更加具体的实现还是自注意力头，假设输入的嵌入向量表示为 $E\\in R^{B\\times L\\times D}$，其中 $B$ 表示批次大小，$L$ 表示序列长度，$D$ 表示每个 token 被编码表示的向量长度，那么具体的计算过程如下： $$\\begin{aligned}\\text{Q} &amp;= \\text{W}_Q E \\in R^{B\\times L\\times D} \\newline\\text{K} &amp;= \\text{W}_K E \\in R^{B\\times L\\times D} \\newline\\text{V} &amp;= \\text{W}_V E \\in R^{B\\times L\\times D} \\newline\\text{Attention}(Q,K,V) &amp;= \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{D}}\\right)V\\end{aligned}$$ 当采用多头注意力机制后，还需要对拼接每个子注意力头得到的注意力分数进行线性变换，这是因为多头注意力机制不仅学习序列的注意力特征，而且学习每一个子注意力头对注意力分数的贡献程度，具体计算如下：$$\\begin{aligned}\\text{MultiHead}(Q,K,V) &amp;= \\text{Concat}(\\text{head}_1, \\text{head}_2, \\ldots, \\text{head}_h)W^O \\newline\\text{where} \\quad \\text{head}_i &amp;= \\text{Attention}(Q, K, V)\\end{aligned}$$ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def attention(query, key, value, mask=None, dropout=None): &quot;Compute 'Scaled Dot Product Attention'&quot; d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) p_attn = scores.softmax(dim=-1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attnclass MultiHeadedAttention(nn.Module): def __init__(self, n_head, d_model, dropout=0.1): # Take in model size and number of heads. super(MultiHeadedAttention, self).__init__() assert d_model % n_head == 0 # We assume d_v always equals d_k self.d_k = d_model // n_head self.n_head = n_head self.linears = clones(nn.Linear(d_model, d_model), 4) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): nbatches = query.size(0) # Do all the linear projections in batch from d_model =&gt; n_head x d_k query, key, value = [ lin(x).view(nbatches, -1, self.n_head, self.d_k).transpose(1, 2) for lin, x in zip(self.linears, (query, key, value)) ] # Apply attention on all the projected vectors in batch. x, self.attn = attention( query, key, value, mask=mask, dropout=self.dropout ) # Concat using a view and apply a final linear. x = ( x.transpose(1, 2) .contiguous() .view(nbatches, -1, self.n_head * self.d_k) ) return self.linears[-1](x) Feed-Forward Network前馈神经网络就是一个简单的两层全连接层，通常第一层的隐藏层大小设置为 $4d_{model}$，并且使用 ReLU 作为激活函数，具体实现如下： 12345678910111213class FeedForward(nn.Module): def __init__(self, d_model, d_ff=2048, dropout=0.1): super().__init__() # We set d_ff as a default to 2048 self.linear_1 = nn.Linear(d_model, d_ff) self.dropout = nn.Dropout(dropout) self.linear_2 = nn.Linear(d_ff, d_model) def forward(self, x): x = self.dropout(F.relu(self.linear_1(x))) return self.linear_2(x) Decoder解码器的任务是不断地生成文本，还记得上文中提到的，BOS_IDX token 这个特殊的 token 标记句子的开始，可以先理解为解码器最开始输入的句子就是只有一个开始标记，然后不断地往下生成 $n$ 个单词，组成一句完整的话。但是对于 Transformer 而言，由于其强大的并行处理能力，实际上是通过对目标句子加阶梯型掩码（表示token生成的顺序），然后通过注意力机制不断得到一个加权平均的嵌入向量。实际上，这个嵌入向量表示就是 transformer 生成的目标句子，而且是一次性生成的。 由于代码结果解释性比较强，为了深入地揭示 what happened 在 Decoder 中，下文主要结合代码执行结果进行说明。 Decoder 输入的目标语句信息从下面可以看到，目标语句长度 padding 到了 40 tokens 而且对应的每一个序列的第一个 token 都是 bos，说明在处理的时候 Decoder 还是以 bos 开始处理。 1234567891011121314151617181920&gt;&gt;&gt; target sentence length: 40&gt;&gt;&gt; target bos token id: 2&gt;&gt;&gt; target eos token id: 3&gt;&gt;&gt; target pad token id: 1&gt;&gt;&gt; target first token id: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:1')&gt;&gt;&gt; target last token id: tensor([ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:1') Decoder 输入的 mask 信息Decoder 需要考虑句子生成的先后顺序，在生成第 $i$ 个 token 的时候，只能看到第 $i$ 个 token 之前的 tokens，所以需要通过 mask 来实现，因此第一个 mask 记为 padding mask，第二个 mask 记为 subsequent mask，最后需要将这两个 mask 进行想与得到总的 mask，具体如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&gt;&gt;&gt; target padding mask shape: torch.Size([128, 1, 40, 1])&gt;&gt;&gt; target padding mask:tensor([[[[ True, True, True, ..., False, False, False]]], [[[ True, True, True, ..., False, False, False]]], [[[ True, True, True, ..., False, False, False]]], ..., [[[ True, True, True, ..., False, False, False]]], [[[ True, True, True, ..., False, False, False]]], [[[ True, True, True, ..., False, False, False]]]], device='cuda:1')&gt;&gt;&gt; target sub mask shape: torch.Size([40, 40])&gt;&gt;&gt; target sub mask:tensor([[1, 0, 0, ..., 0, 0, 0], [1, 1, 0, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], ..., [1, 1, 1, ..., 1, 0, 0], [1, 1, 1, ..., 1, 1, 0], [1, 1, 1, ..., 1, 1, 1]], device='cuda:1', dtype=torch.uint8)&gt;&gt;&gt; target sentence mask shape:torch.Size([128, 1, 40, 40])&gt;&gt;&gt; target sentence mask:tensor([[[[1, 0, 0, ..., 0, 0, 0], [1, 1, 0, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]], [[[1, 0, 0, ..., 0, 0, 0], [1, 1, 0, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]], [[[1, 0, 0, ..., 0, 0, 0], [1, 1, 0, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], ..., ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]]], device='cuda:1', dtype=torch.uint8) Decoder Multi-Head Attention解码器需要考虑两个序列，一是已经生成的序列（加掩码的目标序列），另一个是编码器提取的语义特征，这是为了进行两个序列的语义对齐，尤其是将 decoder attention 作为 query，encoder attention 作为 key、value。 直观的理解 解码器向编码器提出一个查询请求，寻找下一个需要生成的 token，此时就需要比较解码器查询与编码器的特征表示的相似度，以此作为注意力分数，注意这个地方是不能在目标序列中得到下一个 token 的，因此 value 只能是编码器的 attention 输出，通过运算后这样会得到加权平均的语义特征，通过 projector 将这些语义特征投影到目标序列的词汇表中做一次分类，即可实现 token 的筛选。 特征表示层面 通过自注意力机制，解码器提取出的特征表示为 $L_1\\times D$，编码器提取出的语义特征为 $L_2\\times D$, 其中$ L_1, L_2$ 表示目标序列以及源序列的 token 长度，而 $D$ 表示每一个 token 的特征长度。实际上计算应为： $$ \\begin{aligned} L_1\\times D \\cdot D\\times L_2 &amp;= L_1\\times L_2\\newline L_1\\times L_2 \\cdot L_2\\times D &amp;= L_1\\times D \\end{aligned} $$ 通过这种交叉注意力机制，解码器的每一个 token 都能够得到一个关于源序列各个 tokens 的表示关联程度的注意力权重，通过这个注意力权重与编码器提取出的语义特征，在 token 的没一个维度上进行加权求和，这样会得到相对于源序列的语义特征，这就是最后要生成的 tokens 序列。 并行处理 一次性生成整个句子？ 其实深入地观察，可以发现，在解码器获取语义特征的过程中，施加了上面提到的掩码操作，这样就能够同时获得将要生成的 tokens 序列的位置关系，通过自注意力机制便一次性提取出所有 token 的语义特征，直接可以作为生成的 tokens 序列的特征。为了与源序列进行语义对齐，需要和编码器的语义特征计算相似度以获得源序列的注意力权重，再对源序列的语义特征进行加权平均。 Decoder12345678910111213141516171819202122232425262728293031323334353637383940class DecoderLayer(nn.Module): &quot;Decoder is made of self-attn, src-attn, and feed forward (defined below)&quot; def __init__(self, n_head, d_model, d_ff, dropout): super(DecoderLayer, self).__init__() self.d_model = d_model self.self_attn = MultiHeadedAttention(d_model=d_model, n_head=n_head) self.cross_attn = MultiHeadedAttention(d_model=d_model, n_head=n_head) self.feed_forward = FeedForward(d_model, d_ff, dropout) # 3 add &amp; norm sublayers one for self-attn, one for cross-attn and one for feed forward self.sublayer = clones(SublayerConnection(d_model, dropout), 3) def forward(self, dec, enc, src_mask, tgt_mask): &quot;Compute self attention, cross attention, positionwise feed forward network..&quot; dec = self.sublayer[0](dec, lambda dec: self.self_attn(dec, dec, dec, tgt_mask)) dec = self.sublayer[1](dec, lambda dec: self.cross_attn(dec, enc, enc, src_mask)) return self.sublayer[2](dec, self.feed_forward)class Decoder(nn.Module): &quot;Generic N layer decoder with masking.&quot; def __init__(self, dec_voc_size, max_len, n_layers, n_head, d_model, d_ff, dropout): super(Decoder, self).__init__() decoder_layer = DecoderLayer(n_head, d_model, d_ff, dropout) self.layers = clones(decoder_layer, n_layers) self.emb = Embedding(vocab_size=dec_voc_size, d_model=d_model, max_len=max_len, dropout=dropout) self.norm = LayerNorm(decoder_layer.d_model) def forward(self, tgt, enc_src, src_mask, tgt_mask): tgt = self.emb(tgt) # embedded the input_ids for layer in self.layers: tgt = layer(tgt, enc_src, src_mask, tgt_mask) return self.norm(tgt) Transformer在完成上述各模块的设计后，可以得到完整的 Transformer 模型，其结构如下： Transformer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&quot;&quot;&quot;@author: Zhihao Li@date: 2024-11-11@homepage: https://zhihaoli.top/&quot;&quot;&quot;import torchimport torch.nn as nnfrom torch.nn.functional import log_softmaxfrom model.encoder import Encoderfrom model.decoder import Decoderclass Generator(nn.Module): &quot;Define standard linear + softmax generation step.&quot; def __init__(self, d_model, vocab): super(Generator, self).__init__() self.proj = nn.Linear(d_model, vocab) def forward(self, x): return log_softmax(self.proj(x), dim=-1)class Transformer(nn.Module): &quot;&quot;&quot; A standard Transformer architecture. Base for this and many other models. &quot;&quot;&quot; def __init__(self, src_pad_idx, tgt_pad_idx, tgt_bos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len, d_ff, n_layers, dropout, device): super().__init__() self.src_pad_idx = src_pad_idx self.tgt_pad_idx = tgt_pad_idx self.tgt_bos_idx = tgt_bos_idx self.device = device self.encoder = Encoder(enc_voc_size=enc_voc_size, max_len=max_len, n_layers=n_layers, n_head=n_head, d_model=d_model, d_ff=d_ff, dropout=dropout) self.decoder = Decoder(dec_voc_size=dec_voc_size, max_len=max_len, n_layers=n_layers, n_head=n_head, d_model=d_model, d_ff=d_ff, dropout=dropout) self.generator = Generator(d_model, dec_voc_size) def forward(self, src, tgt): &quot;Take in and process masked src and target sequences.&quot; src_mask = self.make_src_mask(src) tgt_mask = self.make_tgt_mask(tgt) enc_src = self.encoder(src, src_mask) dec_tgt = self.decoder(tgt, enc_src, src_mask, tgt_mask) return self.generator(dec_tgt) def make_src_mask(self, src): &quot;&quot;&quot; Mask the padding tokens int source sentence. &quot;&quot;&quot; src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2) return src_mask def make_tgt_mask(self, tgt): &quot;&quot;&quot; Mask the padding tokens int target sentence. &quot;&quot;&quot; tgt_pad_mask = (tgt != self.tgt_pad_idx).unsqueeze(1).unsqueeze(3) tgt_len = tgt.shape[1] tgt_sub_mask = torch.tril(torch.ones(tgt_len, tgt_len)).type(torch.ByteTensor).to(self.device) tgt_mask = tgt_pad_mask &amp; tgt_sub_mask return tgt_mask Exploration From ScratchPreparationClone Project准备探索之前，需要将 TransformerPractice 项目克隆下来，可以使用如下命令克隆到本地： 1git clone https://github.com/LZHMS/TransformerPractice.git 项目中已经集成好了所有必要的模型组件并通过不同的 Trainers 串联起来，以完成特定的下游任务。 Install Conda Environment安装 conda 环境，tokenizer 使用最新的 spacy 库，其他库的版本也都是兼容下比较新的，可以通过以下命令进行环境配置： 1conda env create -f environment.yml Download the Dataset本项目使用 Multi30K Dataset 数据集训练和评估文本翻译模型，具体需要先在官网上下载数据集然后提取 task1 的所有文件，将其放置在目录 data/multi30k 下。详细目录结构可以见下文： Category Structure12345678910.├─ data│ ├─ multi30k│ │ ├─ task1│ │ │ ├─ ...├─ dataset├─ model ├─ output├─ trainer└─ model Explore the Modules对于 Transformer 处理流程的探索，可以在 Jupyter Notebook 中单步演示。 为了更好地体验，可以结合 The Transformer Architecture: A Visual Guide [2] 对比分析。 Training the Models一次性训练文本翻译器，可以通过以下命令： 1python main.py --epochs 1000 &gt; output/output.log Reference [1] Transformer: Concept and code from scratch [2] The Transformer Architecture: A Visual Guide","link":"/projects/TransformerPractice/"},{"title":"2D Virtual Try-on Based on Deep Learning","text":"(function(){var player = new DPlayer({\"container\":document.getElementById(\"dplayer0\"),\"lang\":\"en\",\"hotkey\":true,\"preload\":\"metadata\",\"video\":{\"url\":\"https://lzhms.oss-cn-hangzhou.aliyuncs.com/videos/projects/2DVirtualTryon.mp4\"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})() 项目介绍本项目主要面向第 $14$ 届全国服务外包创新创业比赛 $A16$ 赛道虚拟试衣赛题，采用 $2D$ 虚拟试衣技术依托于 $VITON$ 开源数据集训练 $DNN$ 网络并着重进行工程化落地应用；项目选用了前沿顶刊论文的 $PFAFN$ 模型，在此基础上对模型进行优化改进，实现了模型压缩和推理加速并使用 $OpenVINO$ 框架进行部署应用，出色地完成了赛题的要求。 项目开发环境 开发平台 版本 开发工具 版本 Pycharm 2022.3.2 Visual Studio Code 1.80.1 Visual Studio 17.5.5 开发环境 版本 开发环境 版本 neural-compressor 2.2.1 nncf 2.5.0 numpy 1.23.4 onnx 1.14.0 opencv-python 4.7.0.72 onnxruntime 1.15.1 openvino 2022.3.0 pandas 1.3.5 pytorch-fid 0.3.0 rembg 2.0.50 pytorch 2.0.0 torch-pruning 1.1.9 intel-openmp 2021.4.0 模型结构介绍本项目基于 $PFAFN$ 模型重新设计各个网络模块，具体结构如下图所示： 项目工程化落地为了满足赛题方的要求，本项目开展了工程化落地部分，主要分为两个部分，模型训练和模型剪枝量化。项目工程化部署总图如下所示： 项目详细技术文档 实验结果：通道剪枝 Clothe Warp Module Metrics GFLOPs Para(M) SIZE(MB) Total SIZE(MB) Compresion Ratio FID FID Loss Original Module 6.63 9.37 35.8 112.0 100.00% 8.906 0.00% Ratio=0.2 with FineTuning 5.23 7.28 27.6 88.69 79.19% 9.013 1.20% Ratio=0.3 with FineTuning 4.40 6.48 24.8 65.73 58.69% 9.113 2.32% Ratio=0.4 with FineTuning 3.79 5.61 20.4 40.97 36.58% 9.304 4.47% Ratio=0.5 with FineTuning 3.42 4.55 16.8 35.47 31.67% 9.977 12.03% Image Generation Module Metrics GFLOPs Para(M) SIZE(MB) Total SIZE(MB) Compresion Ratio FID FID Loss Original Module 21.93 43.90 167 167 100.00% 8.906 0.00% Ratio=0.2 with FineTuning 16.54 35.02 112.3 112.3 67.25% 9.212 3.44% Ratio=0.25 with FineTuning 15.45 31.93 94.39 94.39 56.52% 9.405 5.60% Ratio=0.3 with FineTuning 13.90 29.89 80.25 80.25 48.05% 9.679 8.68% Ratio=0.35 with FineTuning 12.78 27.31 73.49 73.49 44.01% 9.835 10.43% Ratio=0.4 with FineTuning 11.20 26.12 68.52 68.52 41.03% 10.527 18.20% 最优剪枝方案 Model Original Model Sparsity Pruned Model FID FPS CWM 112MB 40% 40.97MB 9.504 2.92 IGM 167MB 25% 94.39MB 9.504 2.92 实验结果：量化感知训练 Optimization CPU-FID GPU-FID Original Model Quantized Model Unquantized 9.504 9.483 135.36MB 135.36MB Quantize CWM 9.783 9.701 40.97MB 10.85MB Quantize IGM 10.382 10.249 94.39MB 24.10MB Quantize CWM &amp; IGM 11.503 11.379 135.36MB 34.95MB 实验结果：img2col 优化加速 Runtimes CorrTorch(s) Img2Col(s) FPS Acceleration Rate n=1000 147.8491 94.7902 10.81 1.5598 n=10000 1489.1325 927.4293 10.77 1.6057 Average Time 0.1488 0.029 10.79 1.6017 参考文献 Y. Ge, Y. Song, R. Zhang, C. Ge, W. Liu, and P. Luo, “Parser-Free Virtual Try-on via Distilling Appearance Flows,” arXiv preprint arXiv:2103.04559, 2021. Y. Cheng, D. Wang, P. Zhou and T. Zhang, “Model Compression and Acceleration for DeepNeural Networks: The Principles, Progress, and Challenges,” in IEEE Signal Processing Magazine,vol. 35, no. 1, pp. 126-136, Jan. 2018, doi: 10.1109/MSP.2017.2765695. PyTorch Quantization Aware Training","link":"/projects/VirtualTryon/"},{"title":"A Literature Survey about Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels","text":"I.Summary OverviewBackground: A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises.Interest: Studying the key reasons contributing to the robustness of the prompt tuning paradigm. Findings: the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. II.Research InterestsThe author studies the key reasons contributing to the robustness of the prompt tuning paradigm. III.Problems SolvedIn author’s work, they demonstrate that prompt tuning is robust to noisy labels, and investigate the mechanisms that enable this robustness. IV.Previous ResearchWhile prompt tuning has proven effective when training on downstream tasks with accurately annotated datasets, their robustness to noisy labels has been neglected. V.Author’s InnovationThe author investigates the mechanisms that enable this robustness and proposes a simple yet effective method for unsupervised prompt tuning, showing that randomly selected noisy pseudo labels can be effectively used to enhance CLIP zero-shot performance. VI.Author’s Contribution We demonstrate that prompt tuning for pre-trained vision-language models (e.g., CLIP) is more robust to noisy labels than traditional transfer learning approaches, such as model fine-tuning and linear probes. We further demonstrate that prompt tuning robustness can be further enhanced through the use of a robust training objective. We conduct an extensive analysis on why prompt tuning is robust to noisy labels to discover which components contribute the most to its robustness. Motivated by this property, we propose a simple yet effective method for unsupervised prompt tuning, showing that randomly selected noisy pseudo labels can be effectively used to enhance CLIP zero-shot performance. The proposed robust prompt tuning outperformed prior work on a variety of datasets, even though noisier pseudo-labels are used for self-training. VII.Algorithm FlowRecent Research CLIP: CLIP applies prompt engineering to incorporate the category information in the text input such that its pre-trained model can adapt to various image classification tasks without further training. CoOp: CoOp introduces learnable prompts optimized on target datasets to address CLIP’s problem ProDA: ProDA tackles CoOp’s issue by utilizing diverse prompts to capture the distribution of varying visual representations. UPL: UPL proposes a framework to perform prompt tuning without labeled data. TPT: TPT achieves zero-shot transfer by dynamically adjusting prompts using only a single test sample. Potential of prompt tuning: Label noise-robust learning Label noise-robust learning robust losses that tolerate noisy labels loss correction approaches that estimate a transition matrix to correct the predictions meta-learning frameworks that learn to correct the label noise in training examples regularization techniques that are customized to lower the negative impact of noise Existing Problems CLIP: the design of a proper prompt is challenging and requires heuristics. CoOp: CoOp has also faced criticism for disregarding the diversity of visual representations. Author’s Processing Demonstrate that prompt tuning on CLIP naturally holds powerful noise robustness. Explore the key factors behind such robustness. Show its application on unsupervised prompt tuning. Constructed Model CLIPIn the case of image classification, a normalized image embedding $\\boldsymbol{f}^v$ is obtained by passing an image $\\boldsymbol{x}$ through CLIP’s visual encoder, and a set of normalized class embeddings $[\\boldsymbol{f}^t_i]^K_{i=1}$ by feeding template prompts of the form “A photo of a “ into CLIP’s text encoder.$$Pr(y=i|\\boldsymbol{x})=\\frac{\\exp(sim(\\boldsymbol{f}^v,\\boldsymbol{f}^t_i))/\\tau}{\\sum_{j=1}^K\\exp(sim(\\boldsymbol{f}^v,\\boldsymbol{f}^t_j))/\\tau}$$ Prompt TuningThe name of a class c is first converted into a classname embedding $\\boldsymbol{w}\\in R^d$ and prepended with a sequence of $M$ learnable tokens $\\boldsymbol{p_m}\\in R^d$ shared across all classes.$$P_c=[\\boldsymbol{p_1}, \\boldsymbol{p_2}, \\cdots, \\boldsymbol{p_M}, \\boldsymbol{w_c}]\\rightarrow \\boldsymbol{f}^t_c$$CoOp optimizes the shared learnable tokens $\\boldsymbol{p_1}, \\boldsymbol{p_1}, \\cdots, \\boldsymbol{p_M}$ on a small labeled dataset $D = [(\\boldsymbol{x_i}, c_i)^N_{i=1}]$ to minimize the cross-entropy loss$$L_{CE}=-E_{(\\boldsymbol{x},c)\\in D}[\\log Pr(y=c|\\boldsymbol{x})].$$ Robust Prompt TuningFurther enhance this robustness by optimizing the learnable prompts using the generalized cross-entropy (GCE) loss$$L_{GCE}=E_{(\\boldsymbol{x},c)\\in D}[\\frac{1-Pr(y=c|\\boldsymbol{x})^q}{q}].$$ Author’s Conclusion: $q = 0.7$ leads to overall good performance across several experimental settings. VIII.Robustness Analysis Pre-trained CLIP Generates Effective Class Embeddings Author’s Conclusions: Classifier-R v.s. Classifier-C: CLIP class embeddings provide a strong initialization for few-shot learning. TEnc-FT v.s. Classifier-C: The highly expressive CLIP text encoder can easily overfit to the noisy labels. Prompt Tuning v.s. Classifiers: The text encoder is essential for providing a strong but informative regularization of the text embeddings to combat noisy inputs. Prompt Tuning v.s. TEnc-FT: The text encoder should be fixed to prevent overfitting. Effectiveness of Prompt Author’s Conclusions: Full Prompt Tuning v.s. CLS Tuning: The class embeddings generated by CLIP pre-trained text encoder plays a critical role in noise robustness. Hypothesis: The classname token $\\boldsymbol{w_c}$ provides a strong regularization to the model, since it is leveraged by the text encoder to encode relationships between the different visual concepts. Prompt Tuning Suppresses Noisy Gradients Prompt tuning can suppress gradient updates from noisy samples, while aggregating gradients from clean samples. This property likely arises from the highly constrained prompt tuning optimization, which restricting the model to fit the noisy labels. Generalization Across Model Architectures Context length The optimal context length is dataset dependent. Image encoders ViT-B/32-PT outperforms RN50-PT under most settings. Moreover, both methods do not suffer from a large performance drop and maintain competitive accuracy at high noise rates. Robustness to Correlated Label Noise Confusion noise: Each mislabeled sample is labeled as the incorrect class that is most favored by zero-shot CLIP. Author’s Conclusions: Confusion noise presents a bigger challenge to transfer learning, leading to larger degradation of classification accuracy at high noise ratios compared to random noise. Prompt tuning still achieves the best overall performance, providing further evidence for its robustness even to more challenging types of noise. IX.Application to Unsupervised Prompt Tuning Baseline UPL Phase 1: Leverage pre-trained CLIP to generate pseudo labels for unlabeled images. Phase 2: Select the $K$ most confident samples per class to optimize the learnable tokens through the typical prompt-tuning optimization process (described in CoOp). Features: UPL improved transfer performance by ensembling multiple predictions generated by models with different learnable prompts. Robust UPL Overview: Based on UPL, randomly sample $K$ training samples and optimize the prompt with the robust GCE loss X.Summary And ViewsSummaryThis paper focus on prompt tuning to research and analyze the attribution of robustness to label noise that it has naturally. And the author also combines the findings with the UPL model and proposes a more robust UPL model in unsupervised prompt tuning. Personal ViewsFirstly I learned a lot from this paper which analysis the robust of prompt tuning to label noise. This research spirit and methodology is a great need in motivating me to work on the research of robustness. And what’s impresses me most is the robust UPL model that is the author’s innovation about the previous research. XI.Domain LearningRelated Terms Vision-language model text-image embedding and image-text embedding few-shot prompt tuning fixed classname tokens zero-shot learning downstream tasks: few-shot learning, continual learning, object segmentation model-informed structure traditional fine-tuning and linear probing paradigms generalized cross-entropy (GCE) VisionLanguage Pre-Trained Models (VL-PTMs) meta-learning References Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?","link":"/readings/PINLPaperReport/"},{"title":"Literature Survey about Volumetric Grasping Network:Real-time 6 DOF Grasp Detection in Clutter","text":"摘要概述在通用机器人研究领域中，grasp detection 任务要求能够在一堆杂乱的物体中识别从未遇到过的物体以及处理物体之间的堆叠问题。作者针对此项任务提出了Volumetric Grasping Network(VGN)，以$3$D场景的Truncated Signed Distance Function(TSDF)表示作为输入，并能够对$3$D场景中的每一个体积元直接输出机器人抓取质量预测值，以及钩爪方向和张开宽度。这种方法能够在$10$ms内规划下一次抓取任务并且可以在现实世界杂乱物体中清除$92$%的物体。 研究的领域机器人控制领域需要解决灵活性问题，即在复杂环境中能够计算无限次抓取并且处理物体聚类、堆叠以及高维噪声的问题。 解决的问题在杂乱环境中规划未知物体的平行抓取问题，目标是寻找能够使得机器人成功抓取并从工作空间中移除所有物体的夹持器配置。 之前的研究最近的研究大都关注于以数据驱动的方法规划抓取任务，但是规划的能力通常在单张深度图中局限于自顶向下的抓取。这种方法将搜寻能力约束为垂直抓取，假定物体能够垂直放置并且机器人只从一个单一的方向抓取。最近比较好的一些工作能够在姿势估计上处理$6$个自由度的抓取，但是只能处理单个、孤立的物体，这使得这种方法在现实场景应用中需要额外的堆叠检测，甚至需要较高的推理时间。 作者的创新作者提出了一种新颖的方法——$6$自由度实时抓取的综合方法，算法的输入是一个采用TSDF算法重建的表面模型，其中每一个体积元都利用截断符号距离表示真实场景表面附近的区域。作者的主要创新点在于对于TSDF算法不仅是用于在$3$D场景重建中融合多个点云数据映射成连续的表面模型，还利用TSDF算法构建的规则的结构借助深度神经网络进行场景的特征学习。 如上图，作者构建了一个全卷积网络(FCN)将输入TSDF映射到一个带有解决方案的相同空间中，其中的每一个体积元都包含有预测的抓取质量、钩爪方向和张开宽度。融合的特征使得这种方法能够通过网络的一步前向传递来检测整个工作空间的抓取。物体堆叠的处理：作者假设包含整个场景的$3$D信息能够使得神经网络捕获钩爪与环境之间的冲突。New Idea: 代替以往的研究以采样和评估单个的抓取策略，作者针对整个离散的抓取策略空间中所有抓取位置进行了评估。 作者的贡献 使得$6$自由度的抓取合成方法能够实时处理 使用全部3D场景信息去直接学习无冲突的抓取策略 算法的流程最近的研究由于深度学习对于未知的物体具有非常优越的泛化能力以及能够在杂乱的场景中找到可行的抓取策略，因此机器人抓取研究中经常选择深度学习方法来检测机器人的抓取。 综合的抓取方法可以分为两大类，第一种是输出自顶向下的抓取策略(尤其是$3$或$4$自由度)，第二种是输出$6$自由度的抓取策略。自顶向下的抓取策略或者使用顶视图数据，或者是深度图数据，或者是两者的结合并且以图形结构的形式返回可行的抓取策略；$6$自由度的抓取网络以整个场景的点云或者占据网格形式表达的$3$D信息作为输入。假设：场景的点云信息能够识别空间物体的表面，假定由TSDF表示的额外的距离到表面信息能够提高整个抓取检测性能表现。因此作者认为对整个场景信息的充分利用能够使得系统考虑物体之间的物理交互作用，所以作者将整个TSDF输入给网络。通过这个策略使得最终处理场景重建和堆叠检测时不再需要进行分割处理。 存在的问题这些抓取方法基本都作为抓取质量的预测器，这要求需要一些初始化过程在抓取策略空间中进行采样评估。初始化过程是非常麻烦的，因为这需要在计算复杂度与采样覆盖范围达到最优的平衡。 作者的处理作者训练抓取网络在整个空间体积表示中对于每一个体积元直接输出一个抓取策略(抓取方向和张开宽度)以及相联系的抓取质量预测值。网络采用非局部极大值抑制方法直接输出的就是最佳的抓取策略，而不用在运行时对候选的抓取策略进行评估得到最佳抓取策略，也不需要在抓取策略空间中进行迭代寻找可行的抓取策略，这是作者建立的网络模型能够进行实时处理的很重要的原因。 问题的表述 Gripper表示 $$\\tilde{\\boldsymbol{t}} = \\frac{T_{RV}(t)}{\\boldsymbol{v}}, \\tilde{\\boldsymbol{r}}=T_{RV}(\\boldsymbol{r}), \\tilde{w}=\\frac{w}{v}$$ 其中，$\\tilde{\\boldsymbol{t}}$ 表示钩爪被定义的体积元的坐标，$\\tilde{w}$ 表示以体积元的大小为单元进行计量； 规划的目标解决该该问题的目标就是寻找一个映射关系 $$f: \\boldsymbol{V}\\rightarrow \\boldsymbol{Q}, \\boldsymbol{R}, \\boldsymbol{W}$$ 其中，$\\boldsymbol{Q}, \\boldsymbol{R}, \\boldsymbol{W}$ 包含在每一个体积元 $\\tilde{\\boldsymbol{t}}$ 上的抓取质量 $q$, 抓取方向 $\\tilde{\\boldsymbol{r}}$ 和 张开宽度 $\\tilde{w}$. 构建的模型作者构建了 Volumetric Grasping Network(VGN), 利用深度神经网络去估计深度映射关系 $f$。 网络结构VGN采用FCN结构，首先设置了一个感知模块，用于将输入空间体 $\\boldsymbol{V}$ 映射成特征图，第二部分由三个卷积层组成，交织2倍的双线性上采样，紧随三个独立的模块分别用于预测抓取质量，旋转以及张开宽度。 输出说明 抓取质量模块输出 $1\\times N^3$ 大小的体积单元，其中每一项表示在该体积单元上成功完成抓取任务的概率值。 旋转模块输出以四元组的形式表示抓取策略的方向，其中四元组选用欧拉角进行表示 张开宽度模块输出预测了每一个体积元上应当采取的张开宽度 综合训练作者训练整个网络采用端到端的方式进行训练，构建了以下损失函数： $$\\zeta(\\hat{g_i}, \\tilde{g_i}) = \\zeta_q(\\hat{q_i}, q_i)+q_i(\\zeta_r(\\hat{\\boldsymbol{r}_i}, \\tilde{\\boldsymbol{r}_i})+\\zeta_w(\\hat{w_i}, \\tilde{w_i}))$$ 其中，$q_i\\in${$0, 1$} 表示可行抓取策略的目标标签，而 $\\hat{q_i}$ 表示VGN网络的预测输出标签，$\\zeta_q$ 表示$q_i$ 和$\\hat{q_i}$ 之间的二进制交叉损失，$zeta_w$ 表示展开宽度的预测 $\\hat{w}$ 与目标 $w$ 的均方误差。对于四元组表示的抓取方向，在这里以点积的形式进行计算损失： $$\\zeta_{quat} = 1-|\\boldsymbol{\\hat{r}}\\cdot \\tilde{\\boldsymbol{r}}|$$ 由于夹持器的对称性，在旋转$180^\\circ$的配置实际上对应的是相同的抓取，但是这会导致不一致的损失信号，因为网络会因为回归到两种不同的三维旋转之一而受到惩罚，因此作者对损失函数进行了扩展： $$\\zeta_r(\\boldsymbol{\\hat{r}}, \\tilde{\\boldsymbol{r}})=\\min(\\zeta_{quat}(\\boldsymbol{\\hat{r}}, \\tilde{\\boldsymbol{r}}), \\zeta_{quat}(\\boldsymbol{\\hat{r}}, \\tilde{\\boldsymbol{r_{\\pi}}}))$$ 遗留的问题 机器人夹具形状差异的问题作者所提出的方法进一步推广应用到不同的夹具几何形状上需要通过进一步的实验来验证。 物理模拟实验局限性的问题在真实的机器人实验中，仅根据模拟数据进行训练存在一定的局限性，需要在物理模拟中引入对抗性测试进一步地去验证。 总结与思考Summary这篇论文的主要贡献在于针对通用机器人领域中抓取物体的研究提出了创新性的算法与网络模型，解决了抓取任务中物体堆叠造成的冲突问题以及因计算复杂而造成的不可实时处理的问题。作者最大的创新之处在于摆脱了以往研究中通过采样和评估来获得单次的抓取策略，提出对整个场景空间中的所有抓取位置进行评估，选取抓取质量最好的位置进行抓取。 Personal Views对体抓取网络(VGN)的一些看法，作者不仅利用TSDF结构表示场景信息，并且借助于深度神经网络设计了一个特征学习模块，从场景(TSDF)中学习空间中每个体积元的特征，并通过进一步预测抓取质量、抓取方向以及张开宽度。这三个网络模块都是以3D场景中的每个体积元中心进行抓取的，因此在实际场景中，可以利用深度传感器检测物体的空间分布，然后对于覆盖的所有体积元选择抓取质量最高的体积元来获取抓取策略。可能这就是作者提出的体抓取网络名字的由来。一些延伸想法，作者提出的VGN需要根据TSDF重建的3D场景信息计算所有的体积元，然后预测获取他们的抓取质量、抓取方向以及张开宽度；但是在场景范围比较大的时候，模型的计算量也将会是非常巨大的，并且抓取物体不仅与抓取方向和抓取宽度有关，还与在物体的某个方向施加的抓取力度有关，因此或许可以进一步在模型中考虑抓取力度对成功率的影响。","link":"/readings/VGNPaperReport/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","link":"/tags/Embedded-System/"},{"name":"Project Tools","slug":"Project-Tools","link":"/tags/Project-Tools/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Diffusion Model","slug":"Diffusion-Model","link":"/tags/Diffusion-Model/"},{"name":"AIGC","slug":"AIGC","link":"/tags/AIGC/"},{"name":"Project Habits","slug":"Project-Habits","link":"/tags/Project-Habits/"},{"name":"Mathematical Modeling","slug":"Mathematical-Modeling","link":"/tags/Mathematical-Modeling/"},{"name":"Data Visualization","slug":"Data-Visualization","link":"/tags/Data-Visualization/"},{"name":"OpenSSL","slug":"OpenSSL","link":"/tags/OpenSSL/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Research Habits","slug":"Research-Habits","link":"/tags/Research-Habits/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Computer Network","slug":"Computer-Network","link":"/tags/Computer-Network/"},{"name":"Collaboration Project","slug":"Collaboration-Project","link":"/tags/Collaboration-Project/"},{"name":"Microcomputer","slug":"Microcomputer","link":"/tags/Microcomputer/"},{"name":"Eletromagnetic Physics","slug":"Eletromagnetic-Physics","link":"/tags/Eletromagnetic-Physics/"},{"name":"Mathematical Theory","slug":"Mathematical-Theory","link":"/tags/Mathematical-Theory/"},{"name":"Microarchitecture","slug":"Microarchitecture","link":"/tags/Microarchitecture/"},{"name":"Software Engineering","slug":"Software-Engineering","link":"/tags/Software-Engineering/"},{"name":"College Life","slug":"College-Life","link":"/tags/College-Life/"},{"name":"Health","slug":"Health","link":"/tags/Health/"},{"name":"My Research","slug":"My-Research","link":"/tags/My-Research/"},{"name":"Mountain Climbing","slug":"Mountain-Climbing","link":"/tags/Mountain-Climbing/"},{"name":"Computer Graphics","slug":"Computer-Graphics","link":"/tags/Computer-Graphics/"},{"name":"Professional Knowledge","slug":"Professional-Knowledge","link":"/tags/Professional-Knowledge/"},{"name":"Life Knowledge","slug":"Life-Knowledge","link":"/tags/Life-Knowledge/"},{"name":"3D Vision","slug":"3D-Vision","link":"/tags/3D-Vision/"},{"name":"3DGS","slug":"3DGS","link":"/tags/3DGS/"},{"name":"Computer Principle","slug":"Computer-Principle","link":"/tags/Computer-Principle/"},{"name":"Deep Model Deployment","slug":"Deep-Model-Deployment","link":"/tags/Deep-Model-Deployment/"},{"name":"Object Detection","slug":"Object-Detection","link":"/tags/Object-Detection/"},{"name":"Prompt Learning","slug":"Prompt-Learning","link":"/tags/Prompt-Learning/"},{"name":"Few Shots Learning","slug":"Few-Shots-Learning","link":"/tags/Few-Shots-Learning/"},{"name":"Noisy Label Learning","slug":"Noisy-Label-Learning","link":"/tags/Noisy-Label-Learning/"},{"name":"Visual Language Models","slug":"Visual-Language-Models","link":"/tags/Visual-Language-Models/"},{"name":"Transformer","slug":"Transformer","link":"/tags/Transformer/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"Literature Survey","slug":"Literature-Survey","link":"/tags/Literature-Survey/"}],"categories":[{"name":"blog","slug":"blog","link":"/blog/"},{"name":"collaboration","slug":"collaboration","link":"/collaboration/"},{"name":"essay","slug":"essay","link":"/essay/"},{"name":"knowledge","slug":"knowledge","link":"/knowledge/"},{"name":"projects","slug":"projects","link":"/projects/"},{"name":"readings","slug":"readings","link":"/readings/"}],"pages":[{"title":"","text":"慕松柏 萧落落，衰叶已凋尽，露枝犹霜。茫茫眼下，唯翠枝两三； 雾漫漫，古村已隐尽，落山如雪。苍苍望去，只白雾一道。 于凌冬岁月，我仍傲青翠。 记于松山北上 About MeHi, I’m Zhihao Li. This is a brief introduction about me.I am a junior student at Xidian University, and my favorite research direction is 3D Vision and Digital Human. As a new blogger, I am very excited to share with you the learning experience and technical points in the major, and discuss the tricky problems in the technical field together. News @ ZHao [September, 2024] Honored with the Outstanding Student Model Award of Xidian University (Top 1%) [September, 2024] Awarded the National Scholarship at Xidian University 8000 (Top 1%) [May, 2024] Won the International First Prize of American Collegiate Mathematical Modeling Contest MCM/ICM (Top 6%) [December, 2023] Awarded the Huawei \"Intelligent Base\" Industry-Education Integration Collaboration Education Base Scholarship of Xidian University 5000 [November, 2023] Awarded the Huameng Scholarship of Xidian University 5000 [November, 2023] Honored with the Excellent Student Model Award of Xidian University (Top 5% ) [November, 2023] Won the National Second Prize of China Collegiate Mathematical Modeling Contest CUMCM (Top 1.53% ) [August, 2023] Won the National First Prize in the China College Student Service Outsourcing Innovation and Entrepreneurship Competition FWWB 5000 (Top 0.3%) [June, 2023] Received an award for the Top prize of Shaanxi Province Advanced Mathematical Competition for College Students [December, 2022] Honored with the Youth Model Award of Xidian University (Top 1%) Courses @ ZHao Thankful to the senior of Chenlai Qian who has inspired me to make this analysis using PowerBI.","link":"/index.html"}]}