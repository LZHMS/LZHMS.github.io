---
title: Literature Survey about Volumetric Grasping Network:Real-time 6 DOF Grasp Detection in Clutter
date: 2023-11-01 22:56:09
toc: true
tags:
    - Literature Survey
categories: readings
excerpt: This is a literature survey about the paper of Volumetric Grasping Network:Real-time 6 DOF Grasp Detection in Clutter.
---
## 摘要概述

在通用机器人研究领域中，grasp detection 任务要求能够在一堆杂乱的物体中识别从未遇到过的物体以及处理物体之间的堆叠问题。作者针对此项任务提出了Volumetric Grasping Network(VGN)，以$3$D场景的Truncated Signed Distance Function(TSDF)表示作为输入，并能够对$3$D场景中的每一个体积元直接输出机器人抓取质量预测值，以及钩爪方向和张开宽度。这种方法能够在$10$ms内规划下一次抓取任务并且可以在现实世界杂乱物体中清除$92$%的物体。

## 研究的领域

机器人控制领域需要解决灵活性问题，即在复杂环境中能够计算无限次抓取并且处理物体聚类、堆叠以及高维噪声的问题。

## 解决的问题

在杂乱环境中规划未知物体的平行抓取问题，目标是寻找能够使得机器人成功抓取并从工作空间中移除所有物体的夹持器配置。

## 之前的研究

最近的研究大都关注于以数据驱动的方法规划抓取任务，但是规划的能力通常在单张深度图中局限于自顶向下的抓取。这种方法将搜寻能力约束为垂直抓取，假定物体能够垂直放置并且机器人只从一个单一的方向抓取。
最近比较好的一些工作能够在姿势估计上处理$6$个自由度的抓取，但是只能处理单个、孤立的物体，这使得这种方法在现实场景应用中需要额外的堆叠检测，甚至需要较高的推理时间。

## 作者的创新

作者提出了一种新颖的方法——$6$自由度实时抓取的综合方法，算法的输入是一个采用TSDF算法重建的表面模型，其中每一个体积元都利用截断符号距离表示真实场景表面附近的区域。
作者的主要创新点在于对于TSDF算法不仅是用于在$3$D场景重建中融合多个点云数据映射成连续的表面模型，还利用TSDF算法构建的规则的结构借助深度神经网络进行场景的特征学习。

<img src="https://cdn.jsdelivr.net/gh/LZHMS/picx-images-hosting@master/EBlog/Paper/image.18n59hby3ce8.webp" alt="Workflows" width="70%"/>

如上图，作者构建了一个全卷积网络(FCN)将输入TSDF映射到一个带有解决方案的相同空间中，其中的每一个体积元都包含有预测的抓取质量、钩爪方向和张开宽度。融合的特征使得这种方法能够通过网络的一步前向传递来检测整个工作空间的抓取。
物体堆叠的处理：作者假设包含整个场景的$3$D信息能够使得神经网络捕获钩爪与环境之间的冲突。
New Idea: 代替以往的研究以采样和评估单个的抓取策略，作者针对整个离散的抓取策略空间中所有抓取位置进行了评估。

## 作者的贡献

+ 使得$6$自由度的抓取合成方法能够实时处理
+ 使用全部3D场景信息去直接学习无冲突的抓取策略

## 算法的流程

### 最近的研究

由于深度学习对于未知的物体具有非常优越的泛化能力以及能够在杂乱的场景中找到可行的抓取策略，因此机器人抓取研究中经常选择深度学习方法来检测机器人的抓取。

综合的抓取方法可以分为两大类，第一种是输出自顶向下的抓取策略(尤其是$3$或$4$自由度)，第二种是输出$6$自由度的抓取策略。自顶向下的抓取策略或者使用顶视图数据，或者是深度图数据，或者是两者的结合并且以图形结构的形式返回可行的抓取策略；$6$自由度的抓取网络以整个场景的点云或者占据网格形式表达的$3$D信息作为输入。
假设：场景的点云信息能够识别空间物体的表面，假定由TSDF表示的额外的距离到表面信息能够提高整个抓取检测性能表现。因此作者认为对整个场景信息的充分利用能够使得系统考虑物体之间的物理交互作用，所以作者将整个TSDF输入给网络。通过这个策略使得最终处理场景重建和堆叠检测时不再需要进行分割处理。

### 存在的问题

这些抓取方法基本都作为抓取质量的预测器，这要求需要一些初始化过程在抓取策略空间中进行采样评估。
初始化过程是非常麻烦的，因为这需要在计算复杂度与采样覆盖范围达到最优的平衡。

### 作者的处理

作者训练抓取网络在整个空间体积表示中对于每一个体积元直接输出一个抓取策略(抓取方向和张开宽度)以及相联系的抓取质量预测值。网络采用非局部极大值抑制方法直接输出的就是最佳的抓取策略，而不用在运行时对候选的抓取策略进行评估得到最佳抓取策略，也不需要在抓取策略空间中进行迭代寻找可行的抓取策略，这是作者建立的网络模型能够进行实时处理的很重要的原因。

### 问题的表述

+ Gripper表示

$$
\tilde{\boldsymbol{t}} = \frac{T_{RV}(t)}{\boldsymbol{v}}, \tilde{\boldsymbol{r}}=T_{RV}(\boldsymbol{r}), \tilde{w}=\frac{w}{v}
$$

其中，$\tilde{\boldsymbol{t}}$ 表示钩爪被定义的体积元的坐标，$\tilde{w}$ 表示以体积元的大小为单元进行计量；

+ 规划的目标
  解决该该问题的目标就是寻找一个映射关系

$$
f: \boldsymbol{V}\rightarrow \boldsymbol{Q}, \boldsymbol{R}, \boldsymbol{W}
$$

其中，$\boldsymbol{Q}, \boldsymbol{R}, \boldsymbol{W}$ 包含在每一个体积元 $\tilde{\boldsymbol{t}}$ 上的抓取质量 $q$, 抓取方向 $\tilde{\boldsymbol{r}}$ 和 张开宽度 $\tilde{w}$.

### 构建的模型

作者构建了 Volumetric Grasping Network(VGN), 利用深度神经网络去估计深度映射关系 $f$。

+ 网络结构
  VGN采用FCN结构，首先设置了一个感知模块，用于将输入空间体 $\boldsymbol{V}$ 映射成特征图，第二部分由三个卷积层组成，交织2倍的双线性上采样，紧随三个独立的模块分别用于预测抓取质量，旋转以及张开宽度。
+ 输出说明

  + 抓取质量模块输出 $1\times N^3$ 大小的体积单元，其中每一项表示在该体积单元上成功完成抓取任务的概率值。
  + 旋转模块输出以四元组的形式表示抓取策略的方向，其中四元组选用欧拉角进行表示
  + 张开宽度模块输出预测了每一个体积元上应当采取的张开宽度
+ 综合训练
  作者训练整个网络采用端到端的方式进行训练，构建了以下损失函数：

$$
\zeta(\hat{g_i}, \tilde{g_i}) = \zeta_q(\hat{q_i}, q_i)+q_i(\zeta_r(\hat{\boldsymbol{r}_i}, \tilde{\boldsymbol{r}_i})+\zeta_w(\hat{w_i}, \tilde{w_i}))
$$

其中，$q_i\in${$0, 1$} 表示可行抓取策略的目标标签，而 $\hat{q_i}$ 表示VGN网络的预测输出标签，$\zeta_q$ 表示$q_i$ 和$\hat{q_i}$ 之间的二进制交叉损失，$zeta_w$ 表示展开宽度的预测 $\hat{w}$ 与目标 $w$ 的均方误差。对于四元组表示的抓取方向，在这里以点积的形式进行计算损失：

$$
\zeta_{quat} = 1-|\boldsymbol{\hat{r}}\cdot \tilde{\boldsymbol{r}}|
$$

由于夹持器的对称性，在旋转$180^\circ$的配置实际上对应的是相同的抓取，但是这会导致不一致的损失信号，因为网络会因为回归到两种不同的三维旋转之一而受到惩罚，因此作者对损失函数进行了扩展：

$$
\zeta_r(\boldsymbol{\hat{r}}, \tilde{\boldsymbol{r}})=\min(\zeta_{quat}(\boldsymbol{\hat{r}}, \tilde{\boldsymbol{r}}), \zeta_{quat}(\boldsymbol{\hat{r}}, \tilde{\boldsymbol{r_{\pi}}}))
$$

## 遗留的问题

+ 机器人夹具形状差异的问题
  作者所提出的方法进一步推广应用到不同的夹具几何形状上需要通过进一步的实验来验证。
+ 物理模拟实验局限性的问题
  在真实的机器人实验中，仅根据模拟数据进行训练存在一定的局限性，需要在物理模拟中引入对抗性测试进一步地去验证。

## 总结与思考

### Summary

这篇论文的主要贡献在于针对通用机器人领域中抓取物体的研究提出了创新性的算法与网络模型，解决了抓取任务中物体堆叠造成的冲突问题以及因计算复杂而造成的不可实时处理的问题。作者最大的创新之处在于摆脱了以往研究中通过采样和评估来获得单次的抓取策略，提出对整个场景空间中的所有抓取位置进行评估，选取抓取质量最好的位置进行抓取。

### Personal Views

对体抓取网络(VGN)的一些看法，作者不仅利用TSDF结构表示场景信息，并且借助于深度神经网络设计了一个特征学习模块，从场景(TSDF)中学习空间中每个体积元的特征，并通过进一步预测抓取质量、抓取方向以及张开宽度。这三个网络模块都是以3D场景中的每个体积元中心进行抓取的，因此在实际场景中，可以利用深度传感器检测物体的空间分布，然后对于覆盖的所有体积元选择抓取质量最高的体积元来获取抓取策略。可能这就是作者提出的体抓取网络名字的由来。
一些延伸想法，作者提出的VGN需要根据TSDF重建的3D场景信息计算所有的体积元，然后预测获取他们的抓取质量、抓取方向以及张开宽度；但是在场景范围比较大的时候，模型的计算量也将会是非常巨大的，并且抓取物体不仅与抓取方向和抓取宽度有关，还与在物体的某个方向施加的抓取力度有关，因此或许可以进一步在模型中考虑抓取力度对成功率的影响。
